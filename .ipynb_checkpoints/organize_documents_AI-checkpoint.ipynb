{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df5a812-3281-47bf-87b4-580520fd963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0feffb40-e066-4aec-8e2c-0753fa8a5972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2020 The HuggingFace Team. All rights reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "# When adding a new object to this init, remember to add it twice: once inside the `_import_structure` dictionary and\n",
      "# once inside the `if TYPE_CHECKING` branch. The `TYPE_CHECKING` should have import statements as usual, but they are\n",
      "# only there for type checking. The `_import_structure` is a dictionary submodule to list of object names, and is used\n",
      "# to defer the actual importing for when the objects are requested. This way `import transformers` provides the names\n",
      "# in the namespace without actually importing anything (and especially none of the backends).\n",
      "\n",
      "__version__ = \"4.51.3\"\n",
      "\n",
      "from typing import TYPE_CHECKING\n",
      "\n",
      "# Check the dependencies satisfy the minimal versions required.\n",
      "from . import dependency_versions_check\n",
      "from .utils import (\n",
      "    OptionalDependencyNotAvailable,\n",
      "    _LazyModule,\n",
      "    is_bitsandbytes_available,\n",
      "    is_essentia_available,\n",
      "    is_flax_available,\n",
      "    is_g2p_en_available,\n",
      "    is_keras_nlp_available,\n",
      "    is_librosa_available,\n",
      "    is_pretty_midi_available,\n",
      "    is_scipy_available,\n",
      "    is_sentencepiece_available,\n",
      "    is_speech_available,\n",
      "    is_tensorflow_text_available,\n",
      "    is_tf_available,\n",
      "    is_timm_available,\n",
      "    is_tokenizers_available,\n",
      "    is_torch_available,\n",
      "    is_torchaudio_available,\n",
      "    is_torchvision_available,\n",
      "    is_vision_available,\n",
      "    logging,\n",
      ")\n",
      "\n",
      "\n",
      "logger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n",
      "\n",
      "\n",
      "# Base objects, independent of any specific backend\n",
      "_import_structure = {\n",
      "    \"agents\": [\n",
      "        \"Agent\",\n",
      "        \"CodeAgent\",\n",
      "        \"HfApiEngine\",\n",
      "        \"ManagedAgent\",\n",
      "        \"PipelineTool\",\n",
      "        \"ReactAgent\",\n",
      "        \"ReactCodeAgent\",\n",
      "        \"ReactJsonAgent\",\n",
      "        \"Tool\",\n",
      "        \"Toolbox\",\n",
      "        \"ToolCollection\",\n",
      "        \"TransformersEngine\",\n",
      "        \"launch_gradio_demo\",\n",
      "        \"load_tool\",\n",
      "        \"stream_to_gradio\",\n",
      "        \"tool\",\n",
      "    ],\n",
      "    \"audio_utils\": [],\n",
      "    \"commands\": [],\n",
      "    \"configuration_utils\": [\"PretrainedConfig\"],\n",
      "    \"convert_graph_to_onnx\": [],\n",
      "    \"convert_slow_tokenizers_checkpoints_to_fast\": [],\n",
      "    \"convert_tf_hub_seq_to_seq_bert_to_pytorch\": [],\n",
      "    \"data\": [\n",
      "        \"DataProcessor\",\n",
      "        \"InputExample\",\n",
      "        \"InputFeatures\",\n",
      "        \"SingleSentenceClassificationProcessor\",\n",
      "        \"SquadExample\",\n",
      "        \"SquadFeatures\",\n",
      "        \"SquadV1Processor\",\n",
      "        \"SquadV2Processor\",\n",
      "        \"glue_compute_metrics\",\n",
      "        \"glue_convert_examples_to_features\",\n",
      "        \"glue_output_modes\",\n",
      "        \"glue_processors\",\n",
      "        \"glue_tasks_num_labels\",\n",
      "        \"squad_convert_examples_to_features\",\n",
      "        \"xnli_compute_metrics\",\n",
      "        \"xnli_output_modes\",\n",
      "        \"xnli_processors\",\n",
      "        \"xnli_tasks_num_labels\",\n",
      "    ],\n",
      "    \"data.data_collator\": [\n",
      "        \"DataCollator\",\n",
      "        \"DataCollatorForLanguageModeling\",\n",
      "        \"DataCollatorForMultipleChoice\",\n",
      "        \"DataCollatorForPermutationLanguageModeling\",\n",
      "        \"DataCollatorForSeq2Seq\",\n",
      "        \"DataCollatorForSOP\",\n",
      "        \"DataCollatorForTokenClassification\",\n",
      "        \"DataCollatorForWholeWordMask\",\n",
      "        \"DataCollatorWithFlattening\",\n",
      "        \"DataCollatorWithPadding\",\n",
      "        \"DefaultDataCollator\",\n",
      "        \"default_data_collator\",\n",
      "    ],\n",
      "    \"data.metrics\": [],\n",
      "    \"data.processors\": [],\n",
      "    \"debug_utils\": [],\n",
      "    \"dependency_versions_check\": [],\n",
      "    \"dependency_versions_table\": [],\n",
      "    \"dynamic_module_utils\": [],\n",
      "    \"feature_extraction_sequence_utils\": [\"SequenceFeatureExtractor\"],\n",
      "    \"feature_extraction_utils\": [\"BatchFeature\", \"FeatureExtractionMixin\"],\n",
      "    \"file_utils\": [],\n",
      "    \"generation\": [\n",
      "        \"AsyncTextIteratorStreamer\",\n",
      "        \"CompileConfig\",\n",
      "        \"GenerationConfig\",\n",
      "        \"TextIteratorStreamer\",\n",
      "        \"TextStreamer\",\n",
      "        \"WatermarkingConfig\",\n",
      "    ],\n",
      "    \"hf_argparser\": [\"HfArgumentParser\"],\n",
      "    \"hyperparameter_search\": [],\n",
      "    \"image_transforms\": [],\n",
      "    \"integrations\": [\n",
      "        \"is_clearml_available\",\n",
      "        \"is_comet_available\",\n",
      "        \"is_dvclive_available\",\n",
      "        \"is_neptune_available\",\n",
      "        \"is_optuna_available\",\n",
      "        \"is_ray_available\",\n",
      "        \"is_ray_tune_available\",\n",
      "        \"is_sigopt_available\",\n",
      "        \"is_swanlab_available\",\n",
      "        \"is_tensorboard_available\",\n",
      "        \"is_wandb_available\",\n",
      "    ],\n",
      "    \"loss\": [],\n",
      "    \"modelcard\": [\"ModelCard\"],\n",
      "    # Losses\n",
      "    \"modeling_tf_pytorch_utils\": [\n",
      "        \"convert_tf_weight_name_to_pt_weight_name\",\n",
      "        \"load_pytorch_checkpoint_in_tf2_model\",\n",
      "        \"load_pytorch_model_in_tf2_model\",\n",
      "        \"load_pytorch_weights_in_tf2_model\",\n",
      "        \"load_tf2_checkpoint_in_pytorch_model\",\n",
      "        \"load_tf2_model_in_pytorch_model\",\n",
      "        \"load_tf2_weights_in_pytorch_model\",\n",
      "    ],\n",
      "    # Models\n",
      "    \"models\": [],\n",
      "    \"models.albert\": [\"AlbertConfig\"],\n",
      "    \"models.align\": [\n",
      "        \"AlignConfig\",\n",
      "        \"AlignProcessor\",\n",
      "        \"AlignTextConfig\",\n",
      "        \"AlignVisionConfig\",\n",
      "    ],\n",
      "    \"models.altclip\": [\n",
      "        \"AltCLIPConfig\",\n",
      "        \"AltCLIPProcessor\",\n",
      "        \"AltCLIPTextConfig\",\n",
      "        \"AltCLIPVisionConfig\",\n",
      "    ],\n",
      "    \"models.aria\": [\n",
      "        \"AriaConfig\",\n",
      "        \"AriaProcessor\",\n",
      "        \"AriaTextConfig\",\n",
      "    ],\n",
      "    \"models.audio_spectrogram_transformer\": [\n",
      "        \"ASTConfig\",\n",
      "        \"ASTFeatureExtractor\",\n",
      "    ],\n",
      "    \"models.auto\": [\n",
      "        \"CONFIG_MAPPING\",\n",
      "        \"FEATURE_EXTRACTOR_MAPPING\",\n",
      "        \"IMAGE_PROCESSOR_MAPPING\",\n",
      "        \"MODEL_NAMES_MAPPING\",\n",
      "        \"PROCESSOR_MAPPING\",\n",
      "        \"TOKENIZER_MAPPING\",\n",
      "        \"AutoConfig\",\n",
      "        \"AutoFeatureExtractor\",\n",
      "        \"AutoImageProcessor\",\n",
      "        \"AutoProcessor\",\n",
      "        \"AutoTokenizer\",\n",
      "    ],\n",
      "    \"models.autoformer\": [\"AutoformerConfig\"],\n",
      "    \"models.aya_vision\": [\"AyaVisionConfig\", \"AyaVisionProcessor\"],\n",
      "    \"models.bamba\": [\"BambaConfig\"],\n",
      "    \"models.bark\": [\n",
      "        \"BarkCoarseConfig\",\n",
      "        \"BarkConfig\",\n",
      "        \"BarkFineConfig\",\n",
      "        \"BarkProcessor\",\n",
      "        \"BarkSemanticConfig\",\n",
      "    ],\n",
      "    \"models.bart\": [\"BartConfig\", \"BartTokenizer\"],\n",
      "    \"models.barthez\": [],\n",
      "    \"models.bartpho\": [],\n",
      "    \"models.beit\": [\"BeitConfig\"],\n",
      "    \"models.bert\": [\n",
      "        \"BasicTokenizer\",\n",
      "        \"BertConfig\",\n",
      "        \"BertTokenizer\",\n",
      "        \"WordpieceTokenizer\",\n",
      "    ],\n",
      "    \"models.bert_generation\": [\"BertGenerationConfig\"],\n",
      "    \"models.bert_japanese\": [\n",
      "        \"BertJapaneseTokenizer\",\n",
      "        \"CharacterTokenizer\",\n",
      "        \"MecabTokenizer\",\n",
      "    ],\n",
      "    \"models.bertweet\": [\"BertweetTokenizer\"],\n",
      "    \"models.big_bird\": [\"BigBirdConfig\"],\n",
      "    \"models.bigbird_pegasus\": [\"BigBirdPegasusConfig\"],\n",
      "    \"models.biogpt\": [\n",
      "        \"BioGptConfig\",\n",
      "        \"BioGptTokenizer\",\n",
      "    ],\n",
      "    \"models.bit\": [\"BitConfig\"],\n",
      "    \"models.blenderbot\": [\n",
      "        \"BlenderbotConfig\",\n",
      "        \"BlenderbotTokenizer\",\n",
      "    ],\n",
      "    \"models.blenderbot_small\": [\n",
      "        \"BlenderbotSmallConfig\",\n",
      "        \"BlenderbotSmallTokenizer\",\n",
      "    ],\n",
      "    \"models.blip\": [\n",
      "        \"BlipConfig\",\n",
      "        \"BlipProcessor\",\n",
      "        \"BlipTextConfig\",\n",
      "        \"BlipVisionConfig\",\n",
      "    ],\n",
      "    \"models.blip_2\": [\n",
      "        \"Blip2Config\",\n",
      "        \"Blip2Processor\",\n",
      "        \"Blip2QFormerConfig\",\n",
      "        \"Blip2VisionConfig\",\n",
      "    ],\n",
      "    \"models.bloom\": [\"BloomConfig\"],\n",
      "    \"models.bridgetower\": [\n",
      "        \"BridgeTowerConfig\",\n",
      "        \"BridgeTowerProcessor\",\n",
      "        \"BridgeTowerTextConfig\",\n",
      "        \"BridgeTowerVisionConfig\",\n",
      "    ],\n",
      "    \"models.bros\": [\n",
      "        \"BrosConfig\",\n",
      "        \"BrosProcessor\",\n",
      "    ],\n",
      "    \"models.byt5\": [\"ByT5Tokenizer\"],\n",
      "    \"models.camembert\": [\"CamembertConfig\"],\n",
      "    \"models.canine\": [\n",
      "        \"CanineConfig\",\n",
      "        \"CanineTokenizer\",\n",
      "    ],\n",
      "    \"models.chameleon\": [\n",
      "        \"ChameleonConfig\",\n",
      "        \"ChameleonProcessor\",\n",
      "        \"ChameleonVQVAEConfig\",\n",
      "    ],\n",
      "    \"models.chinese_clip\": [\n",
      "        \"ChineseCLIPConfig\",\n",
      "        \"ChineseCLIPProcessor\",\n",
      "        \"ChineseCLIPTextConfig\",\n",
      "        \"ChineseCLIPVisionConfig\",\n",
      "    ],\n",
      "    \"models.clap\": [\n",
      "        \"ClapAudioConfig\",\n",
      "        \"ClapConfig\",\n",
      "        \"ClapProcessor\",\n",
      "        \"ClapTextConfig\",\n",
      "    ],\n",
      "    \"models.clip\": [\n",
      "        \"CLIPConfig\",\n",
      "        \"CLIPProcessor\",\n",
      "        \"CLIPTextConfig\",\n",
      "        \"CLIPTokenizer\",\n",
      "        \"CLIPVisionConfig\",\n",
      "    ],\n",
      "    \"models.clipseg\": [\n",
      "        \"CLIPSegConfig\",\n",
      "        \"CLIPSegProcessor\",\n",
      "        \"CLIPSegTextConfig\",\n",
      "        \"CLIPSegVisionConfig\",\n",
      "    ],\n",
      "    \"models.clvp\": [\n",
      "        \"ClvpConfig\",\n",
      "        \"ClvpDecoderConfig\",\n",
      "        \"ClvpEncoderConfig\",\n",
      "        \"ClvpFeatureExtractor\",\n",
      "        \"ClvpProcessor\",\n",
      "        \"ClvpTokenizer\",\n",
      "    ],\n",
      "    \"models.code_llama\": [],\n",
      "    \"models.codegen\": [\n",
      "        \"CodeGenConfig\",\n",
      "        \"CodeGenTokenizer\",\n",
      "    ],\n",
      "    \"models.cohere\": [\"CohereConfig\"],\n",
      "    \"models.cohere2\": [\"Cohere2Config\"],\n",
      "    \"models.colpali\": [\n",
      "        \"ColPaliConfig\",\n",
      "        \"ColPaliProcessor\",\n",
      "    ],\n",
      "    \"models.conditional_detr\": [\"ConditionalDetrConfig\"],\n",
      "    \"models.convbert\": [\n",
      "        \"ConvBertConfig\",\n",
      "        \"ConvBertTokenizer\",\n",
      "    ],\n",
      "    \"models.convnext\": [\"ConvNextConfig\"],\n",
      "    \"models.convnextv2\": [\"ConvNextV2Config\"],\n",
      "    \"models.cpm\": [],\n",
      "    \"models.cpmant\": [\n",
      "        \"CpmAntConfig\",\n",
      "        \"CpmAntTokenizer\",\n",
      "    ],\n",
      "    \"models.ctrl\": [\n",
      "        \"CTRLConfig\",\n",
      "        \"CTRLTokenizer\",\n",
      "    ],\n",
      "    \"models.cvt\": [\"CvtConfig\"],\n",
      "    \"models.dab_detr\": [\"DabDetrConfig\"],\n",
      "    \"models.dac\": [\"DacConfig\", \"DacFeatureExtractor\"],\n",
      "    \"models.data2vec\": [\n",
      "        \"Data2VecAudioConfig\",\n",
      "        \"Data2VecTextConfig\",\n",
      "        \"Data2VecVisionConfig\",\n",
      "    ],\n",
      "    \"models.dbrx\": [\"DbrxConfig\"],\n",
      "    \"models.deberta\": [\n",
      "        \"DebertaConfig\",\n",
      "        \"DebertaTokenizer\",\n",
      "    ],\n",
      "    \"models.deberta_v2\": [\"DebertaV2Config\"],\n",
      "    \"models.decision_transformer\": [\"DecisionTransformerConfig\"],\n",
      "    \"models.deepseek_v3\": [\"DeepseekV3Config\"],\n",
      "    \"models.deformable_detr\": [\"DeformableDetrConfig\"],\n",
      "    \"models.deit\": [\"DeiTConfig\"],\n",
      "    \"models.deprecated\": [],\n",
      "    \"models.deprecated.bort\": [],\n",
      "    \"models.deprecated.deta\": [\"DetaConfig\"],\n",
      "    \"models.deprecated.efficientformer\": [\"EfficientFormerConfig\"],\n",
      "    \"models.deprecated.ernie_m\": [\"ErnieMConfig\"],\n",
      "    \"models.deprecated.gptsan_japanese\": [\n",
      "        \"GPTSanJapaneseConfig\",\n",
      "        \"GPTSanJapaneseTokenizer\",\n",
      "    ],\n",
      "    \"models.deprecated.graphormer\": [\"GraphormerConfig\"],\n",
      "    \"models.deprecated.jukebox\": [\n",
      "        \"JukeboxConfig\",\n",
      "        \"JukeboxPriorConfig\",\n",
      "        \"JukeboxTokenizer\",\n",
      "        \"JukeboxVQVAEConfig\",\n",
      "    ],\n",
      "    \"models.deprecated.mctct\": [\n",
      "        \"MCTCTConfig\",\n",
      "        \"MCTCTFeatureExtractor\",\n",
      "        \"MCTCTProcessor\",\n",
      "    ],\n",
      "    \"models.deprecated.mega\": [\"MegaConfig\"],\n",
      "    \"models.deprecated.mmbt\": [\"MMBTConfig\"],\n",
      "    \"models.deprecated.nat\": [\"NatConfig\"],\n",
      "    \"models.deprecated.nezha\": [\"NezhaConfig\"],\n",
      "    \"models.deprecated.open_llama\": [\"OpenLlamaConfig\"],\n",
      "    \"models.deprecated.qdqbert\": [\"QDQBertConfig\"],\n",
      "    \"models.deprecated.realm\": [\n",
      "        \"RealmConfig\",\n",
      "        \"RealmTokenizer\",\n",
      "    ],\n",
      "    \"models.deprecated.retribert\": [\n",
      "        \"RetriBertConfig\",\n",
      "        \"RetriBertTokenizer\",\n",
      "    ],\n",
      "    \"models.deprecated.speech_to_text_2\": [\n",
      "        \"Speech2Text2Config\",\n",
      "        \"Speech2Text2Processor\",\n",
      "        \"Speech2Text2Tokenizer\",\n",
      "    ],\n",
      "    \"models.deprecated.tapex\": [\"TapexTokenizer\"],\n",
      "    \"models.deprecated.trajectory_transformer\": [\"TrajectoryTransformerConfig\"],\n",
      "    \"models.deprecated.transfo_xl\": [\n",
      "        \"TransfoXLConfig\",\n",
      "        \"TransfoXLCorpus\",\n",
      "        \"TransfoXLTokenizer\",\n",
      "    ],\n",
      "    \"models.deprecated.tvlt\": [\n",
      "        \"TvltConfig\",\n",
      "        \"TvltFeatureExtractor\",\n",
      "        \"TvltProcessor\",\n",
      "    ],\n",
      "    \"models.deprecated.van\": [\"VanConfig\"],\n",
      "    \"models.deprecated.vit_hybrid\": [\"ViTHybridConfig\"],\n",
      "    \"models.deprecated.xlm_prophetnet\": [\"XLMProphetNetConfig\"],\n",
      "    \"models.depth_anything\": [\"DepthAnythingConfig\"],\n",
      "    \"models.depth_pro\": [\"DepthProConfig\"],\n",
      "    \"models.detr\": [\"DetrConfig\"],\n",
      "    \"models.dialogpt\": [],\n",
      "    \"models.diffllama\": [\"DiffLlamaConfig\"],\n",
      "    \"models.dinat\": [\"DinatConfig\"],\n",
      "    \"models.dinov2\": [\"Dinov2Config\"],\n",
      "    \"models.dinov2_with_registers\": [\"Dinov2WithRegistersConfig\"],\n",
      "    \"models.distilbert\": [\n",
      "        \"DistilBertConfig\",\n",
      "        \"DistilBertTokenizer\",\n",
      "    ],\n",
      "    \"models.dit\": [],\n",
      "    \"models.donut\": [\n",
      "        \"DonutProcessor\",\n",
      "        \"DonutSwinConfig\",\n",
      "    ],\n",
      "    \"models.dpr\": [\n",
      "        \"DPRConfig\",\n",
      "        \"DPRContextEncoderTokenizer\",\n",
      "        \"DPRQuestionEncoderTokenizer\",\n",
      "        \"DPRReaderOutput\",\n",
      "        \"DPRReaderTokenizer\",\n",
      "    ],\n",
      "    \"models.dpt\": [\"DPTConfig\"],\n",
      "    \"models.efficientnet\": [\"EfficientNetConfig\"],\n",
      "    \"models.electra\": [\n",
      "        \"ElectraConfig\",\n",
      "        \"ElectraTokenizer\",\n",
      "    ],\n",
      "    \"models.emu3\": [\n",
      "        \"Emu3Config\",\n",
      "        \"Emu3Processor\",\n",
      "        \"Emu3TextConfig\",\n",
      "        \"Emu3VQVAEConfig\",\n",
      "    ],\n",
      "    \"models.encodec\": [\n",
      "        \"EncodecConfig\",\n",
      "        \"EncodecFeatureExtractor\",\n",
      "    ],\n",
      "    \"models.encoder_decoder\": [\"EncoderDecoderConfig\"],\n",
      "    \"models.ernie\": [\"ErnieConfig\"],\n",
      "    \"models.esm\": [\"EsmConfig\", \"EsmTokenizer\"],\n",
      "    \"models.falcon\": [\"FalconConfig\"],\n",
      "    \"models.falcon_mamba\": [\"FalconMambaConfig\"],\n",
      "    \"models.fastspeech2_conformer\": [\n",
      "        \"FastSpeech2ConformerConfig\",\n",
      "        \"FastSpeech2ConformerHifiGanConfig\",\n",
      "        \"FastSpeech2ConformerTokenizer\",\n",
      "        \"FastSpeech2ConformerWithHifiGanConfig\",\n",
      "    ],\n",
      "    \"models.flaubert\": [\"FlaubertConfig\", \"FlaubertTokenizer\"],\n",
      "    \"models.flava\": [\n",
      "        \"FlavaConfig\",\n",
      "        \"FlavaImageCodebookConfig\",\n",
      "        \"FlavaImageConfig\",\n",
      "        \"FlavaMultimodalConfig\",\n",
      "        \"FlavaTextConfig\",\n",
      "    ],\n",
      "    \"models.fnet\": [\"FNetConfig\"],\n",
      "    \"models.focalnet\": [\"FocalNetConfig\"],\n",
      "    \"models.fsmt\": [\n",
      "        \"FSMTConfig\",\n",
      "        \"FSMTTokenizer\",\n",
      "    ],\n",
      "    \"models.funnel\": [\n",
      "        \"FunnelConfig\",\n",
      "        \"FunnelTokenizer\",\n",
      "    ],\n",
      "    \"models.fuyu\": [\"FuyuConfig\"],\n",
      "    \"models.gemma\": [\"GemmaConfig\"],\n",
      "    \"models.gemma2\": [\"Gemma2Config\"],\n",
      "    \"models.gemma3\": [\"Gemma3Config\", \"Gemma3Processor\", \"Gemma3TextConfig\"],\n",
      "    \"models.git\": [\n",
      "        \"GitConfig\",\n",
      "        \"GitProcessor\",\n",
      "        \"GitVisionConfig\",\n",
      "    ],\n",
      "    \"models.glm\": [\"GlmConfig\"],\n",
      "    \"models.glm4\": [\"Glm4Config\"],\n",
      "    \"models.glpn\": [\"GLPNConfig\"],\n",
      "    \"models.got_ocr2\": [\n",
      "        \"GotOcr2Config\",\n",
      "        \"GotOcr2Processor\",\n",
      "        \"GotOcr2VisionConfig\",\n",
      "    ],\n",
      "    \"models.gpt2\": [\n",
      "        \"GPT2Config\",\n",
      "        \"GPT2Tokenizer\",\n",
      "    ],\n",
      "    \"models.gpt_bigcode\": [\"GPTBigCodeConfig\"],\n",
      "    \"models.gpt_neo\": [\"GPTNeoConfig\"],\n",
      "    \"models.gpt_neox\": [\"GPTNeoXConfig\"],\n",
      "    \"models.gpt_neox_japanese\": [\"GPTNeoXJapaneseConfig\"],\n",
      "    \"models.gpt_sw3\": [],\n",
      "    \"models.gptj\": [\"GPTJConfig\"],\n",
      "    \"models.granite\": [\"GraniteConfig\"],\n",
      "    \"models.granitemoe\": [\"GraniteMoeConfig\"],\n",
      "    \"models.granitemoeshared\": [\"GraniteMoeSharedConfig\"],\n",
      "    \"models.grounding_dino\": [\n",
      "        \"GroundingDinoConfig\",\n",
      "        \"GroundingDinoProcessor\",\n",
      "    ],\n",
      "    \"models.groupvit\": [\n",
      "        \"GroupViTConfig\",\n",
      "        \"GroupViTTextConfig\",\n",
      "        \"GroupViTVisionConfig\",\n",
      "    ],\n",
      "    \"models.helium\": [\"HeliumConfig\"],\n",
      "    \"models.herbert\": [\"HerbertTokenizer\"],\n",
      "    \"models.hiera\": [\"HieraConfig\"],\n",
      "    \"models.hubert\": [\"HubertConfig\"],\n",
      "    \"models.ibert\": [\"IBertConfig\"],\n",
      "    \"models.idefics\": [\"IdeficsConfig\"],\n",
      "    \"models.idefics2\": [\"Idefics2Config\"],\n",
      "    \"models.idefics3\": [\"Idefics3Config\"],\n",
      "    \"models.ijepa\": [\"IJepaConfig\"],\n",
      "    \"models.imagegpt\": [\"ImageGPTConfig\"],\n",
      "    \"models.informer\": [\"InformerConfig\"],\n",
      "    \"models.instructblip\": [\n",
      "        \"InstructBlipConfig\",\n",
      "        \"InstructBlipProcessor\",\n",
      "        \"InstructBlipQFormerConfig\",\n",
      "        \"InstructBlipVisionConfig\",\n",
      "    ],\n",
      "    \"models.instructblipvideo\": [\n",
      "        \"InstructBlipVideoConfig\",\n",
      "        \"InstructBlipVideoProcessor\",\n",
      "        \"InstructBlipVideoQFormerConfig\",\n",
      "        \"InstructBlipVideoVisionConfig\",\n",
      "    ],\n",
      "    \"models.jamba\": [\"JambaConfig\"],\n",
      "    \"models.jetmoe\": [\"JetMoeConfig\"],\n",
      "    \"models.kosmos2\": [\n",
      "        \"Kosmos2Config\",\n",
      "        \"Kosmos2Processor\",\n",
      "    ],\n",
      "    \"models.layoutlm\": [\n",
      "        \"LayoutLMConfig\",\n",
      "        \"LayoutLMTokenizer\",\n",
      "    ],\n",
      "    \"models.layoutlmv2\": [\n",
      "        \"LayoutLMv2Config\",\n",
      "        \"LayoutLMv2FeatureExtractor\",\n",
      "        \"LayoutLMv2ImageProcessor\",\n",
      "        \"LayoutLMv2Processor\",\n",
      "        \"LayoutLMv2Tokenizer\",\n",
      "    ],\n",
      "    \"models.layoutlmv3\": [\n",
      "        \"LayoutLMv3Config\",\n",
      "        \"LayoutLMv3FeatureExtractor\",\n",
      "        \"LayoutLMv3ImageProcessor\",\n",
      "        \"LayoutLMv3Processor\",\n",
      "        \"LayoutLMv3Tokenizer\",\n",
      "    ],\n",
      "    \"models.layoutxlm\": [\"LayoutXLMProcessor\"],\n",
      "    \"models.led\": [\"LEDConfig\", \"LEDTokenizer\"],\n",
      "    \"models.levit\": [\"LevitConfig\"],\n",
      "    \"models.lilt\": [\"LiltConfig\"],\n",
      "    \"models.llama\": [\"LlamaConfig\"],\n",
      "    \"models.llama4\": [\n",
      "        \"Llama4Config\",\n",
      "        \"Llama4Processor\",\n",
      "        \"Llama4TextConfig\",\n",
      "        \"Llama4VisionConfig\",\n",
      "    ],\n",
      "    \"models.llava\": [\n",
      "        \"LlavaConfig\",\n",
      "        \"LlavaProcessor\",\n",
      "    ],\n",
      "    \"models.llava_next\": [\n",
      "        \"LlavaNextConfig\",\n",
      "        \"LlavaNextProcessor\",\n",
      "    ],\n",
      "    \"models.llava_next_video\": [\n",
      "        \"LlavaNextVideoConfig\",\n",
      "        \"LlavaNextVideoProcessor\",\n",
      "    ],\n",
      "    \"models.llava_onevision\": [\"LlavaOnevisionConfig\", \"LlavaOnevisionProcessor\"],\n",
      "    \"models.longformer\": [\n",
      "        \"LongformerConfig\",\n",
      "        \"LongformerTokenizer\",\n",
      "    ],\n",
      "    \"models.longt5\": [\"LongT5Config\"],\n",
      "    \"models.luke\": [\n",
      "        \"LukeConfig\",\n",
      "        \"LukeTokenizer\",\n",
      "    ],\n",
      "    \"models.lxmert\": [\n",
      "        \"LxmertConfig\",\n",
      "        \"LxmertTokenizer\",\n",
      "    ],\n",
      "    \"models.m2m_100\": [\"M2M100Config\"],\n",
      "    \"models.mamba\": [\"MambaConfig\"],\n",
      "    \"models.mamba2\": [\"Mamba2Config\"],\n",
      "    \"models.marian\": [\"MarianConfig\"],\n",
      "    \"models.markuplm\": [\n",
      "        \"MarkupLMConfig\",\n",
      "        \"MarkupLMFeatureExtractor\",\n",
      "        \"MarkupLMProcessor\",\n",
      "        \"MarkupLMTokenizer\",\n",
      "    ],\n",
      "    \"models.mask2former\": [\"Mask2FormerConfig\"],\n",
      "    \"models.maskformer\": [\n",
      "        \"MaskFormerConfig\",\n",
      "        \"MaskFormerSwinConfig\",\n",
      "    ],\n",
      "    \"models.mbart\": [\"MBartConfig\"],\n",
      "    \"models.mbart50\": [],\n",
      "    \"models.megatron_bert\": [\"MegatronBertConfig\"],\n",
      "    \"models.megatron_gpt2\": [],\n",
      "    \"models.mgp_str\": [\n",
      "        \"MgpstrConfig\",\n",
      "        \"MgpstrProcessor\",\n",
      "        \"MgpstrTokenizer\",\n",
      "    ],\n",
      "    \"models.mimi\": [\"MimiConfig\"],\n",
      "    \"models.mistral\": [\"MistralConfig\"],\n",
      "    \"models.mistral3\": [\"Mistral3Config\"],\n",
      "    \"models.mixtral\": [\"MixtralConfig\"],\n",
      "    \"models.mllama\": [\n",
      "        \"MllamaConfig\",\n",
      "        \"MllamaProcessor\",\n",
      "    ],\n",
      "    \"models.mluke\": [],\n",
      "    \"models.mobilebert\": [\n",
      "        \"MobileBertConfig\",\n",
      "        \"MobileBertTokenizer\",\n",
      "    ],\n",
      "    \"models.mobilenet_v1\": [\"MobileNetV1Config\"],\n",
      "    \"models.mobilenet_v2\": [\"MobileNetV2Config\"],\n",
      "    \"models.mobilevit\": [\"MobileViTConfig\"],\n",
      "    \"models.mobilevitv2\": [\"MobileViTV2Config\"],\n",
      "    \"models.modernbert\": [\"ModernBertConfig\"],\n",
      "    \"models.moonshine\": [\"MoonshineConfig\"],\n",
      "    \"models.moshi\": [\n",
      "        \"MoshiConfig\",\n",
      "        \"MoshiDepthConfig\",\n",
      "    ],\n",
      "    \"models.mpnet\": [\n",
      "        \"MPNetConfig\",\n",
      "        \"MPNetTokenizer\",\n",
      "    ],\n",
      "    \"models.mpt\": [\"MptConfig\"],\n",
      "    \"models.mra\": [\"MraConfig\"],\n",
      "    \"models.mt5\": [\"MT5Config\"],\n",
      "    \"models.musicgen\": [\n",
      "        \"MusicgenConfig\",\n",
      "        \"MusicgenDecoderConfig\",\n",
      "    ],\n",
      "    \"models.musicgen_melody\": [\n",
      "        \"MusicgenMelodyConfig\",\n",
      "        \"MusicgenMelodyDecoderConfig\",\n",
      "    ],\n",
      "    \"models.mvp\": [\"MvpConfig\", \"MvpTokenizer\"],\n",
      "    \"models.myt5\": [\"MyT5Tokenizer\"],\n",
      "    \"models.nemotron\": [\"NemotronConfig\"],\n",
      "    \"models.nllb\": [],\n",
      "    \"models.nllb_moe\": [\"NllbMoeConfig\"],\n",
      "    \"models.nougat\": [\"NougatProcessor\"],\n",
      "    \"models.nystromformer\": [\"NystromformerConfig\"],\n",
      "    \"models.olmo\": [\"OlmoConfig\"],\n",
      "    \"models.olmo2\": [\"Olmo2Config\"],\n",
      "    \"models.olmoe\": [\"OlmoeConfig\"],\n",
      "    \"models.omdet_turbo\": [\n",
      "        \"OmDetTurboConfig\",\n",
      "        \"OmDetTurboProcessor\",\n",
      "    ],\n",
      "    \"models.oneformer\": [\n",
      "        \"OneFormerConfig\",\n",
      "        \"OneFormerProcessor\",\n",
      "    ],\n",
      "    \"models.openai\": [\n",
      "        \"OpenAIGPTConfig\",\n",
      "        \"OpenAIGPTTokenizer\",\n",
      "    ],\n",
      "    \"models.opt\": [\"OPTConfig\"],\n",
      "    \"models.owlv2\": [\n",
      "        \"Owlv2Config\",\n",
      "        \"Owlv2Processor\",\n",
      "        \"Owlv2TextConfig\",\n",
      "        \"Owlv2VisionConfig\",\n",
      "    ],\n",
      "    \"models.owlvit\": [\n",
      "        \"OwlViTConfig\",\n",
      "        \"OwlViTProcessor\",\n",
      "        \"OwlViTTextConfig\",\n",
      "        \"OwlViTVisionConfig\",\n",
      "    ],\n",
      "    \"models.paligemma\": [\"PaliGemmaConfig\"],\n",
      "    \"models.patchtsmixer\": [\"PatchTSMixerConfig\"],\n",
      "    \"models.patchtst\": [\"PatchTSTConfig\"],\n",
      "    \"models.pegasus\": [\n",
      "        \"PegasusConfig\",\n",
      "        \"PegasusTokenizer\",\n",
      "    ],\n",
      "    \"models.pegasus_x\": [\"PegasusXConfig\"],\n",
      "    \"models.perceiver\": [\n",
      "        \"PerceiverConfig\",\n",
      "        \"PerceiverTokenizer\",\n",
      "    ],\n",
      "    \"models.persimmon\": [\"PersimmonConfig\"],\n",
      "    \"models.phi\": [\"PhiConfig\"],\n",
      "    \"models.phi3\": [\"Phi3Config\"],\n",
      "    \"models.phi4_multimodal\": [\n",
      "        \"Phi4MultimodalAudioConfig\",\n",
      "        \"Phi4MultimodalConfig\",\n",
      "        \"Phi4MultimodalFeatureExtractor\",\n",
      "        \"Phi4MultimodalProcessor\",\n",
      "        \"Phi4MultimodalVisionConfig\",\n",
      "    ],\n",
      "    \"models.phimoe\": [\"PhimoeConfig\"],\n",
      "    \"models.phobert\": [\"PhobertTokenizer\"],\n",
      "    \"models.pix2struct\": [\n",
      "        \"Pix2StructConfig\",\n",
      "        \"Pix2StructProcessor\",\n",
      "        \"Pix2StructTextConfig\",\n",
      "        \"Pix2StructVisionConfig\",\n",
      "    ],\n",
      "    \"models.pixtral\": [\"PixtralProcessor\", \"PixtralVisionConfig\"],\n",
      "    \"models.plbart\": [\"PLBartConfig\"],\n",
      "    \"models.poolformer\": [\"PoolFormerConfig\"],\n",
      "    \"models.pop2piano\": [\"Pop2PianoConfig\"],\n",
      "    \"models.prompt_depth_anything\": [\"PromptDepthAnythingConfig\"],\n",
      "    \"models.prophetnet\": [\n",
      "        \"ProphetNetConfig\",\n",
      "        \"ProphetNetTokenizer\",\n",
      "    ],\n",
      "    \"models.pvt\": [\"PvtConfig\"],\n",
      "    \"models.pvt_v2\": [\"PvtV2Config\"],\n",
      "    \"models.qwen2\": [\n",
      "        \"Qwen2Config\",\n",
      "        \"Qwen2Tokenizer\",\n",
      "    ],\n",
      "    \"models.qwen2_5_vl\": [\n",
      "        \"Qwen2_5_VLConfig\",\n",
      "        \"Qwen2_5_VLProcessor\",\n",
      "    ],\n",
      "    \"models.qwen2_audio\": [\n",
      "        \"Qwen2AudioConfig\",\n",
      "        \"Qwen2AudioEncoderConfig\",\n",
      "        \"Qwen2AudioProcessor\",\n",
      "    ],\n",
      "    \"models.qwen2_moe\": [\"Qwen2MoeConfig\"],\n",
      "    \"models.qwen2_vl\": [\n",
      "        \"Qwen2VLConfig\",\n",
      "        \"Qwen2VLProcessor\",\n",
      "    ],\n",
      "    \"models.qwen3\": [\"Qwen3Config\"],\n",
      "    \"models.qwen3_moe\": [\"Qwen3MoeConfig\"],\n",
      "    \"models.rag\": [\"RagConfig\", \"RagRetriever\", \"RagTokenizer\"],\n",
      "    \"models.recurrent_gemma\": [\"RecurrentGemmaConfig\"],\n",
      "    \"models.reformer\": [\"ReformerConfig\"],\n",
      "    \"models.regnet\": [\"RegNetConfig\"],\n",
      "    \"models.rembert\": [\"RemBertConfig\"],\n",
      "    \"models.resnet\": [\"ResNetConfig\"],\n",
      "    \"models.roberta\": [\n",
      "        \"RobertaConfig\",\n",
      "        \"RobertaTokenizer\",\n",
      "    ],\n",
      "    \"models.roberta_prelayernorm\": [\"RobertaPreLayerNormConfig\"],\n",
      "    \"models.roc_bert\": [\n",
      "        \"RoCBertConfig\",\n",
      "        \"RoCBertTokenizer\",\n",
      "    ],\n",
      "    \"models.roformer\": [\n",
      "        \"RoFormerConfig\",\n",
      "        \"RoFormerTokenizer\",\n",
      "    ],\n",
      "    \"models.rt_detr\": [\"RTDetrConfig\", \"RTDetrResNetConfig\"],\n",
      "    \"models.rt_detr_v2\": [\"RTDetrV2Config\"],\n",
      "    \"models.rwkv\": [\"RwkvConfig\"],\n",
      "    \"models.sam\": [\n",
      "        \"SamConfig\",\n",
      "        \"SamMaskDecoderConfig\",\n",
      "        \"SamProcessor\",\n",
      "        \"SamPromptEncoderConfig\",\n",
      "        \"SamVisionConfig\",\n",
      "    ],\n",
      "    \"models.seamless_m4t\": [\n",
      "        \"SeamlessM4TConfig\",\n",
      "        \"SeamlessM4TFeatureExtractor\",\n",
      "        \"SeamlessM4TProcessor\",\n",
      "    ],\n",
      "    \"models.seamless_m4t_v2\": [\"SeamlessM4Tv2Config\"],\n",
      "    \"models.segformer\": [\"SegformerConfig\"],\n",
      "    \"models.seggpt\": [\"SegGptConfig\"],\n",
      "    \"models.sew\": [\"SEWConfig\"],\n",
      "    \"models.sew_d\": [\"SEWDConfig\"],\n",
      "    \"models.shieldgemma2\": [\n",
      "        \"ShieldGemma2Config\",\n",
      "        \"ShieldGemma2Processor\",\n",
      "    ],\n",
      "    \"models.siglip\": [\n",
      "        \"SiglipConfig\",\n",
      "        \"SiglipProcessor\",\n",
      "        \"SiglipTextConfig\",\n",
      "        \"SiglipVisionConfig\",\n",
      "    ],\n",
      "    \"models.siglip2\": [\n",
      "        \"Siglip2Config\",\n",
      "        \"Siglip2Processor\",\n",
      "        \"Siglip2TextConfig\",\n",
      "        \"Siglip2VisionConfig\",\n",
      "    ],\n",
      "    \"models.smolvlm\": [\"SmolVLMConfig\"],\n",
      "    \"models.speech_encoder_decoder\": [\"SpeechEncoderDecoderConfig\"],\n",
      "    \"models.speech_to_text\": [\n",
      "        \"Speech2TextConfig\",\n",
      "        \"Speech2TextFeatureExtractor\",\n",
      "        \"Speech2TextProcessor\",\n",
      "    ],\n",
      "    \"models.speecht5\": [\n",
      "        \"SpeechT5Config\",\n",
      "        \"SpeechT5FeatureExtractor\",\n",
      "        \"SpeechT5HifiGanConfig\",\n",
      "        \"SpeechT5Processor\",\n",
      "    ],\n",
      "    \"models.splinter\": [\n",
      "        \"SplinterConfig\",\n",
      "        \"SplinterTokenizer\",\n",
      "    ],\n",
      "    \"models.squeezebert\": [\n",
      "        \"SqueezeBertConfig\",\n",
      "        \"SqueezeBertTokenizer\",\n",
      "    ],\n",
      "    \"models.stablelm\": [\"StableLmConfig\"],\n",
      "    \"models.starcoder2\": [\"Starcoder2Config\"],\n",
      "    \"models.superglue\": [\"SuperGlueConfig\"],\n",
      "    \"models.superpoint\": [\"SuperPointConfig\"],\n",
      "    \"models.swiftformer\": [\"SwiftFormerConfig\"],\n",
      "    \"models.swin\": [\"SwinConfig\"],\n",
      "    \"models.swin2sr\": [\"Swin2SRConfig\"],\n",
      "    \"models.swinv2\": [\"Swinv2Config\"],\n",
      "    \"models.switch_transformers\": [\"SwitchTransformersConfig\"],\n",
      "    \"models.t5\": [\"T5Config\"],\n",
      "    \"models.table_transformer\": [\"TableTransformerConfig\"],\n",
      "    \"models.tapas\": [\n",
      "        \"TapasConfig\",\n",
      "        \"TapasTokenizer\",\n",
      "    ],\n",
      "    \"models.textnet\": [\"TextNetConfig\"],\n",
      "    \"models.time_series_transformer\": [\"TimeSeriesTransformerConfig\"],\n",
      "    \"models.timesformer\": [\"TimesformerConfig\"],\n",
      "    \"models.timm_backbone\": [\"TimmBackboneConfig\"],\n",
      "    \"models.timm_wrapper\": [\"TimmWrapperConfig\"],\n",
      "    \"models.trocr\": [\n",
      "        \"TrOCRConfig\",\n",
      "        \"TrOCRProcessor\",\n",
      "    ],\n",
      "    \"models.tvp\": [\n",
      "        \"TvpConfig\",\n",
      "        \"TvpProcessor\",\n",
      "    ],\n",
      "    \"models.udop\": [\n",
      "        \"UdopConfig\",\n",
      "        \"UdopProcessor\",\n",
      "    ],\n",
      "    \"models.umt5\": [\"UMT5Config\"],\n",
      "    \"models.unispeech\": [\"UniSpeechConfig\"],\n",
      "    \"models.unispeech_sat\": [\"UniSpeechSatConfig\"],\n",
      "    \"models.univnet\": [\n",
      "        \"UnivNetConfig\",\n",
      "        \"UnivNetFeatureExtractor\",\n",
      "    ],\n",
      "    \"models.upernet\": [\"UperNetConfig\"],\n",
      "    \"models.video_llava\": [\"VideoLlavaConfig\"],\n",
      "    \"models.videomae\": [\"VideoMAEConfig\"],\n",
      "    \"models.vilt\": [\n",
      "        \"ViltConfig\",\n",
      "        \"ViltFeatureExtractor\",\n",
      "        \"ViltImageProcessor\",\n",
      "        \"ViltProcessor\",\n",
      "    ],\n",
      "    \"models.vipllava\": [\"VipLlavaConfig\"],\n",
      "    \"models.vision_encoder_decoder\": [\"VisionEncoderDecoderConfig\"],\n",
      "    \"models.vision_text_dual_encoder\": [\n",
      "        \"VisionTextDualEncoderConfig\",\n",
      "        \"VisionTextDualEncoderProcessor\",\n",
      "    ],\n",
      "    \"models.visual_bert\": [\"VisualBertConfig\"],\n",
      "    \"models.vit\": [\"ViTConfig\"],\n",
      "    \"models.vit_mae\": [\"ViTMAEConfig\"],\n",
      "    \"models.vit_msn\": [\"ViTMSNConfig\"],\n",
      "    \"models.vitdet\": [\"VitDetConfig\"],\n",
      "    \"models.vitmatte\": [\"VitMatteConfig\"],\n",
      "    \"models.vitpose\": [\"VitPoseConfig\"],\n",
      "    \"models.vitpose_backbone\": [\"VitPoseBackboneConfig\"],\n",
      "    \"models.vits\": [\n",
      "        \"VitsConfig\",\n",
      "        \"VitsTokenizer\",\n",
      "    ],\n",
      "    \"models.vivit\": [\"VivitConfig\"],\n",
      "    \"models.wav2vec2\": [\n",
      "        \"Wav2Vec2Config\",\n",
      "        \"Wav2Vec2CTCTokenizer\",\n",
      "        \"Wav2Vec2FeatureExtractor\",\n",
      "        \"Wav2Vec2Processor\",\n",
      "        \"Wav2Vec2Tokenizer\",\n",
      "    ],\n",
      "    \"models.wav2vec2_bert\": [\n",
      "        \"Wav2Vec2BertConfig\",\n",
      "        \"Wav2Vec2BertProcessor\",\n",
      "    ],\n",
      "    \"models.wav2vec2_conformer\": [\"Wav2Vec2ConformerConfig\"],\n",
      "    \"models.wav2vec2_phoneme\": [\"Wav2Vec2PhonemeCTCTokenizer\"],\n",
      "    \"models.wav2vec2_with_lm\": [\"Wav2Vec2ProcessorWithLM\"],\n",
      "    \"models.wavlm\": [\"WavLMConfig\"],\n",
      "    \"models.whisper\": [\n",
      "        \"WhisperConfig\",\n",
      "        \"WhisperFeatureExtractor\",\n",
      "        \"WhisperProcessor\",\n",
      "        \"WhisperTokenizer\",\n",
      "    ],\n",
      "    \"models.x_clip\": [\n",
      "        \"XCLIPConfig\",\n",
      "        \"XCLIPProcessor\",\n",
      "        \"XCLIPTextConfig\",\n",
      "        \"XCLIPVisionConfig\",\n",
      "    ],\n",
      "    \"models.xglm\": [\"XGLMConfig\"],\n",
      "    \"models.xlm\": [\"XLMConfig\", \"XLMTokenizer\"],\n",
      "    \"models.xlm_roberta\": [\"XLMRobertaConfig\"],\n",
      "    \"models.xlm_roberta_xl\": [\"XLMRobertaXLConfig\"],\n",
      "    \"models.xlnet\": [\"XLNetConfig\"],\n",
      "    \"models.xmod\": [\"XmodConfig\"],\n",
      "    \"models.yolos\": [\"YolosConfig\"],\n",
      "    \"models.yoso\": [\"YosoConfig\"],\n",
      "    \"models.zamba\": [\"ZambaConfig\"],\n",
      "    \"models.zamba2\": [\"Zamba2Config\"],\n",
      "    \"models.zoedepth\": [\"ZoeDepthConfig\"],\n",
      "    \"onnx\": [],\n",
      "    \"pipelines\": [\n",
      "        \"AudioClassificationPipeline\",\n",
      "        \"AutomaticSpeechRecognitionPipeline\",\n",
      "        \"CsvPipelineDataFormat\",\n",
      "        \"DepthEstimationPipeline\",\n",
      "        \"DocumentQuestionAnsweringPipeline\",\n",
      "        \"FeatureExtractionPipeline\",\n",
      "        \"FillMaskPipeline\",\n",
      "        \"ImageClassificationPipeline\",\n",
      "        \"ImageFeatureExtractionPipeline\",\n",
      "        \"ImageSegmentationPipeline\",\n",
      "        \"ImageTextToTextPipeline\",\n",
      "        \"ImageToImagePipeline\",\n",
      "        \"ImageToTextPipeline\",\n",
      "        \"JsonPipelineDataFormat\",\n",
      "        \"MaskGenerationPipeline\",\n",
      "        \"NerPipeline\",\n",
      "        \"ObjectDetectionPipeline\",\n",
      "        \"PipedPipelineDataFormat\",\n",
      "        \"Pipeline\",\n",
      "        \"PipelineDataFormat\",\n",
      "        \"QuestionAnsweringPipeline\",\n",
      "        \"SummarizationPipeline\",\n",
      "        \"TableQuestionAnsweringPipeline\",\n",
      "        \"Text2TextGenerationPipeline\",\n",
      "        \"TextClassificationPipeline\",\n",
      "        \"TextGenerationPipeline\",\n",
      "        \"TextToAudioPipeline\",\n",
      "        \"TokenClassificationPipeline\",\n",
      "        \"TranslationPipeline\",\n",
      "        \"VideoClassificationPipeline\",\n",
      "        \"VisualQuestionAnsweringPipeline\",\n",
      "        \"ZeroShotAudioClassificationPipeline\",\n",
      "        \"ZeroShotClassificationPipeline\",\n",
      "        \"ZeroShotImageClassificationPipeline\",\n",
      "        \"ZeroShotObjectDetectionPipeline\",\n",
      "        \"pipeline\",\n",
      "    ],\n",
      "    \"processing_utils\": [\"ProcessorMixin\"],\n",
      "    \"quantizers\": [],\n",
      "    \"testing_utils\": [],\n",
      "    \"tokenization_utils\": [\"PreTrainedTokenizer\"],\n",
      "    \"tokenization_utils_base\": [\n",
      "        \"AddedToken\",\n",
      "        \"BatchEncoding\",\n",
      "        \"CharSpan\",\n",
      "        \"PreTrainedTokenizerBase\",\n",
      "        \"SpecialTokensMixin\",\n",
      "        \"TokenSpan\",\n",
      "    ],\n",
      "    \"trainer_callback\": [\n",
      "        \"DefaultFlowCallback\",\n",
      "        \"EarlyStoppingCallback\",\n",
      "        \"PrinterCallback\",\n",
      "        \"ProgressCallback\",\n",
      "        \"TrainerCallback\",\n",
      "        \"TrainerControl\",\n",
      "        \"TrainerState\",\n",
      "    ],\n",
      "    \"trainer_utils\": [\n",
      "        \"EvalPrediction\",\n",
      "        \"IntervalStrategy\",\n",
      "        \"SchedulerType\",\n",
      "        \"enable_full_determinism\",\n",
      "        \"set_seed\",\n",
      "    ],\n",
      "    \"training_args\": [\"TrainingArguments\"],\n",
      "    \"training_args_seq2seq\": [\"Seq2SeqTrainingArguments\"],\n",
      "    \"training_args_tf\": [\"TFTrainingArguments\"],\n",
      "    \"utils\": [\n",
      "        \"CONFIG_NAME\",\n",
      "        \"MODEL_CARD_NAME\",\n",
      "        \"PYTORCH_PRETRAINED_BERT_CACHE\",\n",
      "        \"PYTORCH_TRANSFORMERS_CACHE\",\n",
      "        \"SPIECE_UNDERLINE\",\n",
      "        \"TF2_WEIGHTS_NAME\",\n",
      "        \"TF_WEIGHTS_NAME\",\n",
      "        \"TRANSFORMERS_CACHE\",\n",
      "        \"WEIGHTS_NAME\",\n",
      "        \"TensorType\",\n",
      "        \"add_end_docstrings\",\n",
      "        \"add_start_docstrings\",\n",
      "        \"is_apex_available\",\n",
      "        \"is_av_available\",\n",
      "        \"is_bitsandbytes_available\",\n",
      "        \"is_datasets_available\",\n",
      "        \"is_faiss_available\",\n",
      "        \"is_flax_available\",\n",
      "        \"is_keras_nlp_available\",\n",
      "        \"is_phonemizer_available\",\n",
      "        \"is_psutil_available\",\n",
      "        \"is_py3nvml_available\",\n",
      "        \"is_pyctcdecode_available\",\n",
      "        \"is_sacremoses_available\",\n",
      "        \"is_safetensors_available\",\n",
      "        \"is_scipy_available\",\n",
      "        \"is_sentencepiece_available\",\n",
      "        \"is_sklearn_available\",\n",
      "        \"is_speech_available\",\n",
      "        \"is_tensorflow_text_available\",\n",
      "        \"is_tf_available\",\n",
      "        \"is_timm_available\",\n",
      "        \"is_tokenizers_available\",\n",
      "        \"is_torch_available\",\n",
      "        \"is_torch_hpu_available\",\n",
      "        \"is_torch_mlu_available\",\n",
      "        \"is_torch_musa_available\",\n",
      "        \"is_torch_neuroncore_available\",\n",
      "        \"is_torch_npu_available\",\n",
      "        \"is_torchvision_available\",\n",
      "        \"is_torch_xla_available\",\n",
      "        \"is_torch_xpu_available\",\n",
      "        \"is_vision_available\",\n",
      "        \"logging\",\n",
      "    ],\n",
      "    \"utils.quantization_config\": [\n",
      "        \"AqlmConfig\",\n",
      "        \"AwqConfig\",\n",
      "        \"BitNetConfig\",\n",
      "        \"BitsAndBytesConfig\",\n",
      "        \"CompressedTensorsConfig\",\n",
      "        \"EetqConfig\",\n",
      "        \"FbgemmFp8Config\",\n",
      "        \"FineGrainedFP8Config\",\n",
      "        \"GPTQConfig\",\n",
      "        \"HiggsConfig\",\n",
      "        \"HqqConfig\",\n",
      "        \"QuantoConfig\",\n",
      "        \"QuarkConfig\",\n",
      "        \"SpQRConfig\",\n",
      "        \"TorchAoConfig\",\n",
      "        \"VptqConfig\",\n",
      "    ],\n",
      "}\n",
      "\n",
      "# sentencepiece-backed objects\n",
      "try:\n",
      "    if not is_sentencepiece_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_sentencepiece_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_sentencepiece_objects\"] = [\n",
      "        name for name in dir(dummy_sentencepiece_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"models.albert\"].append(\"AlbertTokenizer\")\n",
      "    _import_structure[\"models.barthez\"].append(\"BarthezTokenizer\")\n",
      "    _import_structure[\"models.bartpho\"].append(\"BartphoTokenizer\")\n",
      "    _import_structure[\"models.bert_generation\"].append(\"BertGenerationTokenizer\")\n",
      "    _import_structure[\"models.big_bird\"].append(\"BigBirdTokenizer\")\n",
      "    _import_structure[\"models.camembert\"].append(\"CamembertTokenizer\")\n",
      "    _import_structure[\"models.code_llama\"].append(\"CodeLlamaTokenizer\")\n",
      "    _import_structure[\"models.cpm\"].append(\"CpmTokenizer\")\n",
      "    _import_structure[\"models.deberta_v2\"].append(\"DebertaV2Tokenizer\")\n",
      "    _import_structure[\"models.deprecated.ernie_m\"].append(\"ErnieMTokenizer\")\n",
      "    _import_structure[\"models.deprecated.xlm_prophetnet\"].append(\"XLMProphetNetTokenizer\")\n",
      "    _import_structure[\"models.fnet\"].append(\"FNetTokenizer\")\n",
      "    _import_structure[\"models.gemma\"].append(\"GemmaTokenizer\")\n",
      "    _import_structure[\"models.gpt_sw3\"].append(\"GPTSw3Tokenizer\")\n",
      "    _import_structure[\"models.layoutxlm\"].append(\"LayoutXLMTokenizer\")\n",
      "    _import_structure[\"models.llama\"].append(\"LlamaTokenizer\")\n",
      "    _import_structure[\"models.m2m_100\"].append(\"M2M100Tokenizer\")\n",
      "    _import_structure[\"models.marian\"].append(\"MarianTokenizer\")\n",
      "    _import_structure[\"models.mbart\"].append(\"MBartTokenizer\")\n",
      "    _import_structure[\"models.mbart50\"].append(\"MBart50Tokenizer\")\n",
      "    _import_structure[\"models.mluke\"].append(\"MLukeTokenizer\")\n",
      "    _import_structure[\"models.mt5\"].append(\"MT5Tokenizer\")\n",
      "    _import_structure[\"models.nllb\"].append(\"NllbTokenizer\")\n",
      "    _import_structure[\"models.pegasus\"].append(\"PegasusTokenizer\")\n",
      "    _import_structure[\"models.plbart\"].append(\"PLBartTokenizer\")\n",
      "    _import_structure[\"models.reformer\"].append(\"ReformerTokenizer\")\n",
      "    _import_structure[\"models.rembert\"].append(\"RemBertTokenizer\")\n",
      "    _import_structure[\"models.seamless_m4t\"].append(\"SeamlessM4TTokenizer\")\n",
      "    _import_structure[\"models.siglip\"].append(\"SiglipTokenizer\")\n",
      "    _import_structure[\"models.speech_to_text\"].append(\"Speech2TextTokenizer\")\n",
      "    _import_structure[\"models.speecht5\"].append(\"SpeechT5Tokenizer\")\n",
      "    _import_structure[\"models.t5\"].append(\"T5Tokenizer\")\n",
      "    _import_structure[\"models.udop\"].append(\"UdopTokenizer\")\n",
      "    _import_structure[\"models.xglm\"].append(\"XGLMTokenizer\")\n",
      "    _import_structure[\"models.xlm_roberta\"].append(\"XLMRobertaTokenizer\")\n",
      "    _import_structure[\"models.xlnet\"].append(\"XLNetTokenizer\")\n",
      "\n",
      "# tokenizers-backed objects\n",
      "try:\n",
      "    if not is_tokenizers_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_tokenizers_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_tokenizers_objects\"] = [\n",
      "        name for name in dir(dummy_tokenizers_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    # Fast tokenizers structure\n",
      "    _import_structure[\"models.albert\"].append(\"AlbertTokenizerFast\")\n",
      "    _import_structure[\"models.bart\"].append(\"BartTokenizerFast\")\n",
      "    _import_structure[\"models.barthez\"].append(\"BarthezTokenizerFast\")\n",
      "    _import_structure[\"models.bert\"].append(\"BertTokenizerFast\")\n",
      "    _import_structure[\"models.big_bird\"].append(\"BigBirdTokenizerFast\")\n",
      "    _import_structure[\"models.blenderbot\"].append(\"BlenderbotTokenizerFast\")\n",
      "    _import_structure[\"models.blenderbot_small\"].append(\"BlenderbotSmallTokenizerFast\")\n",
      "    _import_structure[\"models.bloom\"].append(\"BloomTokenizerFast\")\n",
      "    _import_structure[\"models.camembert\"].append(\"CamembertTokenizerFast\")\n",
      "    _import_structure[\"models.clip\"].append(\"CLIPTokenizerFast\")\n",
      "    _import_structure[\"models.code_llama\"].append(\"CodeLlamaTokenizerFast\")\n",
      "    _import_structure[\"models.codegen\"].append(\"CodeGenTokenizerFast\")\n",
      "    _import_structure[\"models.cohere\"].append(\"CohereTokenizerFast\")\n",
      "    _import_structure[\"models.convbert\"].append(\"ConvBertTokenizerFast\")\n",
      "    _import_structure[\"models.cpm\"].append(\"CpmTokenizerFast\")\n",
      "    _import_structure[\"models.deberta\"].append(\"DebertaTokenizerFast\")\n",
      "    _import_structure[\"models.deberta_v2\"].append(\"DebertaV2TokenizerFast\")\n",
      "    _import_structure[\"models.deprecated.realm\"].append(\"RealmTokenizerFast\")\n",
      "    _import_structure[\"models.deprecated.retribert\"].append(\"RetriBertTokenizerFast\")\n",
      "    _import_structure[\"models.distilbert\"].append(\"DistilBertTokenizerFast\")\n",
      "    _import_structure[\"models.dpr\"].extend(\n",
      "        [\n",
      "            \"DPRContextEncoderTokenizerFast\",\n",
      "            \"DPRQuestionEncoderTokenizerFast\",\n",
      "            \"DPRReaderTokenizerFast\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.electra\"].append(\"ElectraTokenizerFast\")\n",
      "    _import_structure[\"models.fnet\"].append(\"FNetTokenizerFast\")\n",
      "    _import_structure[\"models.funnel\"].append(\"FunnelTokenizerFast\")\n",
      "    _import_structure[\"models.gemma\"].append(\"GemmaTokenizerFast\")\n",
      "    _import_structure[\"models.gpt2\"].append(\"GPT2TokenizerFast\")\n",
      "    _import_structure[\"models.gpt_neox\"].append(\"GPTNeoXTokenizerFast\")\n",
      "    _import_structure[\"models.gpt_neox_japanese\"].append(\"GPTNeoXJapaneseTokenizer\")\n",
      "    _import_structure[\"models.herbert\"].append(\"HerbertTokenizerFast\")\n",
      "    _import_structure[\"models.layoutlm\"].append(\"LayoutLMTokenizerFast\")\n",
      "    _import_structure[\"models.layoutlmv2\"].append(\"LayoutLMv2TokenizerFast\")\n",
      "    _import_structure[\"models.layoutlmv3\"].append(\"LayoutLMv3TokenizerFast\")\n",
      "    _import_structure[\"models.layoutxlm\"].append(\"LayoutXLMTokenizerFast\")\n",
      "    _import_structure[\"models.led\"].append(\"LEDTokenizerFast\")\n",
      "    _import_structure[\"models.llama\"].append(\"LlamaTokenizerFast\")\n",
      "    _import_structure[\"models.longformer\"].append(\"LongformerTokenizerFast\")\n",
      "    _import_structure[\"models.lxmert\"].append(\"LxmertTokenizerFast\")\n",
      "    _import_structure[\"models.markuplm\"].append(\"MarkupLMTokenizerFast\")\n",
      "    _import_structure[\"models.mbart\"].append(\"MBartTokenizerFast\")\n",
      "    _import_structure[\"models.mbart50\"].append(\"MBart50TokenizerFast\")\n",
      "    _import_structure[\"models.mobilebert\"].append(\"MobileBertTokenizerFast\")\n",
      "    _import_structure[\"models.mpnet\"].append(\"MPNetTokenizerFast\")\n",
      "    _import_structure[\"models.mt5\"].append(\"MT5TokenizerFast\")\n",
      "    _import_structure[\"models.mvp\"].append(\"MvpTokenizerFast\")\n",
      "    _import_structure[\"models.nllb\"].append(\"NllbTokenizerFast\")\n",
      "    _import_structure[\"models.nougat\"].append(\"NougatTokenizerFast\")\n",
      "    _import_structure[\"models.openai\"].append(\"OpenAIGPTTokenizerFast\")\n",
      "    _import_structure[\"models.pegasus\"].append(\"PegasusTokenizerFast\")\n",
      "    _import_structure[\"models.qwen2\"].append(\"Qwen2TokenizerFast\")\n",
      "    _import_structure[\"models.reformer\"].append(\"ReformerTokenizerFast\")\n",
      "    _import_structure[\"models.rembert\"].append(\"RemBertTokenizerFast\")\n",
      "    _import_structure[\"models.roberta\"].append(\"RobertaTokenizerFast\")\n",
      "    _import_structure[\"models.roformer\"].append(\"RoFormerTokenizerFast\")\n",
      "    _import_structure[\"models.seamless_m4t\"].append(\"SeamlessM4TTokenizerFast\")\n",
      "    _import_structure[\"models.splinter\"].append(\"SplinterTokenizerFast\")\n",
      "    _import_structure[\"models.squeezebert\"].append(\"SqueezeBertTokenizerFast\")\n",
      "    _import_structure[\"models.t5\"].append(\"T5TokenizerFast\")\n",
      "    _import_structure[\"models.udop\"].append(\"UdopTokenizerFast\")\n",
      "    _import_structure[\"models.whisper\"].append(\"WhisperTokenizerFast\")\n",
      "    _import_structure[\"models.xglm\"].append(\"XGLMTokenizerFast\")\n",
      "    _import_structure[\"models.xlm_roberta\"].append(\"XLMRobertaTokenizerFast\")\n",
      "    _import_structure[\"models.xlnet\"].append(\"XLNetTokenizerFast\")\n",
      "    _import_structure[\"tokenization_utils_fast\"] = [\"PreTrainedTokenizerFast\"]\n",
      "\n",
      "\n",
      "try:\n",
      "    if not (is_sentencepiece_available() and is_tokenizers_available()):\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_sentencepiece_and_tokenizers_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_sentencepiece_and_tokenizers_objects\"] = [\n",
      "        name for name in dir(dummy_sentencepiece_and_tokenizers_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"convert_slow_tokenizer\"] = [\n",
      "        \"SLOW_TO_FAST_CONVERTERS\",\n",
      "        \"convert_slow_tokenizer\",\n",
      "    ]\n",
      "\n",
      "# Tensorflow-text-specific objects\n",
      "try:\n",
      "    if not is_tensorflow_text_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_tensorflow_text_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_tensorflow_text_objects\"] = [\n",
      "        name for name in dir(dummy_tensorflow_text_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"models.bert\"].append(\"TFBertTokenizer\")\n",
      "\n",
      "# keras-nlp-specific objects\n",
      "try:\n",
      "    if not is_keras_nlp_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_keras_nlp_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_keras_nlp_objects\"] = [\n",
      "        name for name in dir(dummy_keras_nlp_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"models.gpt2\"].append(\"TFGPT2Tokenizer\")\n",
      "\n",
      "# Vision-specific objects\n",
      "try:\n",
      "    if not is_vision_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_vision_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_vision_objects\"] = [\n",
      "        name for name in dir(dummy_vision_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"image_processing_base\"] = [\"ImageProcessingMixin\"]\n",
      "    _import_structure[\"image_processing_utils\"] = [\"BaseImageProcessor\"]\n",
      "    _import_structure[\"image_utils\"] = [\"ImageFeatureExtractionMixin\"]\n",
      "    _import_structure[\"models.aria\"].extend([\"AriaImageProcessor\"])\n",
      "    _import_structure[\"models.beit\"].extend([\"BeitFeatureExtractor\", \"BeitImageProcessor\"])\n",
      "    _import_structure[\"models.bit\"].extend([\"BitImageProcessor\"])\n",
      "    _import_structure[\"models.blip\"].extend([\"BlipImageProcessor\"])\n",
      "    _import_structure[\"models.bridgetower\"].append(\"BridgeTowerImageProcessor\")\n",
      "    _import_structure[\"models.chameleon\"].append(\"ChameleonImageProcessor\")\n",
      "    _import_structure[\"models.chinese_clip\"].extend([\"ChineseCLIPFeatureExtractor\", \"ChineseCLIPImageProcessor\"])\n",
      "    _import_structure[\"models.clip\"].extend([\"CLIPFeatureExtractor\", \"CLIPImageProcessor\"])\n",
      "    _import_structure[\"models.conditional_detr\"].extend(\n",
      "        [\"ConditionalDetrFeatureExtractor\", \"ConditionalDetrImageProcessor\"]\n",
      "    )\n",
      "    _import_structure[\"models.convnext\"].extend([\"ConvNextFeatureExtractor\", \"ConvNextImageProcessor\"])\n",
      "    _import_structure[\"models.deformable_detr\"].extend(\n",
      "        [\"DeformableDetrFeatureExtractor\", \"DeformableDetrImageProcessor\"]\n",
      "    )\n",
      "    _import_structure[\"models.deit\"].extend([\"DeiTFeatureExtractor\", \"DeiTImageProcessor\"])\n",
      "    _import_structure[\"models.deprecated.deta\"].append(\"DetaImageProcessor\")\n",
      "    _import_structure[\"models.deprecated.efficientformer\"].append(\"EfficientFormerImageProcessor\")\n",
      "    _import_structure[\"models.deprecated.tvlt\"].append(\"TvltImageProcessor\")\n",
      "    _import_structure[\"models.deprecated.vit_hybrid\"].extend([\"ViTHybridImageProcessor\"])\n",
      "    _import_structure[\"models.depth_pro\"].extend([\"DepthProImageProcessor\", \"DepthProImageProcessorFast\"])\n",
      "    _import_structure[\"models.detr\"].extend([\"DetrFeatureExtractor\", \"DetrImageProcessor\"])\n",
      "    _import_structure[\"models.donut\"].extend([\"DonutFeatureExtractor\", \"DonutImageProcessor\"])\n",
      "    _import_structure[\"models.dpt\"].extend([\"DPTFeatureExtractor\", \"DPTImageProcessor\"])\n",
      "    _import_structure[\"models.efficientnet\"].append(\"EfficientNetImageProcessor\")\n",
      "    _import_structure[\"models.emu3\"].append(\"Emu3ImageProcessor\")\n",
      "    _import_structure[\"models.flava\"].extend([\"FlavaFeatureExtractor\", \"FlavaImageProcessor\", \"FlavaProcessor\"])\n",
      "    _import_structure[\"models.fuyu\"].extend([\"FuyuImageProcessor\", \"FuyuProcessor\"])\n",
      "    _import_structure[\"models.gemma3\"].append(\"Gemma3ImageProcessor\")\n",
      "    _import_structure[\"models.glpn\"].extend([\"GLPNFeatureExtractor\", \"GLPNImageProcessor\"])\n",
      "    _import_structure[\"models.got_ocr2\"].extend([\"GotOcr2ImageProcessor\"])\n",
      "    _import_structure[\"models.grounding_dino\"].extend([\"GroundingDinoImageProcessor\"])\n",
      "    _import_structure[\"models.idefics\"].extend([\"IdeficsImageProcessor\"])\n",
      "    _import_structure[\"models.idefics2\"].extend([\"Idefics2ImageProcessor\"])\n",
      "    _import_structure[\"models.idefics3\"].extend([\"Idefics3ImageProcessor\"])\n",
      "    _import_structure[\"models.imagegpt\"].extend([\"ImageGPTFeatureExtractor\", \"ImageGPTImageProcessor\"])\n",
      "    _import_structure[\"models.instructblipvideo\"].extend([\"InstructBlipVideoImageProcessor\"])\n",
      "    _import_structure[\"models.layoutlmv2\"].extend([\"LayoutLMv2FeatureExtractor\", \"LayoutLMv2ImageProcessor\"])\n",
      "    _import_structure[\"models.layoutlmv3\"].extend([\"LayoutLMv3FeatureExtractor\", \"LayoutLMv3ImageProcessor\"])\n",
      "    _import_structure[\"models.levit\"].extend([\"LevitFeatureExtractor\", \"LevitImageProcessor\"])\n",
      "    _import_structure[\"models.llava\"].append(\"LlavaImageProcessor\")\n",
      "    _import_structure[\"models.llava_next\"].append(\"LlavaNextImageProcessor\")\n",
      "    _import_structure[\"models.llava_next_video\"].append(\"LlavaNextVideoImageProcessor\")\n",
      "    _import_structure[\"models.llava_onevision\"].extend(\n",
      "        [\"LlavaOnevisionImageProcessor\", \"LlavaOnevisionVideoProcessor\"]\n",
      "    )\n",
      "    _import_structure[\"models.mask2former\"].append(\"Mask2FormerImageProcessor\")\n",
      "    _import_structure[\"models.maskformer\"].extend([\"MaskFormerFeatureExtractor\", \"MaskFormerImageProcessor\"])\n",
      "    _import_structure[\"models.mllama\"].extend([\"MllamaImageProcessor\"])\n",
      "    _import_structure[\"models.mobilenet_v1\"].extend([\"MobileNetV1FeatureExtractor\", \"MobileNetV1ImageProcessor\"])\n",
      "    _import_structure[\"models.mobilenet_v2\"].extend([\"MobileNetV2FeatureExtractor\", \"MobileNetV2ImageProcessor\"])\n",
      "    _import_structure[\"models.mobilevit\"].extend([\"MobileViTFeatureExtractor\", \"MobileViTImageProcessor\"])\n",
      "    _import_structure[\"models.nougat\"].append(\"NougatImageProcessor\")\n",
      "    _import_structure[\"models.oneformer\"].extend([\"OneFormerImageProcessor\"])\n",
      "    _import_structure[\"models.owlv2\"].append(\"Owlv2ImageProcessor\")\n",
      "    _import_structure[\"models.owlvit\"].extend([\"OwlViTFeatureExtractor\", \"OwlViTImageProcessor\"])\n",
      "    _import_structure[\"models.perceiver\"].extend([\"PerceiverFeatureExtractor\", \"PerceiverImageProcessor\"])\n",
      "    _import_structure[\"models.pix2struct\"].extend([\"Pix2StructImageProcessor\"])\n",
      "    _import_structure[\"models.pixtral\"].append(\"PixtralImageProcessor\")\n",
      "    _import_structure[\"models.poolformer\"].extend([\"PoolFormerFeatureExtractor\", \"PoolFormerImageProcessor\"])\n",
      "    _import_structure[\"models.prompt_depth_anything\"].extend([\"PromptDepthAnythingImageProcessor\"])\n",
      "    _import_structure[\"models.pvt\"].extend([\"PvtImageProcessor\"])\n",
      "    _import_structure[\"models.qwen2_vl\"].extend([\"Qwen2VLImageProcessor\"])\n",
      "    _import_structure[\"models.rt_detr\"].extend([\"RTDetrImageProcessor\"])\n",
      "    _import_structure[\"models.sam\"].extend([\"SamImageProcessor\"])\n",
      "    _import_structure[\"models.segformer\"].extend([\"SegformerFeatureExtractor\", \"SegformerImageProcessor\"])\n",
      "    _import_structure[\"models.seggpt\"].extend([\"SegGptImageProcessor\"])\n",
      "    _import_structure[\"models.siglip\"].append(\"SiglipImageProcessor\")\n",
      "    _import_structure[\"models.siglip2\"].append(\"Siglip2ImageProcessor\")\n",
      "    _import_structure[\"models.smolvlm\"].extend([\"SmolVLMImageProcessor\"])\n",
      "    _import_structure[\"models.superglue\"].extend([\"SuperGlueImageProcessor\"])\n",
      "    _import_structure[\"models.superpoint\"].extend([\"SuperPointImageProcessor\"])\n",
      "    _import_structure[\"models.swin2sr\"].append(\"Swin2SRImageProcessor\")\n",
      "    _import_structure[\"models.textnet\"].extend([\"TextNetImageProcessor\"])\n",
      "    _import_structure[\"models.tvp\"].append(\"TvpImageProcessor\")\n",
      "    _import_structure[\"models.video_llava\"].append(\"VideoLlavaImageProcessor\")\n",
      "    _import_structure[\"models.videomae\"].extend([\"VideoMAEFeatureExtractor\", \"VideoMAEImageProcessor\"])\n",
      "    _import_structure[\"models.vilt\"].extend([\"ViltFeatureExtractor\", \"ViltImageProcessor\", \"ViltProcessor\"])\n",
      "    _import_structure[\"models.vit\"].extend([\"ViTFeatureExtractor\", \"ViTImageProcessor\"])\n",
      "    _import_structure[\"models.vitmatte\"].append(\"VitMatteImageProcessor\")\n",
      "    _import_structure[\"models.vitpose\"].append(\"VitPoseImageProcessor\")\n",
      "    _import_structure[\"models.vivit\"].append(\"VivitImageProcessor\")\n",
      "    _import_structure[\"models.yolos\"].extend([\"YolosFeatureExtractor\", \"YolosImageProcessor\"])\n",
      "    _import_structure[\"models.zoedepth\"].append(\"ZoeDepthImageProcessor\")\n",
      "\n",
      "try:\n",
      "    if not is_torchvision_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_torchvision_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_torchvision_objects\"] = [\n",
      "        name for name in dir(dummy_torchvision_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"image_processing_utils_fast\"] = [\"BaseImageProcessorFast\"]\n",
      "    _import_structure[\"models.blip\"].append(\"BlipImageProcessorFast\")\n",
      "    _import_structure[\"models.clip\"].append(\"CLIPImageProcessorFast\")\n",
      "    _import_structure[\"models.convnext\"].append(\"ConvNextImageProcessorFast\")\n",
      "    _import_structure[\"models.deformable_detr\"].append(\"DeformableDetrImageProcessorFast\")\n",
      "    _import_structure[\"models.deit\"].append(\"DeiTImageProcessorFast\")\n",
      "    _import_structure[\"models.depth_pro\"].append(\"DepthProImageProcessorFast\")\n",
      "    _import_structure[\"models.detr\"].append(\"DetrImageProcessorFast\")\n",
      "    _import_structure[\"models.gemma3\"].append(\"Gemma3ImageProcessorFast\")\n",
      "    _import_structure[\"models.got_ocr2\"].append(\"GotOcr2ImageProcessorFast\")\n",
      "    _import_structure[\"models.llama4\"].append(\"Llama4ImageProcessorFast\")\n",
      "    _import_structure[\"models.llava\"].append(\"LlavaImageProcessorFast\")\n",
      "    _import_structure[\"models.llava_next\"].append(\"LlavaNextImageProcessorFast\")\n",
      "    _import_structure[\"models.llava_onevision\"].append(\"LlavaOnevisionImageProcessorFast\")\n",
      "    _import_structure[\"models.phi4_multimodal\"].append(\"Phi4MultimodalImageProcessorFast\")\n",
      "    _import_structure[\"models.pixtral\"].append(\"PixtralImageProcessorFast\")\n",
      "    _import_structure[\"models.qwen2_vl\"].append(\"Qwen2VLImageProcessorFast\")\n",
      "    _import_structure[\"models.rt_detr\"].append(\"RTDetrImageProcessorFast\")\n",
      "    _import_structure[\"models.siglip\"].append(\"SiglipImageProcessorFast\")\n",
      "    _import_structure[\"models.siglip2\"].append(\"Siglip2ImageProcessorFast\")\n",
      "    _import_structure[\"models.vit\"].append(\"ViTImageProcessorFast\")\n",
      "\n",
      "try:\n",
      "    if not (is_torchvision_available() and is_timm_available()):\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_timm_and_torchvision_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_timm_and_torchvision_objects\"] = [\n",
      "        name for name in dir(dummy_timm_and_torchvision_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"models.timm_wrapper\"].extend([\"TimmWrapperImageProcessor\"])\n",
      "\n",
      "# PyTorch-backed objects\n",
      "try:\n",
      "    if not is_torch_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_pt_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_pt_objects\"] = [name for name in dir(dummy_pt_objects) if not name.startswith(\"_\")]\n",
      "else:\n",
      "    _import_structure[\"model_debugging_utils\"] = [\n",
      "        \"model_addition_debugger\",\n",
      "        \"model_addition_debugger_context\",\n",
      "    ]\n",
      "    _import_structure[\"activations\"] = []\n",
      "    _import_structure[\"cache_utils\"] = [\n",
      "        \"Cache\",\n",
      "        \"CacheConfig\",\n",
      "        \"DynamicCache\",\n",
      "        \"EncoderDecoderCache\",\n",
      "        \"HQQQuantizedCache\",\n",
      "        \"HybridCache\",\n",
      "        \"MambaCache\",\n",
      "        \"OffloadedCache\",\n",
      "        \"OffloadedStaticCache\",\n",
      "        \"QuantizedCache\",\n",
      "        \"QuantizedCacheConfig\",\n",
      "        \"QuantoQuantizedCache\",\n",
      "        \"SinkCache\",\n",
      "        \"SlidingWindowCache\",\n",
      "        \"StaticCache\",\n",
      "    ]\n",
      "    _import_structure[\"data.datasets\"] = [\n",
      "        \"GlueDataset\",\n",
      "        \"GlueDataTrainingArguments\",\n",
      "        \"LineByLineTextDataset\",\n",
      "        \"LineByLineWithRefDataset\",\n",
      "        \"LineByLineWithSOPTextDataset\",\n",
      "        \"SquadDataset\",\n",
      "        \"SquadDataTrainingArguments\",\n",
      "        \"TextDataset\",\n",
      "        \"TextDatasetForNextSentencePrediction\",\n",
      "    ]\n",
      "    _import_structure[\"generation\"].extend(\n",
      "        [\n",
      "            \"AlternatingCodebooksLogitsProcessor\",\n",
      "            \"BayesianDetectorConfig\",\n",
      "            \"BayesianDetectorModel\",\n",
      "            \"BeamScorer\",\n",
      "            \"BeamSearchScorer\",\n",
      "            \"ClassifierFreeGuidanceLogitsProcessor\",\n",
      "            \"ConstrainedBeamSearchScorer\",\n",
      "            \"Constraint\",\n",
      "            \"ConstraintListState\",\n",
      "            \"DisjunctiveConstraint\",\n",
      "            \"EncoderNoRepeatNGramLogitsProcessor\",\n",
      "            \"EncoderRepetitionPenaltyLogitsProcessor\",\n",
      "            \"EosTokenCriteria\",\n",
      "            \"EpsilonLogitsWarper\",\n",
      "            \"EtaLogitsWarper\",\n",
      "            \"ExponentialDecayLengthPenalty\",\n",
      "            \"ForcedBOSTokenLogitsProcessor\",\n",
      "            \"ForcedEOSTokenLogitsProcessor\",\n",
      "            \"GenerationMixin\",\n",
      "            \"HammingDiversityLogitsProcessor\",\n",
      "            \"InfNanRemoveLogitsProcessor\",\n",
      "            \"LogitNormalization\",\n",
      "            \"LogitsProcessor\",\n",
      "            \"LogitsProcessorList\",\n",
      "            \"MaxLengthCriteria\",\n",
      "            \"MaxTimeCriteria\",\n",
      "            \"MinLengthLogitsProcessor\",\n",
      "            \"MinNewTokensLengthLogitsProcessor\",\n",
      "            \"MinPLogitsWarper\",\n",
      "            \"NoBadWordsLogitsProcessor\",\n",
      "            \"NoRepeatNGramLogitsProcessor\",\n",
      "            \"PhrasalConstraint\",\n",
      "            \"PrefixConstrainedLogitsProcessor\",\n",
      "            \"RepetitionPenaltyLogitsProcessor\",\n",
      "            \"SequenceBiasLogitsProcessor\",\n",
      "            \"StoppingCriteria\",\n",
      "            \"StoppingCriteriaList\",\n",
      "            \"StopStringCriteria\",\n",
      "            \"SuppressTokensAtBeginLogitsProcessor\",\n",
      "            \"SuppressTokensLogitsProcessor\",\n",
      "            \"SynthIDTextWatermarkDetector\",\n",
      "            \"SynthIDTextWatermarkingConfig\",\n",
      "            \"SynthIDTextWatermarkLogitsProcessor\",\n",
      "            \"TemperatureLogitsWarper\",\n",
      "            \"TopKLogitsWarper\",\n",
      "            \"TopPLogitsWarper\",\n",
      "            \"TypicalLogitsWarper\",\n",
      "            \"UnbatchedClassifierFreeGuidanceLogitsProcessor\",\n",
      "            \"WatermarkDetector\",\n",
      "            \"WatermarkLogitsProcessor\",\n",
      "            \"WhisperTimeStampLogitsProcessor\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    # PyTorch domain libraries integration\n",
      "    _import_structure[\"integrations.executorch\"] = [\n",
      "        \"TorchExportableModuleWithStaticCache\",\n",
      "        \"convert_and_export_with_cache\",\n",
      "    ]\n",
      "\n",
      "    _import_structure[\"modeling_flash_attention_utils\"] = []\n",
      "    _import_structure[\"modeling_outputs\"] = []\n",
      "    _import_structure[\"modeling_rope_utils\"] = [\"ROPE_INIT_FUNCTIONS\", \"dynamic_rope_update\"]\n",
      "    _import_structure[\"modeling_utils\"] = [\"PreTrainedModel\", \"AttentionInterface\"]\n",
      "\n",
      "    # PyTorch models structure\n",
      "\n",
      "    _import_structure[\"models.albert\"].extend(\n",
      "        [\n",
      "            \"AlbertForMaskedLM\",\n",
      "            \"AlbertForMultipleChoice\",\n",
      "            \"AlbertForPreTraining\",\n",
      "            \"AlbertForQuestionAnswering\",\n",
      "            \"AlbertForSequenceClassification\",\n",
      "            \"AlbertForTokenClassification\",\n",
      "            \"AlbertModel\",\n",
      "            \"AlbertPreTrainedModel\",\n",
      "            \"load_tf_weights_in_albert\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    _import_structure[\"models.align\"].extend(\n",
      "        [\n",
      "            \"AlignModel\",\n",
      "            \"AlignPreTrainedModel\",\n",
      "            \"AlignTextModel\",\n",
      "            \"AlignVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.altclip\"].extend(\n",
      "        [\n",
      "            \"AltCLIPModel\",\n",
      "            \"AltCLIPPreTrainedModel\",\n",
      "            \"AltCLIPTextModel\",\n",
      "            \"AltCLIPVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.aria\"].extend(\n",
      "        [\n",
      "            \"AriaForConditionalGeneration\",\n",
      "            \"AriaPreTrainedModel\",\n",
      "            \"AriaTextForCausalLM\",\n",
      "            \"AriaTextModel\",\n",
      "            \"AriaTextPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.audio_spectrogram_transformer\"].extend(\n",
      "        [\n",
      "            \"ASTForAudioClassification\",\n",
      "            \"ASTModel\",\n",
      "            \"ASTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.auto\"].extend(\n",
      "        [\n",
      "            \"MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_AUDIO_XVECTOR_MAPPING\",\n",
      "            \"MODEL_FOR_BACKBONE_MAPPING\",\n",
      "            \"MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING\",\n",
      "            \"MODEL_FOR_CAUSAL_LM_MAPPING\",\n",
      "            \"MODEL_FOR_CTC_MAPPING\",\n",
      "            \"MODEL_FOR_DEPTH_ESTIMATION_MAPPING\",\n",
      "            \"MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_IMAGE_MAPPING\",\n",
      "            \"MODEL_FOR_IMAGE_SEGMENTATION_MAPPING\",\n",
      "            \"MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING\",\n",
      "            \"MODEL_FOR_IMAGE_TO_IMAGE_MAPPING\",\n",
      "            \"MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING\",\n",
      "            \"MODEL_FOR_KEYPOINT_DETECTION_MAPPING\",\n",
      "            \"MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING\",\n",
      "            \"MODEL_FOR_MASKED_LM_MAPPING\",\n",
      "            \"MODEL_FOR_MASK_GENERATION_MAPPING\",\n",
      "            \"MODEL_FOR_MULTIPLE_CHOICE_MAPPING\",\n",
      "            \"MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING\",\n",
      "            \"MODEL_FOR_OBJECT_DETECTION_MAPPING\",\n",
      "            \"MODEL_FOR_PRETRAINING_MAPPING\",\n",
      "            \"MODEL_FOR_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"MODEL_FOR_RETRIEVAL_MAPPING\",\n",
      "            \"MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING\",\n",
      "            \"MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING\",\n",
      "            \"MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING\",\n",
      "            \"MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"MODEL_FOR_TEXT_ENCODING_MAPPING\",\n",
      "            \"MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING\",\n",
      "            \"MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING\",\n",
      "            \"MODEL_FOR_TIME_SERIES_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_TIME_SERIES_REGRESSION_MAPPING\",\n",
      "            \"MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING\",\n",
      "            \"MODEL_FOR_VIDEO_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_VISION_2_SEQ_MAPPING\",\n",
      "            \"MODEL_FOR_VISUAL_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING\",\n",
      "            \"MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING\",\n",
      "            \"MODEL_MAPPING\",\n",
      "            \"MODEL_WITH_LM_HEAD_MAPPING\",\n",
      "            \"AutoBackbone\",\n",
      "            \"AutoModel\",\n",
      "            \"AutoModelForAudioClassification\",\n",
      "            \"AutoModelForAudioFrameClassification\",\n",
      "            \"AutoModelForAudioXVector\",\n",
      "            \"AutoModelForCausalLM\",\n",
      "            \"AutoModelForCTC\",\n",
      "            \"AutoModelForDepthEstimation\",\n",
      "            \"AutoModelForDocumentQuestionAnswering\",\n",
      "            \"AutoModelForImageClassification\",\n",
      "            \"AutoModelForImageSegmentation\",\n",
      "            \"AutoModelForImageTextToText\",\n",
      "            \"AutoModelForImageToImage\",\n",
      "            \"AutoModelForInstanceSegmentation\",\n",
      "            \"AutoModelForKeypointDetection\",\n",
      "            \"AutoModelForMaskedImageModeling\",\n",
      "            \"AutoModelForMaskedLM\",\n",
      "            \"AutoModelForMaskGeneration\",\n",
      "            \"AutoModelForMultipleChoice\",\n",
      "            \"AutoModelForNextSentencePrediction\",\n",
      "            \"AutoModelForObjectDetection\",\n",
      "            \"AutoModelForPreTraining\",\n",
      "            \"AutoModelForQuestionAnswering\",\n",
      "            \"AutoModelForSemanticSegmentation\",\n",
      "            \"AutoModelForSeq2SeqLM\",\n",
      "            \"AutoModelForSequenceClassification\",\n",
      "            \"AutoModelForSpeechSeq2Seq\",\n",
      "            \"AutoModelForTableQuestionAnswering\",\n",
      "            \"AutoModelForTextEncoding\",\n",
      "            \"AutoModelForTextToSpectrogram\",\n",
      "            \"AutoModelForTextToWaveform\",\n",
      "            \"AutoModelForTokenClassification\",\n",
      "            \"AutoModelForUniversalSegmentation\",\n",
      "            \"AutoModelForVideoClassification\",\n",
      "            \"AutoModelForVision2Seq\",\n",
      "            \"AutoModelForVisualQuestionAnswering\",\n",
      "            \"AutoModelForZeroShotImageClassification\",\n",
      "            \"AutoModelForZeroShotObjectDetection\",\n",
      "            \"AutoModelWithLMHead\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.autoformer\"].extend(\n",
      "        [\n",
      "            \"AutoformerForPrediction\",\n",
      "            \"AutoformerModel\",\n",
      "            \"AutoformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.aya_vision\"].extend([\"AyaVisionForConditionalGeneration\", \"AyaVisionPreTrainedModel\"])\n",
      "    _import_structure[\"models.bamba\"].extend(\n",
      "        [\n",
      "            \"BambaForCausalLM\",\n",
      "            \"BambaModel\",\n",
      "            \"BambaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bark\"].extend(\n",
      "        [\n",
      "            \"BarkCausalModel\",\n",
      "            \"BarkCoarseModel\",\n",
      "            \"BarkFineModel\",\n",
      "            \"BarkModel\",\n",
      "            \"BarkPreTrainedModel\",\n",
      "            \"BarkSemanticModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bart\"].extend(\n",
      "        [\n",
      "            \"BartForCausalLM\",\n",
      "            \"BartForConditionalGeneration\",\n",
      "            \"BartForQuestionAnswering\",\n",
      "            \"BartForSequenceClassification\",\n",
      "            \"BartModel\",\n",
      "            \"BartPretrainedModel\",\n",
      "            \"BartPreTrainedModel\",\n",
      "            \"PretrainedBartModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.beit\"].extend(\n",
      "        [\n",
      "            \"BeitBackbone\",\n",
      "            \"BeitForImageClassification\",\n",
      "            \"BeitForMaskedImageModeling\",\n",
      "            \"BeitForSemanticSegmentation\",\n",
      "            \"BeitModel\",\n",
      "            \"BeitPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bert\"].extend(\n",
      "        [\n",
      "            \"BertForMaskedLM\",\n",
      "            \"BertForMultipleChoice\",\n",
      "            \"BertForNextSentencePrediction\",\n",
      "            \"BertForPreTraining\",\n",
      "            \"BertForQuestionAnswering\",\n",
      "            \"BertForSequenceClassification\",\n",
      "            \"BertForTokenClassification\",\n",
      "            \"BertLMHeadModel\",\n",
      "            \"BertModel\",\n",
      "            \"BertPreTrainedModel\",\n",
      "            \"load_tf_weights_in_bert\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bert_generation\"].extend(\n",
      "        [\n",
      "            \"BertGenerationDecoder\",\n",
      "            \"BertGenerationEncoder\",\n",
      "            \"BertGenerationPreTrainedModel\",\n",
      "            \"load_tf_weights_in_bert_generation\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.big_bird\"].extend(\n",
      "        [\n",
      "            \"BigBirdForCausalLM\",\n",
      "            \"BigBirdForMaskedLM\",\n",
      "            \"BigBirdForMultipleChoice\",\n",
      "            \"BigBirdForPreTraining\",\n",
      "            \"BigBirdForQuestionAnswering\",\n",
      "            \"BigBirdForSequenceClassification\",\n",
      "            \"BigBirdForTokenClassification\",\n",
      "            \"BigBirdModel\",\n",
      "            \"BigBirdPreTrainedModel\",\n",
      "            \"load_tf_weights_in_big_bird\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bigbird_pegasus\"].extend(\n",
      "        [\n",
      "            \"BigBirdPegasusForCausalLM\",\n",
      "            \"BigBirdPegasusForConditionalGeneration\",\n",
      "            \"BigBirdPegasusForQuestionAnswering\",\n",
      "            \"BigBirdPegasusForSequenceClassification\",\n",
      "            \"BigBirdPegasusModel\",\n",
      "            \"BigBirdPegasusPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.biogpt\"].extend(\n",
      "        [\n",
      "            \"BioGptForCausalLM\",\n",
      "            \"BioGptForSequenceClassification\",\n",
      "            \"BioGptForTokenClassification\",\n",
      "            \"BioGptModel\",\n",
      "            \"BioGptPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bit\"].extend(\n",
      "        [\n",
      "            \"BitBackbone\",\n",
      "            \"BitForImageClassification\",\n",
      "            \"BitModel\",\n",
      "            \"BitPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blenderbot\"].extend(\n",
      "        [\n",
      "            \"BlenderbotForCausalLM\",\n",
      "            \"BlenderbotForConditionalGeneration\",\n",
      "            \"BlenderbotModel\",\n",
      "            \"BlenderbotPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blenderbot_small\"].extend(\n",
      "        [\n",
      "            \"BlenderbotSmallForCausalLM\",\n",
      "            \"BlenderbotSmallForConditionalGeneration\",\n",
      "            \"BlenderbotSmallModel\",\n",
      "            \"BlenderbotSmallPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blip\"].extend(\n",
      "        [\n",
      "            \"BlipForConditionalGeneration\",\n",
      "            \"BlipForImageTextRetrieval\",\n",
      "            \"BlipForQuestionAnswering\",\n",
      "            \"BlipModel\",\n",
      "            \"BlipPreTrainedModel\",\n",
      "            \"BlipTextModel\",\n",
      "            \"BlipVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blip_2\"].extend(\n",
      "        [\n",
      "            \"Blip2ForConditionalGeneration\",\n",
      "            \"Blip2ForImageTextRetrieval\",\n",
      "            \"Blip2Model\",\n",
      "            \"Blip2PreTrainedModel\",\n",
      "            \"Blip2QFormerModel\",\n",
      "            \"Blip2TextModelWithProjection\",\n",
      "            \"Blip2VisionModel\",\n",
      "            \"Blip2VisionModelWithProjection\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bloom\"].extend(\n",
      "        [\n",
      "            \"BloomForCausalLM\",\n",
      "            \"BloomForQuestionAnswering\",\n",
      "            \"BloomForSequenceClassification\",\n",
      "            \"BloomForTokenClassification\",\n",
      "            \"BloomModel\",\n",
      "            \"BloomPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bridgetower\"].extend(\n",
      "        [\n",
      "            \"BridgeTowerForContrastiveLearning\",\n",
      "            \"BridgeTowerForImageAndTextRetrieval\",\n",
      "            \"BridgeTowerForMaskedLM\",\n",
      "            \"BridgeTowerModel\",\n",
      "            \"BridgeTowerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bros\"].extend(\n",
      "        [\n",
      "            \"BrosForTokenClassification\",\n",
      "            \"BrosModel\",\n",
      "            \"BrosPreTrainedModel\",\n",
      "            \"BrosProcessor\",\n",
      "            \"BrosSpadeEEForTokenClassification\",\n",
      "            \"BrosSpadeELForTokenClassification\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.camembert\"].extend(\n",
      "        [\n",
      "            \"CamembertForCausalLM\",\n",
      "            \"CamembertForMaskedLM\",\n",
      "            \"CamembertForMultipleChoice\",\n",
      "            \"CamembertForQuestionAnswering\",\n",
      "            \"CamembertForSequenceClassification\",\n",
      "            \"CamembertForTokenClassification\",\n",
      "            \"CamembertModel\",\n",
      "            \"CamembertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.canine\"].extend(\n",
      "        [\n",
      "            \"CanineForMultipleChoice\",\n",
      "            \"CanineForQuestionAnswering\",\n",
      "            \"CanineForSequenceClassification\",\n",
      "            \"CanineForTokenClassification\",\n",
      "            \"CanineModel\",\n",
      "            \"CaninePreTrainedModel\",\n",
      "            \"load_tf_weights_in_canine\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.chameleon\"].extend(\n",
      "        [\n",
      "            \"ChameleonForConditionalGeneration\",\n",
      "            \"ChameleonModel\",\n",
      "            \"ChameleonPreTrainedModel\",\n",
      "            \"ChameleonProcessor\",\n",
      "            \"ChameleonVQVAE\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.chinese_clip\"].extend(\n",
      "        [\n",
      "            \"ChineseCLIPModel\",\n",
      "            \"ChineseCLIPPreTrainedModel\",\n",
      "            \"ChineseCLIPTextModel\",\n",
      "            \"ChineseCLIPVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.clap\"].extend(\n",
      "        [\n",
      "            \"ClapAudioModel\",\n",
      "            \"ClapAudioModelWithProjection\",\n",
      "            \"ClapFeatureExtractor\",\n",
      "            \"ClapModel\",\n",
      "            \"ClapPreTrainedModel\",\n",
      "            \"ClapTextModel\",\n",
      "            \"ClapTextModelWithProjection\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.clip\"].extend(\n",
      "        [\n",
      "            \"CLIPForImageClassification\",\n",
      "            \"CLIPModel\",\n",
      "            \"CLIPPreTrainedModel\",\n",
      "            \"CLIPTextModel\",\n",
      "            \"CLIPTextModelWithProjection\",\n",
      "            \"CLIPVisionModel\",\n",
      "            \"CLIPVisionModelWithProjection\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.clipseg\"].extend(\n",
      "        [\n",
      "            \"CLIPSegForImageSegmentation\",\n",
      "            \"CLIPSegModel\",\n",
      "            \"CLIPSegPreTrainedModel\",\n",
      "            \"CLIPSegTextModel\",\n",
      "            \"CLIPSegVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.clvp\"].extend(\n",
      "        [\n",
      "            \"ClvpDecoder\",\n",
      "            \"ClvpEncoder\",\n",
      "            \"ClvpForCausalLM\",\n",
      "            \"ClvpModel\",\n",
      "            \"ClvpModelForConditionalGeneration\",\n",
      "            \"ClvpPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.codegen\"].extend(\n",
      "        [\n",
      "            \"CodeGenForCausalLM\",\n",
      "            \"CodeGenModel\",\n",
      "            \"CodeGenPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.cohere\"].extend([\"CohereForCausalLM\", \"CohereModel\", \"CoherePreTrainedModel\"])\n",
      "    _import_structure[\"models.cohere2\"].extend([\"Cohere2ForCausalLM\", \"Cohere2Model\", \"Cohere2PreTrainedModel\"])\n",
      "    _import_structure[\"models.colpali\"].extend(\n",
      "        [\n",
      "            \"ColPaliForRetrieval\",\n",
      "            \"ColPaliPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.conditional_detr\"].extend(\n",
      "        [\n",
      "            \"ConditionalDetrForObjectDetection\",\n",
      "            \"ConditionalDetrForSegmentation\",\n",
      "            \"ConditionalDetrModel\",\n",
      "            \"ConditionalDetrPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.convbert\"].extend(\n",
      "        [\n",
      "            \"ConvBertForMaskedLM\",\n",
      "            \"ConvBertForMultipleChoice\",\n",
      "            \"ConvBertForQuestionAnswering\",\n",
      "            \"ConvBertForSequenceClassification\",\n",
      "            \"ConvBertForTokenClassification\",\n",
      "            \"ConvBertModel\",\n",
      "            \"ConvBertPreTrainedModel\",\n",
      "            \"load_tf_weights_in_convbert\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.convnext\"].extend(\n",
      "        [\n",
      "            \"ConvNextBackbone\",\n",
      "            \"ConvNextForImageClassification\",\n",
      "            \"ConvNextModel\",\n",
      "            \"ConvNextPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.convnextv2\"].extend(\n",
      "        [\n",
      "            \"ConvNextV2Backbone\",\n",
      "            \"ConvNextV2ForImageClassification\",\n",
      "            \"ConvNextV2Model\",\n",
      "            \"ConvNextV2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.cpmant\"].extend(\n",
      "        [\n",
      "            \"CpmAntForCausalLM\",\n",
      "            \"CpmAntModel\",\n",
      "            \"CpmAntPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.ctrl\"].extend(\n",
      "        [\n",
      "            \"CTRLForSequenceClassification\",\n",
      "            \"CTRLLMHeadModel\",\n",
      "            \"CTRLModel\",\n",
      "            \"CTRLPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.cvt\"].extend(\n",
      "        [\n",
      "            \"CvtForImageClassification\",\n",
      "            \"CvtModel\",\n",
      "            \"CvtPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dab_detr\"].extend(\n",
      "        [\n",
      "            \"DabDetrForObjectDetection\",\n",
      "            \"DabDetrModel\",\n",
      "            \"DabDetrPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dac\"].extend(\n",
      "        [\n",
      "            \"DacModel\",\n",
      "            \"DacPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.data2vec\"].extend(\n",
      "        [\n",
      "            \"Data2VecAudioForAudioFrameClassification\",\n",
      "            \"Data2VecAudioForCTC\",\n",
      "            \"Data2VecAudioForSequenceClassification\",\n",
      "            \"Data2VecAudioForXVector\",\n",
      "            \"Data2VecAudioModel\",\n",
      "            \"Data2VecAudioPreTrainedModel\",\n",
      "            \"Data2VecTextForCausalLM\",\n",
      "            \"Data2VecTextForMaskedLM\",\n",
      "            \"Data2VecTextForMultipleChoice\",\n",
      "            \"Data2VecTextForQuestionAnswering\",\n",
      "            \"Data2VecTextForSequenceClassification\",\n",
      "            \"Data2VecTextForTokenClassification\",\n",
      "            \"Data2VecTextModel\",\n",
      "            \"Data2VecTextPreTrainedModel\",\n",
      "            \"Data2VecVisionForImageClassification\",\n",
      "            \"Data2VecVisionForSemanticSegmentation\",\n",
      "            \"Data2VecVisionModel\",\n",
      "            \"Data2VecVisionPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dbrx\"].extend(\n",
      "        [\n",
      "            \"DbrxForCausalLM\",\n",
      "            \"DbrxModel\",\n",
      "            \"DbrxPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deberta\"].extend(\n",
      "        [\n",
      "            \"DebertaForMaskedLM\",\n",
      "            \"DebertaForQuestionAnswering\",\n",
      "            \"DebertaForSequenceClassification\",\n",
      "            \"DebertaForTokenClassification\",\n",
      "            \"DebertaModel\",\n",
      "            \"DebertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deberta_v2\"].extend(\n",
      "        [\n",
      "            \"DebertaV2ForMaskedLM\",\n",
      "            \"DebertaV2ForMultipleChoice\",\n",
      "            \"DebertaV2ForQuestionAnswering\",\n",
      "            \"DebertaV2ForSequenceClassification\",\n",
      "            \"DebertaV2ForTokenClassification\",\n",
      "            \"DebertaV2Model\",\n",
      "            \"DebertaV2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.decision_transformer\"].extend(\n",
      "        [\n",
      "            \"DecisionTransformerGPT2Model\",\n",
      "            \"DecisionTransformerGPT2PreTrainedModel\",\n",
      "            \"DecisionTransformerModel\",\n",
      "            \"DecisionTransformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deepseek_v3\"].extend(\n",
      "        [\n",
      "            \"DeepseekV3ForCausalLM\",\n",
      "            \"DeepseekV3Model\",\n",
      "            \"DeepseekV3PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deformable_detr\"].extend(\n",
      "        [\n",
      "            \"DeformableDetrForObjectDetection\",\n",
      "            \"DeformableDetrModel\",\n",
      "            \"DeformableDetrPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deit\"].extend(\n",
      "        [\n",
      "            \"DeiTForImageClassification\",\n",
      "            \"DeiTForImageClassificationWithTeacher\",\n",
      "            \"DeiTForMaskedImageModeling\",\n",
      "            \"DeiTModel\",\n",
      "            \"DeiTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.deta\"].extend(\n",
      "        [\n",
      "            \"DetaForObjectDetection\",\n",
      "            \"DetaModel\",\n",
      "            \"DetaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.efficientformer\"].extend(\n",
      "        [\n",
      "            \"EfficientFormerForImageClassification\",\n",
      "            \"EfficientFormerForImageClassificationWithTeacher\",\n",
      "            \"EfficientFormerModel\",\n",
      "            \"EfficientFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.ernie_m\"].extend(\n",
      "        [\n",
      "            \"ErnieMForInformationExtraction\",\n",
      "            \"ErnieMForMultipleChoice\",\n",
      "            \"ErnieMForQuestionAnswering\",\n",
      "            \"ErnieMForSequenceClassification\",\n",
      "            \"ErnieMForTokenClassification\",\n",
      "            \"ErnieMModel\",\n",
      "            \"ErnieMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.gptsan_japanese\"].extend(\n",
      "        [\n",
      "            \"GPTSanJapaneseForConditionalGeneration\",\n",
      "            \"GPTSanJapaneseModel\",\n",
      "            \"GPTSanJapanesePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.graphormer\"].extend(\n",
      "        [\n",
      "            \"GraphormerForGraphClassification\",\n",
      "            \"GraphormerModel\",\n",
      "            \"GraphormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.jukebox\"].extend(\n",
      "        [\n",
      "            \"JukeboxModel\",\n",
      "            \"JukeboxPreTrainedModel\",\n",
      "            \"JukeboxPrior\",\n",
      "            \"JukeboxVQVAE\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.mctct\"].extend(\n",
      "        [\n",
      "            \"MCTCTForCTC\",\n",
      "            \"MCTCTModel\",\n",
      "            \"MCTCTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.mega\"].extend(\n",
      "        [\n",
      "            \"MegaForCausalLM\",\n",
      "            \"MegaForMaskedLM\",\n",
      "            \"MegaForMultipleChoice\",\n",
      "            \"MegaForQuestionAnswering\",\n",
      "            \"MegaForSequenceClassification\",\n",
      "            \"MegaForTokenClassification\",\n",
      "            \"MegaModel\",\n",
      "            \"MegaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.mmbt\"].extend([\"MMBTForClassification\", \"MMBTModel\", \"ModalEmbeddings\"])\n",
      "    _import_structure[\"models.deprecated.nat\"].extend(\n",
      "        [\n",
      "            \"NatBackbone\",\n",
      "            \"NatForImageClassification\",\n",
      "            \"NatModel\",\n",
      "            \"NatPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.nezha\"].extend(\n",
      "        [\n",
      "            \"NezhaForMaskedLM\",\n",
      "            \"NezhaForMultipleChoice\",\n",
      "            \"NezhaForNextSentencePrediction\",\n",
      "            \"NezhaForPreTraining\",\n",
      "            \"NezhaForQuestionAnswering\",\n",
      "            \"NezhaForSequenceClassification\",\n",
      "            \"NezhaForTokenClassification\",\n",
      "            \"NezhaModel\",\n",
      "            \"NezhaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.open_llama\"].extend(\n",
      "        [\n",
      "            \"OpenLlamaForCausalLM\",\n",
      "            \"OpenLlamaForSequenceClassification\",\n",
      "            \"OpenLlamaModel\",\n",
      "            \"OpenLlamaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.qdqbert\"].extend(\n",
      "        [\n",
      "            \"QDQBertForMaskedLM\",\n",
      "            \"QDQBertForMultipleChoice\",\n",
      "            \"QDQBertForNextSentencePrediction\",\n",
      "            \"QDQBertForQuestionAnswering\",\n",
      "            \"QDQBertForSequenceClassification\",\n",
      "            \"QDQBertForTokenClassification\",\n",
      "            \"QDQBertLMHeadModel\",\n",
      "            \"QDQBertModel\",\n",
      "            \"QDQBertPreTrainedModel\",\n",
      "            \"load_tf_weights_in_qdqbert\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.realm\"].extend(\n",
      "        [\n",
      "            \"RealmEmbedder\",\n",
      "            \"RealmForOpenQA\",\n",
      "            \"RealmKnowledgeAugEncoder\",\n",
      "            \"RealmPreTrainedModel\",\n",
      "            \"RealmReader\",\n",
      "            \"RealmRetriever\",\n",
      "            \"RealmScorer\",\n",
      "            \"load_tf_weights_in_realm\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.retribert\"].extend(\n",
      "        [\n",
      "            \"RetriBertModel\",\n",
      "            \"RetriBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.speech_to_text_2\"].extend(\n",
      "        [\"Speech2Text2ForCausalLM\", \"Speech2Text2PreTrainedModel\"]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.trajectory_transformer\"].extend(\n",
      "        [\n",
      "            \"TrajectoryTransformerModel\",\n",
      "            \"TrajectoryTransformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.transfo_xl\"].extend(\n",
      "        [\n",
      "            \"AdaptiveEmbedding\",\n",
      "            \"TransfoXLForSequenceClassification\",\n",
      "            \"TransfoXLLMHeadModel\",\n",
      "            \"TransfoXLModel\",\n",
      "            \"TransfoXLPreTrainedModel\",\n",
      "            \"load_tf_weights_in_transfo_xl\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.tvlt\"].extend(\n",
      "        [\n",
      "            \"TvltForAudioVisualClassification\",\n",
      "            \"TvltForPreTraining\",\n",
      "            \"TvltModel\",\n",
      "            \"TvltPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.van\"].extend(\n",
      "        [\n",
      "            \"VanForImageClassification\",\n",
      "            \"VanModel\",\n",
      "            \"VanPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.vit_hybrid\"].extend(\n",
      "        [\n",
      "            \"ViTHybridForImageClassification\",\n",
      "            \"ViTHybridModel\",\n",
      "            \"ViTHybridPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.xlm_prophetnet\"].extend(\n",
      "        [\n",
      "            \"XLMProphetNetDecoder\",\n",
      "            \"XLMProphetNetEncoder\",\n",
      "            \"XLMProphetNetForCausalLM\",\n",
      "            \"XLMProphetNetForConditionalGeneration\",\n",
      "            \"XLMProphetNetModel\",\n",
      "            \"XLMProphetNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.depth_anything\"].extend(\n",
      "        [\n",
      "            \"DepthAnythingForDepthEstimation\",\n",
      "            \"DepthAnythingPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.depth_pro\"].extend(\n",
      "        [\n",
      "            \"DepthProForDepthEstimation\",\n",
      "            \"DepthProModel\",\n",
      "            \"DepthProPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.detr\"].extend(\n",
      "        [\n",
      "            \"DetrForObjectDetection\",\n",
      "            \"DetrForSegmentation\",\n",
      "            \"DetrModel\",\n",
      "            \"DetrPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.diffllama\"].extend(\n",
      "        [\n",
      "            \"DiffLlamaForCausalLM\",\n",
      "            \"DiffLlamaForQuestionAnswering\",\n",
      "            \"DiffLlamaForSequenceClassification\",\n",
      "            \"DiffLlamaForTokenClassification\",\n",
      "            \"DiffLlamaModel\",\n",
      "            \"DiffLlamaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dinat\"].extend(\n",
      "        [\n",
      "            \"DinatBackbone\",\n",
      "            \"DinatForImageClassification\",\n",
      "            \"DinatModel\",\n",
      "            \"DinatPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dinov2\"].extend(\n",
      "        [\n",
      "            \"Dinov2Backbone\",\n",
      "            \"Dinov2ForImageClassification\",\n",
      "            \"Dinov2Model\",\n",
      "            \"Dinov2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dinov2_with_registers\"].extend(\n",
      "        [\n",
      "            \"Dinov2WithRegistersBackbone\",\n",
      "            \"Dinov2WithRegistersForImageClassification\",\n",
      "            \"Dinov2WithRegistersModel\",\n",
      "            \"Dinov2WithRegistersPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.distilbert\"].extend(\n",
      "        [\n",
      "            \"DistilBertForMaskedLM\",\n",
      "            \"DistilBertForMultipleChoice\",\n",
      "            \"DistilBertForQuestionAnswering\",\n",
      "            \"DistilBertForSequenceClassification\",\n",
      "            \"DistilBertForTokenClassification\",\n",
      "            \"DistilBertModel\",\n",
      "            \"DistilBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.donut\"].extend(\n",
      "        [\n",
      "            \"DonutSwinModel\",\n",
      "            \"DonutSwinPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dpr\"].extend(\n",
      "        [\n",
      "            \"DPRContextEncoder\",\n",
      "            \"DPRPretrainedContextEncoder\",\n",
      "            \"DPRPreTrainedModel\",\n",
      "            \"DPRPretrainedQuestionEncoder\",\n",
      "            \"DPRPretrainedReader\",\n",
      "            \"DPRQuestionEncoder\",\n",
      "            \"DPRReader\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dpt\"].extend(\n",
      "        [\n",
      "            \"DPTForDepthEstimation\",\n",
      "            \"DPTForSemanticSegmentation\",\n",
      "            \"DPTModel\",\n",
      "            \"DPTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.efficientnet\"].extend(\n",
      "        [\n",
      "            \"EfficientNetForImageClassification\",\n",
      "            \"EfficientNetModel\",\n",
      "            \"EfficientNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.electra\"].extend(\n",
      "        [\n",
      "            \"ElectraForCausalLM\",\n",
      "            \"ElectraForMaskedLM\",\n",
      "            \"ElectraForMultipleChoice\",\n",
      "            \"ElectraForPreTraining\",\n",
      "            \"ElectraForQuestionAnswering\",\n",
      "            \"ElectraForSequenceClassification\",\n",
      "            \"ElectraForTokenClassification\",\n",
      "            \"ElectraModel\",\n",
      "            \"ElectraPreTrainedModel\",\n",
      "            \"load_tf_weights_in_electra\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.emu3\"].extend(\n",
      "        [\n",
      "            \"Emu3ForCausalLM\",\n",
      "            \"Emu3ForConditionalGeneration\",\n",
      "            \"Emu3PreTrainedModel\",\n",
      "            \"Emu3TextModel\",\n",
      "            \"Emu3VQVAE\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.encodec\"].extend(\n",
      "        [\n",
      "            \"EncodecModel\",\n",
      "            \"EncodecPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.encoder_decoder\"].append(\"EncoderDecoderModel\")\n",
      "    _import_structure[\"models.ernie\"].extend(\n",
      "        [\n",
      "            \"ErnieForCausalLM\",\n",
      "            \"ErnieForMaskedLM\",\n",
      "            \"ErnieForMultipleChoice\",\n",
      "            \"ErnieForNextSentencePrediction\",\n",
      "            \"ErnieForPreTraining\",\n",
      "            \"ErnieForQuestionAnswering\",\n",
      "            \"ErnieForSequenceClassification\",\n",
      "            \"ErnieForTokenClassification\",\n",
      "            \"ErnieModel\",\n",
      "            \"ErniePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.esm\"].extend(\n",
      "        [\n",
      "            \"EsmFoldPreTrainedModel\",\n",
      "            \"EsmForMaskedLM\",\n",
      "            \"EsmForProteinFolding\",\n",
      "            \"EsmForSequenceClassification\",\n",
      "            \"EsmForTokenClassification\",\n",
      "            \"EsmModel\",\n",
      "            \"EsmPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.falcon\"].extend(\n",
      "        [\n",
      "            \"FalconForCausalLM\",\n",
      "            \"FalconForQuestionAnswering\",\n",
      "            \"FalconForSequenceClassification\",\n",
      "            \"FalconForTokenClassification\",\n",
      "            \"FalconModel\",\n",
      "            \"FalconPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.falcon_mamba\"].extend(\n",
      "        [\n",
      "            \"FalconMambaForCausalLM\",\n",
      "            \"FalconMambaModel\",\n",
      "            \"FalconMambaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.fastspeech2_conformer\"].extend(\n",
      "        [\n",
      "            \"FastSpeech2ConformerHifiGan\",\n",
      "            \"FastSpeech2ConformerModel\",\n",
      "            \"FastSpeech2ConformerPreTrainedModel\",\n",
      "            \"FastSpeech2ConformerWithHifiGan\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.flaubert\"].extend(\n",
      "        [\n",
      "            \"FlaubertForMultipleChoice\",\n",
      "            \"FlaubertForQuestionAnswering\",\n",
      "            \"FlaubertForQuestionAnsweringSimple\",\n",
      "            \"FlaubertForSequenceClassification\",\n",
      "            \"FlaubertForTokenClassification\",\n",
      "            \"FlaubertModel\",\n",
      "            \"FlaubertPreTrainedModel\",\n",
      "            \"FlaubertWithLMHeadModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.flava\"].extend(\n",
      "        [\n",
      "            \"FlavaForPreTraining\",\n",
      "            \"FlavaImageCodebook\",\n",
      "            \"FlavaImageModel\",\n",
      "            \"FlavaModel\",\n",
      "            \"FlavaMultimodalModel\",\n",
      "            \"FlavaPreTrainedModel\",\n",
      "            \"FlavaTextModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.fnet\"].extend(\n",
      "        [\n",
      "            \"FNetForMaskedLM\",\n",
      "            \"FNetForMultipleChoice\",\n",
      "            \"FNetForNextSentencePrediction\",\n",
      "            \"FNetForPreTraining\",\n",
      "            \"FNetForQuestionAnswering\",\n",
      "            \"FNetForSequenceClassification\",\n",
      "            \"FNetForTokenClassification\",\n",
      "            \"FNetModel\",\n",
      "            \"FNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.focalnet\"].extend(\n",
      "        [\n",
      "            \"FocalNetBackbone\",\n",
      "            \"FocalNetForImageClassification\",\n",
      "            \"FocalNetForMaskedImageModeling\",\n",
      "            \"FocalNetModel\",\n",
      "            \"FocalNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.fsmt\"].extend([\"FSMTForConditionalGeneration\", \"FSMTModel\", \"PretrainedFSMTModel\"])\n",
      "    _import_structure[\"models.funnel\"].extend(\n",
      "        [\n",
      "            \"FunnelBaseModel\",\n",
      "            \"FunnelForMaskedLM\",\n",
      "            \"FunnelForMultipleChoice\",\n",
      "            \"FunnelForPreTraining\",\n",
      "            \"FunnelForQuestionAnswering\",\n",
      "            \"FunnelForSequenceClassification\",\n",
      "            \"FunnelForTokenClassification\",\n",
      "            \"FunnelModel\",\n",
      "            \"FunnelPreTrainedModel\",\n",
      "            \"load_tf_weights_in_funnel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.fuyu\"].extend([\"FuyuForCausalLM\", \"FuyuPreTrainedModel\"])\n",
      "    _import_structure[\"models.gemma\"].extend(\n",
      "        [\n",
      "            \"GemmaForCausalLM\",\n",
      "            \"GemmaForSequenceClassification\",\n",
      "            \"GemmaForTokenClassification\",\n",
      "            \"GemmaModel\",\n",
      "            \"GemmaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gemma2\"].extend(\n",
      "        [\n",
      "            \"Gemma2ForCausalLM\",\n",
      "            \"Gemma2ForSequenceClassification\",\n",
      "            \"Gemma2ForTokenClassification\",\n",
      "            \"Gemma2Model\",\n",
      "            \"Gemma2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gemma3\"].extend(\n",
      "        [\n",
      "            \"Gemma3ForCausalLM\",\n",
      "            \"Gemma3ForConditionalGeneration\",\n",
      "            \"Gemma3PreTrainedModel\",\n",
      "            \"Gemma3TextModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.git\"].extend(\n",
      "        [\n",
      "            \"GitForCausalLM\",\n",
      "            \"GitModel\",\n",
      "            \"GitPreTrainedModel\",\n",
      "            \"GitVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.glm\"].extend(\n",
      "        [\n",
      "            \"GlmForCausalLM\",\n",
      "            \"GlmForSequenceClassification\",\n",
      "            \"GlmForTokenClassification\",\n",
      "            \"GlmModel\",\n",
      "            \"GlmPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.llama4\"].extend(\n",
      "        [\n",
      "            \"Llama4ForCausalLM\",\n",
      "            \"Llama4ForConditionalGeneration\",\n",
      "            \"Llama4TextModel\",\n",
      "            \"Llama4VisionModel\",\n",
      "            \"Llama4PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.glm4\"].extend(\n",
      "        [\n",
      "            \"Glm4ForCausalLM\",\n",
      "            \"Glm4ForSequenceClassification\",\n",
      "            \"Glm4ForTokenClassification\",\n",
      "            \"Glm4Model\",\n",
      "            \"Glm4PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.glpn\"].extend(\n",
      "        [\n",
      "            \"GLPNForDepthEstimation\",\n",
      "            \"GLPNModel\",\n",
      "            \"GLPNPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.got_ocr2\"].extend(\n",
      "        [\n",
      "            \"GotOcr2ForConditionalGeneration\",\n",
      "            \"GotOcr2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gpt2\"].extend(\n",
      "        [\n",
      "            \"GPT2DoubleHeadsModel\",\n",
      "            \"GPT2ForQuestionAnswering\",\n",
      "            \"GPT2ForSequenceClassification\",\n",
      "            \"GPT2ForTokenClassification\",\n",
      "            \"GPT2LMHeadModel\",\n",
      "            \"GPT2Model\",\n",
      "            \"GPT2PreTrainedModel\",\n",
      "            \"load_tf_weights_in_gpt2\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gpt_bigcode\"].extend(\n",
      "        [\n",
      "            \"GPTBigCodeForCausalLM\",\n",
      "            \"GPTBigCodeForSequenceClassification\",\n",
      "            \"GPTBigCodeForTokenClassification\",\n",
      "            \"GPTBigCodeModel\",\n",
      "            \"GPTBigCodePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gpt_neo\"].extend(\n",
      "        [\n",
      "            \"GPTNeoForCausalLM\",\n",
      "            \"GPTNeoForQuestionAnswering\",\n",
      "            \"GPTNeoForSequenceClassification\",\n",
      "            \"GPTNeoForTokenClassification\",\n",
      "            \"GPTNeoModel\",\n",
      "            \"GPTNeoPreTrainedModel\",\n",
      "            \"load_tf_weights_in_gpt_neo\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gpt_neox\"].extend(\n",
      "        [\n",
      "            \"GPTNeoXForCausalLM\",\n",
      "            \"GPTNeoXForQuestionAnswering\",\n",
      "            \"GPTNeoXForSequenceClassification\",\n",
      "            \"GPTNeoXForTokenClassification\",\n",
      "            \"GPTNeoXModel\",\n",
      "            \"GPTNeoXPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gpt_neox_japanese\"].extend(\n",
      "        [\n",
      "            \"GPTNeoXJapaneseForCausalLM\",\n",
      "            \"GPTNeoXJapaneseModel\",\n",
      "            \"GPTNeoXJapanesePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gptj\"].extend(\n",
      "        [\n",
      "            \"GPTJForCausalLM\",\n",
      "            \"GPTJForQuestionAnswering\",\n",
      "            \"GPTJForSequenceClassification\",\n",
      "            \"GPTJModel\",\n",
      "            \"GPTJPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.granite\"].extend(\n",
      "        [\n",
      "            \"GraniteForCausalLM\",\n",
      "            \"GraniteModel\",\n",
      "            \"GranitePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.granitemoe\"].extend(\n",
      "        [\n",
      "            \"GraniteMoeForCausalLM\",\n",
      "            \"GraniteMoeModel\",\n",
      "            \"GraniteMoePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    _import_structure[\"models.granitemoeshared\"].extend(\n",
      "        [\n",
      "            \"GraniteMoeSharedForCausalLM\",\n",
      "            \"GraniteMoeSharedModel\",\n",
      "            \"GraniteMoeSharedPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.grounding_dino\"].extend(\n",
      "        [\n",
      "            \"GroundingDinoForObjectDetection\",\n",
      "            \"GroundingDinoModel\",\n",
      "            \"GroundingDinoPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.groupvit\"].extend(\n",
      "        [\n",
      "            \"GroupViTModel\",\n",
      "            \"GroupViTPreTrainedModel\",\n",
      "            \"GroupViTTextModel\",\n",
      "            \"GroupViTVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.helium\"].extend(\n",
      "        [\n",
      "            \"HeliumForCausalLM\",\n",
      "            \"HeliumForSequenceClassification\",\n",
      "            \"HeliumForTokenClassification\",\n",
      "            \"HeliumModel\",\n",
      "            \"HeliumPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.hiera\"].extend(\n",
      "        [\n",
      "            \"HieraBackbone\",\n",
      "            \"HieraForImageClassification\",\n",
      "            \"HieraForPreTraining\",\n",
      "            \"HieraModel\",\n",
      "            \"HieraPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.hubert\"].extend(\n",
      "        [\n",
      "            \"HubertForCTC\",\n",
      "            \"HubertForSequenceClassification\",\n",
      "            \"HubertModel\",\n",
      "            \"HubertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.ibert\"].extend(\n",
      "        [\n",
      "            \"IBertForMaskedLM\",\n",
      "            \"IBertForMultipleChoice\",\n",
      "            \"IBertForQuestionAnswering\",\n",
      "            \"IBertForSequenceClassification\",\n",
      "            \"IBertForTokenClassification\",\n",
      "            \"IBertModel\",\n",
      "            \"IBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.idefics\"].extend(\n",
      "        [\n",
      "            \"IdeficsForVisionText2Text\",\n",
      "            \"IdeficsModel\",\n",
      "            \"IdeficsPreTrainedModel\",\n",
      "            \"IdeficsProcessor\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.idefics2\"].extend(\n",
      "        [\n",
      "            \"Idefics2ForConditionalGeneration\",\n",
      "            \"Idefics2Model\",\n",
      "            \"Idefics2PreTrainedModel\",\n",
      "            \"Idefics2Processor\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.idefics3\"].extend(\n",
      "        [\n",
      "            \"Idefics3ForConditionalGeneration\",\n",
      "            \"Idefics3Model\",\n",
      "            \"Idefics3PreTrainedModel\",\n",
      "            \"Idefics3Processor\",\n",
      "            \"Idefics3VisionConfig\",\n",
      "            \"Idefics3VisionTransformer\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.ijepa\"].extend(\n",
      "        [\n",
      "            \"IJepaForImageClassification\",\n",
      "            \"IJepaModel\",\n",
      "            \"IJepaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.imagegpt\"].extend(\n",
      "        [\n",
      "            \"ImageGPTForCausalImageModeling\",\n",
      "            \"ImageGPTForImageClassification\",\n",
      "            \"ImageGPTModel\",\n",
      "            \"ImageGPTPreTrainedModel\",\n",
      "            \"load_tf_weights_in_imagegpt\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.informer\"].extend(\n",
      "        [\n",
      "            \"InformerForPrediction\",\n",
      "            \"InformerModel\",\n",
      "            \"InformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.instructblip\"].extend(\n",
      "        [\n",
      "            \"InstructBlipForConditionalGeneration\",\n",
      "            \"InstructBlipPreTrainedModel\",\n",
      "            \"InstructBlipQFormerModel\",\n",
      "            \"InstructBlipVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.instructblipvideo\"].extend(\n",
      "        [\n",
      "            \"InstructBlipVideoForConditionalGeneration\",\n",
      "            \"InstructBlipVideoPreTrainedModel\",\n",
      "            \"InstructBlipVideoQFormerModel\",\n",
      "            \"InstructBlipVideoVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.jamba\"].extend(\n",
      "        [\n",
      "            \"JambaForCausalLM\",\n",
      "            \"JambaForSequenceClassification\",\n",
      "            \"JambaModel\",\n",
      "            \"JambaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.jetmoe\"].extend(\n",
      "        [\n",
      "            \"JetMoeForCausalLM\",\n",
      "            \"JetMoeForSequenceClassification\",\n",
      "            \"JetMoeModel\",\n",
      "            \"JetMoePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.kosmos2\"].extend(\n",
      "        [\n",
      "            \"Kosmos2ForConditionalGeneration\",\n",
      "            \"Kosmos2Model\",\n",
      "            \"Kosmos2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.layoutlm\"].extend(\n",
      "        [\n",
      "            \"LayoutLMForMaskedLM\",\n",
      "            \"LayoutLMForQuestionAnswering\",\n",
      "            \"LayoutLMForSequenceClassification\",\n",
      "            \"LayoutLMForTokenClassification\",\n",
      "            \"LayoutLMModel\",\n",
      "            \"LayoutLMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.layoutlmv2\"].extend(\n",
      "        [\n",
      "            \"LayoutLMv2ForQuestionAnswering\",\n",
      "            \"LayoutLMv2ForSequenceClassification\",\n",
      "            \"LayoutLMv2ForTokenClassification\",\n",
      "            \"LayoutLMv2Model\",\n",
      "            \"LayoutLMv2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.layoutlmv3\"].extend(\n",
      "        [\n",
      "            \"LayoutLMv3ForQuestionAnswering\",\n",
      "            \"LayoutLMv3ForSequenceClassification\",\n",
      "            \"LayoutLMv3ForTokenClassification\",\n",
      "            \"LayoutLMv3Model\",\n",
      "            \"LayoutLMv3PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.led\"].extend(\n",
      "        [\n",
      "            \"LEDForConditionalGeneration\",\n",
      "            \"LEDForQuestionAnswering\",\n",
      "            \"LEDForSequenceClassification\",\n",
      "            \"LEDModel\",\n",
      "            \"LEDPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.levit\"].extend(\n",
      "        [\n",
      "            \"LevitForImageClassification\",\n",
      "            \"LevitForImageClassificationWithTeacher\",\n",
      "            \"LevitModel\",\n",
      "            \"LevitPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.lilt\"].extend(\n",
      "        [\n",
      "            \"LiltForQuestionAnswering\",\n",
      "            \"LiltForSequenceClassification\",\n",
      "            \"LiltForTokenClassification\",\n",
      "            \"LiltModel\",\n",
      "            \"LiltPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.llama\"].extend(\n",
      "        [\n",
      "            \"LlamaForCausalLM\",\n",
      "            \"LlamaForQuestionAnswering\",\n",
      "            \"LlamaForSequenceClassification\",\n",
      "            \"LlamaForTokenClassification\",\n",
      "            \"LlamaModel\",\n",
      "            \"LlamaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.llava\"].extend(\n",
      "        [\n",
      "            \"LlavaForConditionalGeneration\",\n",
      "            \"LlavaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.llava_next\"].extend(\n",
      "        [\n",
      "            \"LlavaNextForConditionalGeneration\",\n",
      "            \"LlavaNextPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.phi4_multimodal\"].extend(\n",
      "        [\n",
      "            \"Phi4MultimodalForCausalLM\",\n",
      "            \"Phi4MultimodalPreTrainedModel\",\n",
      "            \"Phi4MultimodalAudioModel\",\n",
      "            \"Phi4MultimodalAudioPreTrainedModel\",\n",
      "            \"Phi4MultimodalModel\",\n",
      "            \"Phi4MultimodalVisionModel\",\n",
      "            \"Phi4MultimodalVisionPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.llava_next_video\"].extend(\n",
      "        [\n",
      "            \"LlavaNextVideoForConditionalGeneration\",\n",
      "            \"LlavaNextVideoPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.llava_onevision\"].extend(\n",
      "        [\n",
      "            \"LlavaOnevisionForConditionalGeneration\",\n",
      "            \"LlavaOnevisionPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.longformer\"].extend(\n",
      "        [\n",
      "            \"LongformerForMaskedLM\",\n",
      "            \"LongformerForMultipleChoice\",\n",
      "            \"LongformerForQuestionAnswering\",\n",
      "            \"LongformerForSequenceClassification\",\n",
      "            \"LongformerForTokenClassification\",\n",
      "            \"LongformerModel\",\n",
      "            \"LongformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.longt5\"].extend(\n",
      "        [\n",
      "            \"LongT5EncoderModel\",\n",
      "            \"LongT5ForConditionalGeneration\",\n",
      "            \"LongT5Model\",\n",
      "            \"LongT5PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.luke\"].extend(\n",
      "        [\n",
      "            \"LukeForEntityClassification\",\n",
      "            \"LukeForEntityPairClassification\",\n",
      "            \"LukeForEntitySpanClassification\",\n",
      "            \"LukeForMaskedLM\",\n",
      "            \"LukeForMultipleChoice\",\n",
      "            \"LukeForQuestionAnswering\",\n",
      "            \"LukeForSequenceClassification\",\n",
      "            \"LukeForTokenClassification\",\n",
      "            \"LukeModel\",\n",
      "            \"LukePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.lxmert\"].extend(\n",
      "        [\n",
      "            \"LxmertEncoder\",\n",
      "            \"LxmertForPreTraining\",\n",
      "            \"LxmertForQuestionAnswering\",\n",
      "            \"LxmertModel\",\n",
      "            \"LxmertPreTrainedModel\",\n",
      "            \"LxmertVisualFeatureEncoder\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.m2m_100\"].extend(\n",
      "        [\n",
      "            \"M2M100ForConditionalGeneration\",\n",
      "            \"M2M100Model\",\n",
      "            \"M2M100PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mamba\"].extend(\n",
      "        [\n",
      "            \"MambaForCausalLM\",\n",
      "            \"MambaModel\",\n",
      "            \"MambaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mamba2\"].extend(\n",
      "        [\n",
      "            \"Mamba2ForCausalLM\",\n",
      "            \"Mamba2Model\",\n",
      "            \"Mamba2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.marian\"].extend(\n",
      "        [\"MarianForCausalLM\", \"MarianModel\", \"MarianMTModel\", \"MarianPreTrainedModel\"]\n",
      "    )\n",
      "    _import_structure[\"models.markuplm\"].extend(\n",
      "        [\n",
      "            \"MarkupLMForQuestionAnswering\",\n",
      "            \"MarkupLMForSequenceClassification\",\n",
      "            \"MarkupLMForTokenClassification\",\n",
      "            \"MarkupLMModel\",\n",
      "            \"MarkupLMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mask2former\"].extend(\n",
      "        [\n",
      "            \"Mask2FormerForUniversalSegmentation\",\n",
      "            \"Mask2FormerModel\",\n",
      "            \"Mask2FormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.maskformer\"].extend(\n",
      "        [\n",
      "            \"MaskFormerForInstanceSegmentation\",\n",
      "            \"MaskFormerModel\",\n",
      "            \"MaskFormerPreTrainedModel\",\n",
      "            \"MaskFormerSwinBackbone\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mbart\"].extend(\n",
      "        [\n",
      "            \"MBartForCausalLM\",\n",
      "            \"MBartForConditionalGeneration\",\n",
      "            \"MBartForQuestionAnswering\",\n",
      "            \"MBartForSequenceClassification\",\n",
      "            \"MBartModel\",\n",
      "            \"MBartPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.megatron_bert\"].extend(\n",
      "        [\n",
      "            \"MegatronBertForCausalLM\",\n",
      "            \"MegatronBertForMaskedLM\",\n",
      "            \"MegatronBertForMultipleChoice\",\n",
      "            \"MegatronBertForNextSentencePrediction\",\n",
      "            \"MegatronBertForPreTraining\",\n",
      "            \"MegatronBertForQuestionAnswering\",\n",
      "            \"MegatronBertForSequenceClassification\",\n",
      "            \"MegatronBertForTokenClassification\",\n",
      "            \"MegatronBertModel\",\n",
      "            \"MegatronBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mgp_str\"].extend(\n",
      "        [\n",
      "            \"MgpstrForSceneTextRecognition\",\n",
      "            \"MgpstrModel\",\n",
      "            \"MgpstrPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mimi\"].extend(\n",
      "        [\n",
      "            \"MimiModel\",\n",
      "            \"MimiPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mistral\"].extend(\n",
      "        [\n",
      "            \"MistralForCausalLM\",\n",
      "            \"MistralForQuestionAnswering\",\n",
      "            \"MistralForSequenceClassification\",\n",
      "            \"MistralForTokenClassification\",\n",
      "            \"MistralModel\",\n",
      "            \"MistralPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mistral3\"].extend(\n",
      "        [\n",
      "            \"Mistral3ForConditionalGeneration\",\n",
      "            \"Mistral3PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mixtral\"].extend(\n",
      "        [\n",
      "            \"MixtralForCausalLM\",\n",
      "            \"MixtralForQuestionAnswering\",\n",
      "            \"MixtralForSequenceClassification\",\n",
      "            \"MixtralForTokenClassification\",\n",
      "            \"MixtralModel\",\n",
      "            \"MixtralPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mllama\"].extend(\n",
      "        [\n",
      "            \"MllamaForCausalLM\",\n",
      "            \"MllamaForConditionalGeneration\",\n",
      "            \"MllamaPreTrainedModel\",\n",
      "            \"MllamaProcessor\",\n",
      "            \"MllamaTextModel\",\n",
      "            \"MllamaVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mobilebert\"].extend(\n",
      "        [\n",
      "            \"MobileBertForMaskedLM\",\n",
      "            \"MobileBertForMultipleChoice\",\n",
      "            \"MobileBertForNextSentencePrediction\",\n",
      "            \"MobileBertForPreTraining\",\n",
      "            \"MobileBertForQuestionAnswering\",\n",
      "            \"MobileBertForSequenceClassification\",\n",
      "            \"MobileBertForTokenClassification\",\n",
      "            \"MobileBertModel\",\n",
      "            \"MobileBertPreTrainedModel\",\n",
      "            \"load_tf_weights_in_mobilebert\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mobilenet_v1\"].extend(\n",
      "        [\n",
      "            \"MobileNetV1ForImageClassification\",\n",
      "            \"MobileNetV1Model\",\n",
      "            \"MobileNetV1PreTrainedModel\",\n",
      "            \"load_tf_weights_in_mobilenet_v1\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mobilenet_v2\"].extend(\n",
      "        [\n",
      "            \"MobileNetV2ForImageClassification\",\n",
      "            \"MobileNetV2ForSemanticSegmentation\",\n",
      "            \"MobileNetV2Model\",\n",
      "            \"MobileNetV2PreTrainedModel\",\n",
      "            \"load_tf_weights_in_mobilenet_v2\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mobilevit\"].extend(\n",
      "        [\n",
      "            \"MobileViTForImageClassification\",\n",
      "            \"MobileViTForSemanticSegmentation\",\n",
      "            \"MobileViTModel\",\n",
      "            \"MobileViTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mobilevitv2\"].extend(\n",
      "        [\n",
      "            \"MobileViTV2ForImageClassification\",\n",
      "            \"MobileViTV2ForSemanticSegmentation\",\n",
      "            \"MobileViTV2Model\",\n",
      "            \"MobileViTV2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.modernbert\"].extend(\n",
      "        [\n",
      "            \"ModernBertForMaskedLM\",\n",
      "            \"ModernBertForQuestionAnswering\",\n",
      "            \"ModernBertForSequenceClassification\",\n",
      "            \"ModernBertForTokenClassification\",\n",
      "            \"ModernBertModel\",\n",
      "            \"ModernBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.moonshine\"].extend(\n",
      "        [\n",
      "            \"MoonshineForConditionalGeneration\",\n",
      "            \"MoonshineModel\",\n",
      "            \"MoonshinePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.moshi\"].extend(\n",
      "        [\n",
      "            \"MoshiForCausalLM\",\n",
      "            \"MoshiForConditionalGeneration\",\n",
      "            \"MoshiModel\",\n",
      "            \"MoshiPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mpnet\"].extend(\n",
      "        [\n",
      "            \"MPNetForMaskedLM\",\n",
      "            \"MPNetForMultipleChoice\",\n",
      "            \"MPNetForQuestionAnswering\",\n",
      "            \"MPNetForSequenceClassification\",\n",
      "            \"MPNetForTokenClassification\",\n",
      "            \"MPNetModel\",\n",
      "            \"MPNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mpt\"].extend(\n",
      "        [\n",
      "            \"MptForCausalLM\",\n",
      "            \"MptForQuestionAnswering\",\n",
      "            \"MptForSequenceClassification\",\n",
      "            \"MptForTokenClassification\",\n",
      "            \"MptModel\",\n",
      "            \"MptPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mra\"].extend(\n",
      "        [\n",
      "            \"MraForMaskedLM\",\n",
      "            \"MraForMultipleChoice\",\n",
      "            \"MraForQuestionAnswering\",\n",
      "            \"MraForSequenceClassification\",\n",
      "            \"MraForTokenClassification\",\n",
      "            \"MraModel\",\n",
      "            \"MraPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mt5\"].extend(\n",
      "        [\n",
      "            \"MT5EncoderModel\",\n",
      "            \"MT5ForConditionalGeneration\",\n",
      "            \"MT5ForQuestionAnswering\",\n",
      "            \"MT5ForSequenceClassification\",\n",
      "            \"MT5ForTokenClassification\",\n",
      "            \"MT5Model\",\n",
      "            \"MT5PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.musicgen\"].extend(\n",
      "        [\n",
      "            \"MusicgenForCausalLM\",\n",
      "            \"MusicgenForConditionalGeneration\",\n",
      "            \"MusicgenModel\",\n",
      "            \"MusicgenPreTrainedModel\",\n",
      "            \"MusicgenProcessor\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.musicgen_melody\"].extend(\n",
      "        [\n",
      "            \"MusicgenMelodyForCausalLM\",\n",
      "            \"MusicgenMelodyForConditionalGeneration\",\n",
      "            \"MusicgenMelodyModel\",\n",
      "            \"MusicgenMelodyPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mvp\"].extend(\n",
      "        [\n",
      "            \"MvpForCausalLM\",\n",
      "            \"MvpForConditionalGeneration\",\n",
      "            \"MvpForQuestionAnswering\",\n",
      "            \"MvpForSequenceClassification\",\n",
      "            \"MvpModel\",\n",
      "            \"MvpPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.nemotron\"].extend(\n",
      "        [\n",
      "            \"NemotronForCausalLM\",\n",
      "            \"NemotronForQuestionAnswering\",\n",
      "            \"NemotronForSequenceClassification\",\n",
      "            \"NemotronForTokenClassification\",\n",
      "            \"NemotronModel\",\n",
      "            \"NemotronPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.nllb_moe\"].extend(\n",
      "        [\n",
      "            \"NllbMoeForConditionalGeneration\",\n",
      "            \"NllbMoeModel\",\n",
      "            \"NllbMoePreTrainedModel\",\n",
      "            \"NllbMoeSparseMLP\",\n",
      "            \"NllbMoeTop2Router\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.nystromformer\"].extend(\n",
      "        [\n",
      "            \"NystromformerForMaskedLM\",\n",
      "            \"NystromformerForMultipleChoice\",\n",
      "            \"NystromformerForQuestionAnswering\",\n",
      "            \"NystromformerForSequenceClassification\",\n",
      "            \"NystromformerForTokenClassification\",\n",
      "            \"NystromformerModel\",\n",
      "            \"NystromformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.olmo\"].extend(\n",
      "        [\n",
      "            \"OlmoForCausalLM\",\n",
      "            \"OlmoModel\",\n",
      "            \"OlmoPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.olmo2\"].extend(\n",
      "        [\n",
      "            \"Olmo2ForCausalLM\",\n",
      "            \"Olmo2Model\",\n",
      "            \"Olmo2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.olmoe\"].extend(\n",
      "        [\n",
      "            \"OlmoeForCausalLM\",\n",
      "            \"OlmoeModel\",\n",
      "            \"OlmoePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.omdet_turbo\"].extend(\n",
      "        [\n",
      "            \"OmDetTurboForObjectDetection\",\n",
      "            \"OmDetTurboPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.oneformer\"].extend(\n",
      "        [\n",
      "            \"OneFormerForUniversalSegmentation\",\n",
      "            \"OneFormerModel\",\n",
      "            \"OneFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.openai\"].extend(\n",
      "        [\n",
      "            \"OpenAIGPTDoubleHeadsModel\",\n",
      "            \"OpenAIGPTForSequenceClassification\",\n",
      "            \"OpenAIGPTLMHeadModel\",\n",
      "            \"OpenAIGPTModel\",\n",
      "            \"OpenAIGPTPreTrainedModel\",\n",
      "            \"load_tf_weights_in_openai_gpt\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.opt\"].extend(\n",
      "        [\n",
      "            \"OPTForCausalLM\",\n",
      "            \"OPTForQuestionAnswering\",\n",
      "            \"OPTForSequenceClassification\",\n",
      "            \"OPTModel\",\n",
      "            \"OPTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.owlv2\"].extend(\n",
      "        [\n",
      "            \"Owlv2ForObjectDetection\",\n",
      "            \"Owlv2Model\",\n",
      "            \"Owlv2PreTrainedModel\",\n",
      "            \"Owlv2TextModel\",\n",
      "            \"Owlv2VisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.owlvit\"].extend(\n",
      "        [\n",
      "            \"OwlViTForObjectDetection\",\n",
      "            \"OwlViTModel\",\n",
      "            \"OwlViTPreTrainedModel\",\n",
      "            \"OwlViTTextModel\",\n",
      "            \"OwlViTVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.paligemma\"].extend(\n",
      "        [\n",
      "            \"PaliGemmaForConditionalGeneration\",\n",
      "            \"PaliGemmaPreTrainedModel\",\n",
      "            \"PaliGemmaProcessor\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.patchtsmixer\"].extend(\n",
      "        [\n",
      "            \"PatchTSMixerForPrediction\",\n",
      "            \"PatchTSMixerForPretraining\",\n",
      "            \"PatchTSMixerForRegression\",\n",
      "            \"PatchTSMixerForTimeSeriesClassification\",\n",
      "            \"PatchTSMixerModel\",\n",
      "            \"PatchTSMixerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.patchtst\"].extend(\n",
      "        [\n",
      "            \"PatchTSTForClassification\",\n",
      "            \"PatchTSTForPrediction\",\n",
      "            \"PatchTSTForPretraining\",\n",
      "            \"PatchTSTForRegression\",\n",
      "            \"PatchTSTModel\",\n",
      "            \"PatchTSTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pegasus\"].extend(\n",
      "        [\n",
      "            \"PegasusForCausalLM\",\n",
      "            \"PegasusForConditionalGeneration\",\n",
      "            \"PegasusModel\",\n",
      "            \"PegasusPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pegasus_x\"].extend(\n",
      "        [\n",
      "            \"PegasusXForConditionalGeneration\",\n",
      "            \"PegasusXModel\",\n",
      "            \"PegasusXPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.perceiver\"].extend(\n",
      "        [\n",
      "            \"PerceiverForImageClassificationConvProcessing\",\n",
      "            \"PerceiverForImageClassificationFourier\",\n",
      "            \"PerceiverForImageClassificationLearned\",\n",
      "            \"PerceiverForMaskedLM\",\n",
      "            \"PerceiverForMultimodalAutoencoding\",\n",
      "            \"PerceiverForOpticalFlow\",\n",
      "            \"PerceiverForSequenceClassification\",\n",
      "            \"PerceiverModel\",\n",
      "            \"PerceiverPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.persimmon\"].extend(\n",
      "        [\n",
      "            \"PersimmonForCausalLM\",\n",
      "            \"PersimmonForSequenceClassification\",\n",
      "            \"PersimmonForTokenClassification\",\n",
      "            \"PersimmonModel\",\n",
      "            \"PersimmonPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.phi\"].extend(\n",
      "        [\n",
      "            \"PhiForCausalLM\",\n",
      "            \"PhiForSequenceClassification\",\n",
      "            \"PhiForTokenClassification\",\n",
      "            \"PhiModel\",\n",
      "            \"PhiPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.phi3\"].extend(\n",
      "        [\n",
      "            \"Phi3ForCausalLM\",\n",
      "            \"Phi3ForSequenceClassification\",\n",
      "            \"Phi3ForTokenClassification\",\n",
      "            \"Phi3Model\",\n",
      "            \"Phi3PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.phimoe\"].extend(\n",
      "        [\n",
      "            \"PhimoeForCausalLM\",\n",
      "            \"PhimoeForSequenceClassification\",\n",
      "            \"PhimoeModel\",\n",
      "            \"PhimoePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pix2struct\"].extend(\n",
      "        [\n",
      "            \"Pix2StructForConditionalGeneration\",\n",
      "            \"Pix2StructPreTrainedModel\",\n",
      "            \"Pix2StructTextModel\",\n",
      "            \"Pix2StructVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pixtral\"].extend([\"PixtralPreTrainedModel\", \"PixtralVisionModel\"])\n",
      "    _import_structure[\"models.plbart\"].extend(\n",
      "        [\n",
      "            \"PLBartForCausalLM\",\n",
      "            \"PLBartForConditionalGeneration\",\n",
      "            \"PLBartForSequenceClassification\",\n",
      "            \"PLBartModel\",\n",
      "            \"PLBartPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.poolformer\"].extend(\n",
      "        [\n",
      "            \"PoolFormerForImageClassification\",\n",
      "            \"PoolFormerModel\",\n",
      "            \"PoolFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pop2piano\"].extend(\n",
      "        [\n",
      "            \"Pop2PianoForConditionalGeneration\",\n",
      "            \"Pop2PianoPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.prompt_depth_anything\"].extend(\n",
      "        [\n",
      "            \"PromptDepthAnythingForDepthEstimation\",\n",
      "            \"PromptDepthAnythingPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.prophetnet\"].extend(\n",
      "        [\n",
      "            \"ProphetNetDecoder\",\n",
      "            \"ProphetNetEncoder\",\n",
      "            \"ProphetNetForCausalLM\",\n",
      "            \"ProphetNetForConditionalGeneration\",\n",
      "            \"ProphetNetModel\",\n",
      "            \"ProphetNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pvt\"].extend(\n",
      "        [\n",
      "            \"PvtForImageClassification\",\n",
      "            \"PvtModel\",\n",
      "            \"PvtPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pvt_v2\"].extend(\n",
      "        [\n",
      "            \"PvtV2Backbone\",\n",
      "            \"PvtV2ForImageClassification\",\n",
      "            \"PvtV2Model\",\n",
      "            \"PvtV2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.qwen2\"].extend(\n",
      "        [\n",
      "            \"Qwen2ForCausalLM\",\n",
      "            \"Qwen2ForQuestionAnswering\",\n",
      "            \"Qwen2ForSequenceClassification\",\n",
      "            \"Qwen2ForTokenClassification\",\n",
      "            \"Qwen2Model\",\n",
      "            \"Qwen2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.qwen2_5_vl\"].extend(\n",
      "        [\n",
      "            \"Qwen2_5_VLForConditionalGeneration\",\n",
      "            \"Qwen2_5_VLModel\",\n",
      "            \"Qwen2_5_VLPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.qwen2_audio\"].extend(\n",
      "        [\n",
      "            \"Qwen2AudioEncoder\",\n",
      "            \"Qwen2AudioForConditionalGeneration\",\n",
      "            \"Qwen2AudioPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.qwen2_moe\"].extend(\n",
      "        [\n",
      "            \"Qwen2MoeForCausalLM\",\n",
      "            \"Qwen2MoeForQuestionAnswering\",\n",
      "            \"Qwen2MoeForSequenceClassification\",\n",
      "            \"Qwen2MoeForTokenClassification\",\n",
      "            \"Qwen2MoeModel\",\n",
      "            \"Qwen2MoePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.qwen2_vl\"].extend(\n",
      "        [\n",
      "            \"Qwen2VLForConditionalGeneration\",\n",
      "            \"Qwen2VLModel\",\n",
      "            \"Qwen2VLPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.qwen3\"].extend(\n",
      "        [\n",
      "            \"Qwen3ForCausalLM\",\n",
      "            \"Qwen3ForQuestionAnswering\",\n",
      "            \"Qwen3ForSequenceClassification\",\n",
      "            \"Qwen3ForTokenClassification\",\n",
      "            \"Qwen3Model\",\n",
      "            \"Qwen3PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.qwen3_moe\"].extend(\n",
      "        [\n",
      "            \"Qwen3MoeForCausalLM\",\n",
      "            \"Qwen3MoeForQuestionAnswering\",\n",
      "            \"Qwen3MoeForSequenceClassification\",\n",
      "            \"Qwen3MoeForTokenClassification\",\n",
      "            \"Qwen3MoeModel\",\n",
      "            \"Qwen3MoePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.rag\"].extend(\n",
      "        [\n",
      "            \"RagModel\",\n",
      "            \"RagPreTrainedModel\",\n",
      "            \"RagSequenceForGeneration\",\n",
      "            \"RagTokenForGeneration\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.recurrent_gemma\"].extend(\n",
      "        [\n",
      "            \"RecurrentGemmaForCausalLM\",\n",
      "            \"RecurrentGemmaModel\",\n",
      "            \"RecurrentGemmaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.reformer\"].extend(\n",
      "        [\n",
      "            \"ReformerForMaskedLM\",\n",
      "            \"ReformerForQuestionAnswering\",\n",
      "            \"ReformerForSequenceClassification\",\n",
      "            \"ReformerModel\",\n",
      "            \"ReformerModelWithLMHead\",\n",
      "            \"ReformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.regnet\"].extend(\n",
      "        [\n",
      "            \"RegNetForImageClassification\",\n",
      "            \"RegNetModel\",\n",
      "            \"RegNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.rembert\"].extend(\n",
      "        [\n",
      "            \"RemBertForCausalLM\",\n",
      "            \"RemBertForMaskedLM\",\n",
      "            \"RemBertForMultipleChoice\",\n",
      "            \"RemBertForQuestionAnswering\",\n",
      "            \"RemBertForSequenceClassification\",\n",
      "            \"RemBertForTokenClassification\",\n",
      "            \"RemBertModel\",\n",
      "            \"RemBertPreTrainedModel\",\n",
      "            \"load_tf_weights_in_rembert\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.resnet\"].extend(\n",
      "        [\n",
      "            \"ResNetBackbone\",\n",
      "            \"ResNetForImageClassification\",\n",
      "            \"ResNetModel\",\n",
      "            \"ResNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roberta\"].extend(\n",
      "        [\n",
      "            \"RobertaForCausalLM\",\n",
      "            \"RobertaForMaskedLM\",\n",
      "            \"RobertaForMultipleChoice\",\n",
      "            \"RobertaForQuestionAnswering\",\n",
      "            \"RobertaForSequenceClassification\",\n",
      "            \"RobertaForTokenClassification\",\n",
      "            \"RobertaModel\",\n",
      "            \"RobertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roberta_prelayernorm\"].extend(\n",
      "        [\n",
      "            \"RobertaPreLayerNormForCausalLM\",\n",
      "            \"RobertaPreLayerNormForMaskedLM\",\n",
      "            \"RobertaPreLayerNormForMultipleChoice\",\n",
      "            \"RobertaPreLayerNormForQuestionAnswering\",\n",
      "            \"RobertaPreLayerNormForSequenceClassification\",\n",
      "            \"RobertaPreLayerNormForTokenClassification\",\n",
      "            \"RobertaPreLayerNormModel\",\n",
      "            \"RobertaPreLayerNormPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roc_bert\"].extend(\n",
      "        [\n",
      "            \"RoCBertForCausalLM\",\n",
      "            \"RoCBertForMaskedLM\",\n",
      "            \"RoCBertForMultipleChoice\",\n",
      "            \"RoCBertForPreTraining\",\n",
      "            \"RoCBertForQuestionAnswering\",\n",
      "            \"RoCBertForSequenceClassification\",\n",
      "            \"RoCBertForTokenClassification\",\n",
      "            \"RoCBertModel\",\n",
      "            \"RoCBertPreTrainedModel\",\n",
      "            \"load_tf_weights_in_roc_bert\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roformer\"].extend(\n",
      "        [\n",
      "            \"RoFormerForCausalLM\",\n",
      "            \"RoFormerForMaskedLM\",\n",
      "            \"RoFormerForMultipleChoice\",\n",
      "            \"RoFormerForQuestionAnswering\",\n",
      "            \"RoFormerForSequenceClassification\",\n",
      "            \"RoFormerForTokenClassification\",\n",
      "            \"RoFormerModel\",\n",
      "            \"RoFormerPreTrainedModel\",\n",
      "            \"load_tf_weights_in_roformer\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.rt_detr\"].extend(\n",
      "        [\n",
      "            \"RTDetrForObjectDetection\",\n",
      "            \"RTDetrModel\",\n",
      "            \"RTDetrPreTrainedModel\",\n",
      "            \"RTDetrResNetBackbone\",\n",
      "            \"RTDetrResNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.rt_detr_v2\"].extend(\n",
      "        [\"RTDetrV2ForObjectDetection\", \"RTDetrV2Model\", \"RTDetrV2PreTrainedModel\"]\n",
      "    )\n",
      "    _import_structure[\"models.rwkv\"].extend(\n",
      "        [\n",
      "            \"RwkvForCausalLM\",\n",
      "            \"RwkvModel\",\n",
      "            \"RwkvPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.sam\"].extend(\n",
      "        [\n",
      "            \"SamModel\",\n",
      "            \"SamPreTrainedModel\",\n",
      "            \"SamVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.seamless_m4t\"].extend(\n",
      "        [\n",
      "            \"SeamlessM4TCodeHifiGan\",\n",
      "            \"SeamlessM4TForSpeechToSpeech\",\n",
      "            \"SeamlessM4TForSpeechToText\",\n",
      "            \"SeamlessM4TForTextToSpeech\",\n",
      "            \"SeamlessM4TForTextToText\",\n",
      "            \"SeamlessM4THifiGan\",\n",
      "            \"SeamlessM4TModel\",\n",
      "            \"SeamlessM4TPreTrainedModel\",\n",
      "            \"SeamlessM4TTextToUnitForConditionalGeneration\",\n",
      "            \"SeamlessM4TTextToUnitModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.seamless_m4t_v2\"].extend(\n",
      "        [\n",
      "            \"SeamlessM4Tv2ForSpeechToSpeech\",\n",
      "            \"SeamlessM4Tv2ForSpeechToText\",\n",
      "            \"SeamlessM4Tv2ForTextToSpeech\",\n",
      "            \"SeamlessM4Tv2ForTextToText\",\n",
      "            \"SeamlessM4Tv2Model\",\n",
      "            \"SeamlessM4Tv2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.segformer\"].extend(\n",
      "        [\n",
      "            \"SegformerDecodeHead\",\n",
      "            \"SegformerForImageClassification\",\n",
      "            \"SegformerForSemanticSegmentation\",\n",
      "            \"SegformerModel\",\n",
      "            \"SegformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.seggpt\"].extend(\n",
      "        [\n",
      "            \"SegGptForImageSegmentation\",\n",
      "            \"SegGptModel\",\n",
      "            \"SegGptPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.sew\"].extend(\n",
      "        [\n",
      "            \"SEWForCTC\",\n",
      "            \"SEWForSequenceClassification\",\n",
      "            \"SEWModel\",\n",
      "            \"SEWPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.sew_d\"].extend(\n",
      "        [\n",
      "            \"SEWDForCTC\",\n",
      "            \"SEWDForSequenceClassification\",\n",
      "            \"SEWDModel\",\n",
      "            \"SEWDPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.shieldgemma2\"].append(\"ShieldGemma2ForImageClassification\")\n",
      "    _import_structure[\"models.siglip\"].extend(\n",
      "        [\n",
      "            \"SiglipForImageClassification\",\n",
      "            \"SiglipModel\",\n",
      "            \"SiglipPreTrainedModel\",\n",
      "            \"SiglipTextModel\",\n",
      "            \"SiglipVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.siglip2\"].extend(\n",
      "        [\n",
      "            \"Siglip2ForImageClassification\",\n",
      "            \"Siglip2Model\",\n",
      "            \"Siglip2PreTrainedModel\",\n",
      "            \"Siglip2TextModel\",\n",
      "            \"Siglip2VisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.smolvlm\"].extend(\n",
      "        [\n",
      "            \"SmolVLMForConditionalGeneration\",\n",
      "            \"SmolVLMModel\",\n",
      "            \"SmolVLMPreTrainedModel\",\n",
      "            \"SmolVLMProcessor\",\n",
      "            \"SmolVLMVisionConfig\",\n",
      "            \"SmolVLMVisionTransformer\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.speech_encoder_decoder\"].extend([\"SpeechEncoderDecoderModel\"])\n",
      "    _import_structure[\"models.speech_to_text\"].extend(\n",
      "        [\n",
      "            \"Speech2TextForConditionalGeneration\",\n",
      "            \"Speech2TextModel\",\n",
      "            \"Speech2TextPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.speecht5\"].extend(\n",
      "        [\n",
      "            \"SpeechT5ForSpeechToSpeech\",\n",
      "            \"SpeechT5ForSpeechToText\",\n",
      "            \"SpeechT5ForTextToSpeech\",\n",
      "            \"SpeechT5HifiGan\",\n",
      "            \"SpeechT5Model\",\n",
      "            \"SpeechT5PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.splinter\"].extend(\n",
      "        [\n",
      "            \"SplinterForPreTraining\",\n",
      "            \"SplinterForQuestionAnswering\",\n",
      "            \"SplinterModel\",\n",
      "            \"SplinterPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.squeezebert\"].extend(\n",
      "        [\n",
      "            \"SqueezeBertForMaskedLM\",\n",
      "            \"SqueezeBertForMultipleChoice\",\n",
      "            \"SqueezeBertForQuestionAnswering\",\n",
      "            \"SqueezeBertForSequenceClassification\",\n",
      "            \"SqueezeBertForTokenClassification\",\n",
      "            \"SqueezeBertModel\",\n",
      "            \"SqueezeBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.stablelm\"].extend(\n",
      "        [\n",
      "            \"StableLmForCausalLM\",\n",
      "            \"StableLmForSequenceClassification\",\n",
      "            \"StableLmForTokenClassification\",\n",
      "            \"StableLmModel\",\n",
      "            \"StableLmPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.starcoder2\"].extend(\n",
      "        [\n",
      "            \"Starcoder2ForCausalLM\",\n",
      "            \"Starcoder2ForSequenceClassification\",\n",
      "            \"Starcoder2ForTokenClassification\",\n",
      "            \"Starcoder2Model\",\n",
      "            \"Starcoder2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.superglue\"].extend(\n",
      "        [\n",
      "            \"SuperGlueForKeypointMatching\",\n",
      "            \"SuperGluePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.superpoint\"].extend(\n",
      "        [\n",
      "            \"SuperPointForKeypointDetection\",\n",
      "            \"SuperPointPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.swiftformer\"].extend(\n",
      "        [\n",
      "            \"SwiftFormerForImageClassification\",\n",
      "            \"SwiftFormerModel\",\n",
      "            \"SwiftFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.swin\"].extend(\n",
      "        [\n",
      "            \"SwinBackbone\",\n",
      "            \"SwinForImageClassification\",\n",
      "            \"SwinForMaskedImageModeling\",\n",
      "            \"SwinModel\",\n",
      "            \"SwinPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.swin2sr\"].extend(\n",
      "        [\n",
      "            \"Swin2SRForImageSuperResolution\",\n",
      "            \"Swin2SRModel\",\n",
      "            \"Swin2SRPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.swinv2\"].extend(\n",
      "        [\n",
      "            \"Swinv2Backbone\",\n",
      "            \"Swinv2ForImageClassification\",\n",
      "            \"Swinv2ForMaskedImageModeling\",\n",
      "            \"Swinv2Model\",\n",
      "            \"Swinv2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.switch_transformers\"].extend(\n",
      "        [\n",
      "            \"SwitchTransformersEncoderModel\",\n",
      "            \"SwitchTransformersForConditionalGeneration\",\n",
      "            \"SwitchTransformersModel\",\n",
      "            \"SwitchTransformersPreTrainedModel\",\n",
      "            \"SwitchTransformersSparseMLP\",\n",
      "            \"SwitchTransformersTop1Router\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.t5\"].extend(\n",
      "        [\n",
      "            \"T5EncoderModel\",\n",
      "            \"T5ForConditionalGeneration\",\n",
      "            \"T5ForQuestionAnswering\",\n",
      "            \"T5ForSequenceClassification\",\n",
      "            \"T5ForTokenClassification\",\n",
      "            \"T5Model\",\n",
      "            \"T5PreTrainedModel\",\n",
      "            \"load_tf_weights_in_t5\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.table_transformer\"].extend(\n",
      "        [\n",
      "            \"TableTransformerForObjectDetection\",\n",
      "            \"TableTransformerModel\",\n",
      "            \"TableTransformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.tapas\"].extend(\n",
      "        [\n",
      "            \"TapasForMaskedLM\",\n",
      "            \"TapasForQuestionAnswering\",\n",
      "            \"TapasForSequenceClassification\",\n",
      "            \"TapasModel\",\n",
      "            \"TapasPreTrainedModel\",\n",
      "            \"load_tf_weights_in_tapas\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.textnet\"].extend(\n",
      "        [\n",
      "            \"TextNetBackbone\",\n",
      "            \"TextNetForImageClassification\",\n",
      "            \"TextNetModel\",\n",
      "            \"TextNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.time_series_transformer\"].extend(\n",
      "        [\n",
      "            \"TimeSeriesTransformerForPrediction\",\n",
      "            \"TimeSeriesTransformerModel\",\n",
      "            \"TimeSeriesTransformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.timesformer\"].extend(\n",
      "        [\n",
      "            \"TimesformerForVideoClassification\",\n",
      "            \"TimesformerModel\",\n",
      "            \"TimesformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.timm_backbone\"].extend([\"TimmBackbone\"])\n",
      "    _import_structure[\"models.timm_wrapper\"].extend(\n",
      "        [\"TimmWrapperForImageClassification\", \"TimmWrapperModel\", \"TimmWrapperPreTrainedModel\"]\n",
      "    )\n",
      "    _import_structure[\"models.trocr\"].extend(\n",
      "        [\n",
      "            \"TrOCRForCausalLM\",\n",
      "            \"TrOCRPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.tvp\"].extend(\n",
      "        [\n",
      "            \"TvpForVideoGrounding\",\n",
      "            \"TvpModel\",\n",
      "            \"TvpPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.udop\"].extend(\n",
      "        [\n",
      "            \"UdopEncoderModel\",\n",
      "            \"UdopForConditionalGeneration\",\n",
      "            \"UdopModel\",\n",
      "            \"UdopPreTrainedModel\",\n",
      "        ],\n",
      "    )\n",
      "    _import_structure[\"models.umt5\"].extend(\n",
      "        [\n",
      "            \"UMT5EncoderModel\",\n",
      "            \"UMT5ForConditionalGeneration\",\n",
      "            \"UMT5ForQuestionAnswering\",\n",
      "            \"UMT5ForSequenceClassification\",\n",
      "            \"UMT5ForTokenClassification\",\n",
      "            \"UMT5Model\",\n",
      "            \"UMT5PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.unispeech\"].extend(\n",
      "        [\n",
      "            \"UniSpeechForCTC\",\n",
      "            \"UniSpeechForPreTraining\",\n",
      "            \"UniSpeechForSequenceClassification\",\n",
      "            \"UniSpeechModel\",\n",
      "            \"UniSpeechPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.unispeech_sat\"].extend(\n",
      "        [\n",
      "            \"UniSpeechSatForAudioFrameClassification\",\n",
      "            \"UniSpeechSatForCTC\",\n",
      "            \"UniSpeechSatForPreTraining\",\n",
      "            \"UniSpeechSatForSequenceClassification\",\n",
      "            \"UniSpeechSatForXVector\",\n",
      "            \"UniSpeechSatModel\",\n",
      "            \"UniSpeechSatPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.univnet\"].extend(\n",
      "        [\n",
      "            \"UnivNetModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.upernet\"].extend(\n",
      "        [\n",
      "            \"UperNetForSemanticSegmentation\",\n",
      "            \"UperNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.video_llava\"].extend(\n",
      "        [\n",
      "            \"VideoLlavaForConditionalGeneration\",\n",
      "            \"VideoLlavaPreTrainedModel\",\n",
      "            \"VideoLlavaProcessor\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.videomae\"].extend(\n",
      "        [\n",
      "            \"VideoMAEForPreTraining\",\n",
      "            \"VideoMAEForVideoClassification\",\n",
      "            \"VideoMAEModel\",\n",
      "            \"VideoMAEPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vilt\"].extend(\n",
      "        [\n",
      "            \"ViltForImageAndTextRetrieval\",\n",
      "            \"ViltForImagesAndTextClassification\",\n",
      "            \"ViltForMaskedLM\",\n",
      "            \"ViltForQuestionAnswering\",\n",
      "            \"ViltForTokenClassification\",\n",
      "            \"ViltModel\",\n",
      "            \"ViltPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vipllava\"].extend(\n",
      "        [\n",
      "            \"VipLlavaForConditionalGeneration\",\n",
      "            \"VipLlavaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vision_encoder_decoder\"].extend([\"VisionEncoderDecoderModel\"])\n",
      "    _import_structure[\"models.vision_text_dual_encoder\"].extend([\"VisionTextDualEncoderModel\"])\n",
      "    _import_structure[\"models.visual_bert\"].extend(\n",
      "        [\n",
      "            \"VisualBertForMultipleChoice\",\n",
      "            \"VisualBertForPreTraining\",\n",
      "            \"VisualBertForQuestionAnswering\",\n",
      "            \"VisualBertForRegionToPhraseAlignment\",\n",
      "            \"VisualBertForVisualReasoning\",\n",
      "            \"VisualBertModel\",\n",
      "            \"VisualBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vit\"].extend(\n",
      "        [\n",
      "            \"ViTForImageClassification\",\n",
      "            \"ViTForMaskedImageModeling\",\n",
      "            \"ViTModel\",\n",
      "            \"ViTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vit_mae\"].extend(\n",
      "        [\n",
      "            \"ViTMAEForPreTraining\",\n",
      "            \"ViTMAEModel\",\n",
      "            \"ViTMAEPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vit_msn\"].extend(\n",
      "        [\n",
      "            \"ViTMSNForImageClassification\",\n",
      "            \"ViTMSNModel\",\n",
      "            \"ViTMSNPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vitdet\"].extend(\n",
      "        [\n",
      "            \"VitDetBackbone\",\n",
      "            \"VitDetModel\",\n",
      "            \"VitDetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vitmatte\"].extend(\n",
      "        [\n",
      "            \"VitMatteForImageMatting\",\n",
      "            \"VitMattePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vitpose\"].extend(\n",
      "        [\n",
      "            \"VitPoseForPoseEstimation\",\n",
      "            \"VitPosePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vitpose_backbone\"].extend(\n",
      "        [\n",
      "            \"VitPoseBackbone\",\n",
      "            \"VitPoseBackbonePreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vits\"].extend(\n",
      "        [\n",
      "            \"VitsModel\",\n",
      "            \"VitsPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vivit\"].extend(\n",
      "        [\n",
      "            \"VivitForVideoClassification\",\n",
      "            \"VivitModel\",\n",
      "            \"VivitPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.wav2vec2\"].extend(\n",
      "        [\n",
      "            \"Wav2Vec2ForAudioFrameClassification\",\n",
      "            \"Wav2Vec2ForCTC\",\n",
      "            \"Wav2Vec2ForMaskedLM\",\n",
      "            \"Wav2Vec2ForPreTraining\",\n",
      "            \"Wav2Vec2ForSequenceClassification\",\n",
      "            \"Wav2Vec2ForXVector\",\n",
      "            \"Wav2Vec2Model\",\n",
      "            \"Wav2Vec2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.wav2vec2_bert\"].extend(\n",
      "        [\n",
      "            \"Wav2Vec2BertForAudioFrameClassification\",\n",
      "            \"Wav2Vec2BertForCTC\",\n",
      "            \"Wav2Vec2BertForSequenceClassification\",\n",
      "            \"Wav2Vec2BertForXVector\",\n",
      "            \"Wav2Vec2BertModel\",\n",
      "            \"Wav2Vec2BertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.wav2vec2_conformer\"].extend(\n",
      "        [\n",
      "            \"Wav2Vec2ConformerForAudioFrameClassification\",\n",
      "            \"Wav2Vec2ConformerForCTC\",\n",
      "            \"Wav2Vec2ConformerForPreTraining\",\n",
      "            \"Wav2Vec2ConformerForSequenceClassification\",\n",
      "            \"Wav2Vec2ConformerForXVector\",\n",
      "            \"Wav2Vec2ConformerModel\",\n",
      "            \"Wav2Vec2ConformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.wavlm\"].extend(\n",
      "        [\n",
      "            \"WavLMForAudioFrameClassification\",\n",
      "            \"WavLMForCTC\",\n",
      "            \"WavLMForSequenceClassification\",\n",
      "            \"WavLMForXVector\",\n",
      "            \"WavLMModel\",\n",
      "            \"WavLMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.whisper\"].extend(\n",
      "        [\n",
      "            \"WhisperForAudioClassification\",\n",
      "            \"WhisperForCausalLM\",\n",
      "            \"WhisperForConditionalGeneration\",\n",
      "            \"WhisperModel\",\n",
      "            \"WhisperPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.x_clip\"].extend(\n",
      "        [\n",
      "            \"XCLIPModel\",\n",
      "            \"XCLIPPreTrainedModel\",\n",
      "            \"XCLIPTextModel\",\n",
      "            \"XCLIPVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xglm\"].extend(\n",
      "        [\n",
      "            \"XGLMForCausalLM\",\n",
      "            \"XGLMModel\",\n",
      "            \"XGLMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlm\"].extend(\n",
      "        [\n",
      "            \"XLMForMultipleChoice\",\n",
      "            \"XLMForQuestionAnswering\",\n",
      "            \"XLMForQuestionAnsweringSimple\",\n",
      "            \"XLMForSequenceClassification\",\n",
      "            \"XLMForTokenClassification\",\n",
      "            \"XLMModel\",\n",
      "            \"XLMPreTrainedModel\",\n",
      "            \"XLMWithLMHeadModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlm_roberta\"].extend(\n",
      "        [\n",
      "            \"XLMRobertaForCausalLM\",\n",
      "            \"XLMRobertaForMaskedLM\",\n",
      "            \"XLMRobertaForMultipleChoice\",\n",
      "            \"XLMRobertaForQuestionAnswering\",\n",
      "            \"XLMRobertaForSequenceClassification\",\n",
      "            \"XLMRobertaForTokenClassification\",\n",
      "            \"XLMRobertaModel\",\n",
      "            \"XLMRobertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlm_roberta_xl\"].extend(\n",
      "        [\n",
      "            \"XLMRobertaXLForCausalLM\",\n",
      "            \"XLMRobertaXLForMaskedLM\",\n",
      "            \"XLMRobertaXLForMultipleChoice\",\n",
      "            \"XLMRobertaXLForQuestionAnswering\",\n",
      "            \"XLMRobertaXLForSequenceClassification\",\n",
      "            \"XLMRobertaXLForTokenClassification\",\n",
      "            \"XLMRobertaXLModel\",\n",
      "            \"XLMRobertaXLPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlnet\"].extend(\n",
      "        [\n",
      "            \"XLNetForMultipleChoice\",\n",
      "            \"XLNetForQuestionAnswering\",\n",
      "            \"XLNetForQuestionAnsweringSimple\",\n",
      "            \"XLNetForSequenceClassification\",\n",
      "            \"XLNetForTokenClassification\",\n",
      "            \"XLNetLMHeadModel\",\n",
      "            \"XLNetModel\",\n",
      "            \"XLNetPreTrainedModel\",\n",
      "            \"load_tf_weights_in_xlnet\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xmod\"].extend(\n",
      "        [\n",
      "            \"XmodForCausalLM\",\n",
      "            \"XmodForMaskedLM\",\n",
      "            \"XmodForMultipleChoice\",\n",
      "            \"XmodForQuestionAnswering\",\n",
      "            \"XmodForSequenceClassification\",\n",
      "            \"XmodForTokenClassification\",\n",
      "            \"XmodModel\",\n",
      "            \"XmodPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.yolos\"].extend(\n",
      "        [\n",
      "            \"YolosForObjectDetection\",\n",
      "            \"YolosModel\",\n",
      "            \"YolosPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.yoso\"].extend(\n",
      "        [\n",
      "            \"YosoForMaskedLM\",\n",
      "            \"YosoForMultipleChoice\",\n",
      "            \"YosoForQuestionAnswering\",\n",
      "            \"YosoForSequenceClassification\",\n",
      "            \"YosoForTokenClassification\",\n",
      "            \"YosoModel\",\n",
      "            \"YosoPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.zamba\"].extend(\n",
      "        [\n",
      "            \"ZambaForCausalLM\",\n",
      "            \"ZambaForSequenceClassification\",\n",
      "            \"ZambaModel\",\n",
      "            \"ZambaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.zamba2\"].extend(\n",
      "        [\n",
      "            \"Zamba2ForCausalLM\",\n",
      "            \"Zamba2ForSequenceClassification\",\n",
      "            \"Zamba2Model\",\n",
      "            \"Zamba2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.zoedepth\"].extend(\n",
      "        [\n",
      "            \"ZoeDepthForDepthEstimation\",\n",
      "            \"ZoeDepthPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"optimization\"] = [\n",
      "        \"Adafactor\",\n",
      "        \"get_constant_schedule\",\n",
      "        \"get_constant_schedule_with_warmup\",\n",
      "        \"get_cosine_schedule_with_warmup\",\n",
      "        \"get_cosine_with_hard_restarts_schedule_with_warmup\",\n",
      "        \"get_inverse_sqrt_schedule\",\n",
      "        \"get_linear_schedule_with_warmup\",\n",
      "        \"get_polynomial_decay_schedule_with_warmup\",\n",
      "        \"get_scheduler\",\n",
      "        \"get_wsd_schedule\",\n",
      "    ]\n",
      "    _import_structure[\"pytorch_utils\"] = [\n",
      "        \"Conv1D\",\n",
      "        \"apply_chunking_to_forward\",\n",
      "        \"prune_layer\",\n",
      "    ]\n",
      "    _import_structure[\"sagemaker\"] = []\n",
      "    _import_structure[\"time_series_utils\"] = []\n",
      "    _import_structure[\"trainer\"] = [\"Trainer\"]\n",
      "    _import_structure[\"trainer_pt_utils\"] = [\"torch_distributed_zero_first\"]\n",
      "    _import_structure[\"trainer_seq2seq\"] = [\"Seq2SeqTrainer\"]\n",
      "\n",
      "# TensorFlow-backed objects\n",
      "try:\n",
      "    if not is_tf_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_tf_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_tf_objects\"] = [name for name in dir(dummy_tf_objects) if not name.startswith(\"_\")]\n",
      "else:\n",
      "    _import_structure[\"activations_tf\"] = []\n",
      "    _import_structure[\"generation\"].extend(\n",
      "        [\n",
      "            \"TFForcedBOSTokenLogitsProcessor\",\n",
      "            \"TFForcedEOSTokenLogitsProcessor\",\n",
      "            \"TFForceTokensLogitsProcessor\",\n",
      "            \"TFGenerationMixin\",\n",
      "            \"TFLogitsProcessor\",\n",
      "            \"TFLogitsProcessorList\",\n",
      "            \"TFLogitsWarper\",\n",
      "            \"TFMinLengthLogitsProcessor\",\n",
      "            \"TFNoBadWordsLogitsProcessor\",\n",
      "            \"TFNoRepeatNGramLogitsProcessor\",\n",
      "            \"TFRepetitionPenaltyLogitsProcessor\",\n",
      "            \"TFSuppressTokensAtBeginLogitsProcessor\",\n",
      "            \"TFSuppressTokensLogitsProcessor\",\n",
      "            \"TFTemperatureLogitsWarper\",\n",
      "            \"TFTopKLogitsWarper\",\n",
      "            \"TFTopPLogitsWarper\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"keras_callbacks\"] = [\"KerasMetricCallback\", \"PushToHubCallback\"]\n",
      "    _import_structure[\"modeling_tf_outputs\"] = []\n",
      "    _import_structure[\"modeling_tf_utils\"] = [\n",
      "        \"TFPreTrainedModel\",\n",
      "        \"TFSequenceSummary\",\n",
      "        \"TFSharedEmbeddings\",\n",
      "        \"shape_list\",\n",
      "    ]\n",
      "    # TensorFlow models structure\n",
      "    _import_structure[\"models.albert\"].extend(\n",
      "        [\n",
      "            \"TFAlbertForMaskedLM\",\n",
      "            \"TFAlbertForMultipleChoice\",\n",
      "            \"TFAlbertForPreTraining\",\n",
      "            \"TFAlbertForQuestionAnswering\",\n",
      "            \"TFAlbertForSequenceClassification\",\n",
      "            \"TFAlbertForTokenClassification\",\n",
      "            \"TFAlbertMainLayer\",\n",
      "            \"TFAlbertModel\",\n",
      "            \"TFAlbertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.auto\"].extend(\n",
      "        [\n",
      "            \"TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\",\n",
      "            \"TF_MODEL_FOR_CAUSAL_LM_MAPPING\",\n",
      "            \"TF_MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"TF_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING\",\n",
      "            \"TF_MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING\",\n",
      "            \"TF_MODEL_FOR_MASKED_LM_MAPPING\",\n",
      "            \"TF_MODEL_FOR_MASK_GENERATION_MAPPING\",\n",
      "            \"TF_MODEL_FOR_MULTIPLE_CHOICE_MAPPING\",\n",
      "            \"TF_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING\",\n",
      "            \"TF_MODEL_FOR_PRETRAINING_MAPPING\",\n",
      "            \"TF_MODEL_FOR_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"TF_MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING\",\n",
      "            \"TF_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING\",\n",
      "            \"TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\",\n",
      "            \"TF_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING\",\n",
      "            \"TF_MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"TF_MODEL_FOR_TEXT_ENCODING_MAPPING\",\n",
      "            \"TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\",\n",
      "            \"TF_MODEL_FOR_VISION_2_SEQ_MAPPING\",\n",
      "            \"TF_MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING\",\n",
      "            \"TF_MODEL_MAPPING\",\n",
      "            \"TF_MODEL_WITH_LM_HEAD_MAPPING\",\n",
      "            \"TFAutoModel\",\n",
      "            \"TFAutoModelForAudioClassification\",\n",
      "            \"TFAutoModelForCausalLM\",\n",
      "            \"TFAutoModelForDocumentQuestionAnswering\",\n",
      "            \"TFAutoModelForImageClassification\",\n",
      "            \"TFAutoModelForMaskedImageModeling\",\n",
      "            \"TFAutoModelForMaskedLM\",\n",
      "            \"TFAutoModelForMaskGeneration\",\n",
      "            \"TFAutoModelForMultipleChoice\",\n",
      "            \"TFAutoModelForNextSentencePrediction\",\n",
      "            \"TFAutoModelForPreTraining\",\n",
      "            \"TFAutoModelForQuestionAnswering\",\n",
      "            \"TFAutoModelForSemanticSegmentation\",\n",
      "            \"TFAutoModelForSeq2SeqLM\",\n",
      "            \"TFAutoModelForSequenceClassification\",\n",
      "            \"TFAutoModelForSpeechSeq2Seq\",\n",
      "            \"TFAutoModelForTableQuestionAnswering\",\n",
      "            \"TFAutoModelForTextEncoding\",\n",
      "            \"TFAutoModelForTokenClassification\",\n",
      "            \"TFAutoModelForVision2Seq\",\n",
      "            \"TFAutoModelForZeroShotImageClassification\",\n",
      "            \"TFAutoModelWithLMHead\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bart\"].extend(\n",
      "        [\n",
      "            \"TFBartForConditionalGeneration\",\n",
      "            \"TFBartForSequenceClassification\",\n",
      "            \"TFBartModel\",\n",
      "            \"TFBartPretrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bert\"].extend(\n",
      "        [\n",
      "            \"TFBertForMaskedLM\",\n",
      "            \"TFBertForMultipleChoice\",\n",
      "            \"TFBertForNextSentencePrediction\",\n",
      "            \"TFBertForPreTraining\",\n",
      "            \"TFBertForQuestionAnswering\",\n",
      "            \"TFBertForSequenceClassification\",\n",
      "            \"TFBertForTokenClassification\",\n",
      "            \"TFBertLMHeadModel\",\n",
      "            \"TFBertMainLayer\",\n",
      "            \"TFBertModel\",\n",
      "            \"TFBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blenderbot\"].extend(\n",
      "        [\n",
      "            \"TFBlenderbotForConditionalGeneration\",\n",
      "            \"TFBlenderbotModel\",\n",
      "            \"TFBlenderbotPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blenderbot_small\"].extend(\n",
      "        [\n",
      "            \"TFBlenderbotSmallForConditionalGeneration\",\n",
      "            \"TFBlenderbotSmallModel\",\n",
      "            \"TFBlenderbotSmallPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blip\"].extend(\n",
      "        [\n",
      "            \"TFBlipForConditionalGeneration\",\n",
      "            \"TFBlipForImageTextRetrieval\",\n",
      "            \"TFBlipForQuestionAnswering\",\n",
      "            \"TFBlipModel\",\n",
      "            \"TFBlipPreTrainedModel\",\n",
      "            \"TFBlipTextModel\",\n",
      "            \"TFBlipVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.camembert\"].extend(\n",
      "        [\n",
      "            \"TFCamembertForCausalLM\",\n",
      "            \"TFCamembertForMaskedLM\",\n",
      "            \"TFCamembertForMultipleChoice\",\n",
      "            \"TFCamembertForQuestionAnswering\",\n",
      "            \"TFCamembertForSequenceClassification\",\n",
      "            \"TFCamembertForTokenClassification\",\n",
      "            \"TFCamembertModel\",\n",
      "            \"TFCamembertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.clip\"].extend(\n",
      "        [\n",
      "            \"TFCLIPModel\",\n",
      "            \"TFCLIPPreTrainedModel\",\n",
      "            \"TFCLIPTextModel\",\n",
      "            \"TFCLIPVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.convbert\"].extend(\n",
      "        [\n",
      "            \"TFConvBertForMaskedLM\",\n",
      "            \"TFConvBertForMultipleChoice\",\n",
      "            \"TFConvBertForQuestionAnswering\",\n",
      "            \"TFConvBertForSequenceClassification\",\n",
      "            \"TFConvBertForTokenClassification\",\n",
      "            \"TFConvBertModel\",\n",
      "            \"TFConvBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.convnext\"].extend(\n",
      "        [\n",
      "            \"TFConvNextForImageClassification\",\n",
      "            \"TFConvNextModel\",\n",
      "            \"TFConvNextPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.convnextv2\"].extend(\n",
      "        [\n",
      "            \"TFConvNextV2ForImageClassification\",\n",
      "            \"TFConvNextV2Model\",\n",
      "            \"TFConvNextV2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.ctrl\"].extend(\n",
      "        [\n",
      "            \"TFCTRLForSequenceClassification\",\n",
      "            \"TFCTRLLMHeadModel\",\n",
      "            \"TFCTRLModel\",\n",
      "            \"TFCTRLPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.cvt\"].extend(\n",
      "        [\n",
      "            \"TFCvtForImageClassification\",\n",
      "            \"TFCvtModel\",\n",
      "            \"TFCvtPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.data2vec\"].extend(\n",
      "        [\n",
      "            \"TFData2VecVisionForImageClassification\",\n",
      "            \"TFData2VecVisionForSemanticSegmentation\",\n",
      "            \"TFData2VecVisionModel\",\n",
      "            \"TFData2VecVisionPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deberta\"].extend(\n",
      "        [\n",
      "            \"TFDebertaForMaskedLM\",\n",
      "            \"TFDebertaForQuestionAnswering\",\n",
      "            \"TFDebertaForSequenceClassification\",\n",
      "            \"TFDebertaForTokenClassification\",\n",
      "            \"TFDebertaModel\",\n",
      "            \"TFDebertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deberta_v2\"].extend(\n",
      "        [\n",
      "            \"TFDebertaV2ForMaskedLM\",\n",
      "            \"TFDebertaV2ForMultipleChoice\",\n",
      "            \"TFDebertaV2ForQuestionAnswering\",\n",
      "            \"TFDebertaV2ForSequenceClassification\",\n",
      "            \"TFDebertaV2ForTokenClassification\",\n",
      "            \"TFDebertaV2Model\",\n",
      "            \"TFDebertaV2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deit\"].extend(\n",
      "        [\n",
      "            \"TFDeiTForImageClassification\",\n",
      "            \"TFDeiTForImageClassificationWithTeacher\",\n",
      "            \"TFDeiTForMaskedImageModeling\",\n",
      "            \"TFDeiTModel\",\n",
      "            \"TFDeiTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.efficientformer\"].extend(\n",
      "        [\n",
      "            \"TFEfficientFormerForImageClassification\",\n",
      "            \"TFEfficientFormerForImageClassificationWithTeacher\",\n",
      "            \"TFEfficientFormerModel\",\n",
      "            \"TFEfficientFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.deprecated.transfo_xl\"].extend(\n",
      "        [\n",
      "            \"TFAdaptiveEmbedding\",\n",
      "            \"TFTransfoXLForSequenceClassification\",\n",
      "            \"TFTransfoXLLMHeadModel\",\n",
      "            \"TFTransfoXLMainLayer\",\n",
      "            \"TFTransfoXLModel\",\n",
      "            \"TFTransfoXLPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.distilbert\"].extend(\n",
      "        [\n",
      "            \"TFDistilBertForMaskedLM\",\n",
      "            \"TFDistilBertForMultipleChoice\",\n",
      "            \"TFDistilBertForQuestionAnswering\",\n",
      "            \"TFDistilBertForSequenceClassification\",\n",
      "            \"TFDistilBertForTokenClassification\",\n",
      "            \"TFDistilBertMainLayer\",\n",
      "            \"TFDistilBertModel\",\n",
      "            \"TFDistilBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dpr\"].extend(\n",
      "        [\n",
      "            \"TFDPRContextEncoder\",\n",
      "            \"TFDPRPretrainedContextEncoder\",\n",
      "            \"TFDPRPretrainedQuestionEncoder\",\n",
      "            \"TFDPRPretrainedReader\",\n",
      "            \"TFDPRQuestionEncoder\",\n",
      "            \"TFDPRReader\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.electra\"].extend(\n",
      "        [\n",
      "            \"TFElectraForMaskedLM\",\n",
      "            \"TFElectraForMultipleChoice\",\n",
      "            \"TFElectraForPreTraining\",\n",
      "            \"TFElectraForQuestionAnswering\",\n",
      "            \"TFElectraForSequenceClassification\",\n",
      "            \"TFElectraForTokenClassification\",\n",
      "            \"TFElectraModel\",\n",
      "            \"TFElectraPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.encoder_decoder\"].append(\"TFEncoderDecoderModel\")\n",
      "    _import_structure[\"models.esm\"].extend(\n",
      "        [\n",
      "            \"TFEsmForMaskedLM\",\n",
      "            \"TFEsmForSequenceClassification\",\n",
      "            \"TFEsmForTokenClassification\",\n",
      "            \"TFEsmModel\",\n",
      "            \"TFEsmPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.flaubert\"].extend(\n",
      "        [\n",
      "            \"TFFlaubertForMultipleChoice\",\n",
      "            \"TFFlaubertForQuestionAnsweringSimple\",\n",
      "            \"TFFlaubertForSequenceClassification\",\n",
      "            \"TFFlaubertForTokenClassification\",\n",
      "            \"TFFlaubertModel\",\n",
      "            \"TFFlaubertPreTrainedModel\",\n",
      "            \"TFFlaubertWithLMHeadModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.funnel\"].extend(\n",
      "        [\n",
      "            \"TFFunnelBaseModel\",\n",
      "            \"TFFunnelForMaskedLM\",\n",
      "            \"TFFunnelForMultipleChoice\",\n",
      "            \"TFFunnelForPreTraining\",\n",
      "            \"TFFunnelForQuestionAnswering\",\n",
      "            \"TFFunnelForSequenceClassification\",\n",
      "            \"TFFunnelForTokenClassification\",\n",
      "            \"TFFunnelModel\",\n",
      "            \"TFFunnelPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gpt2\"].extend(\n",
      "        [\n",
      "            \"TFGPT2DoubleHeadsModel\",\n",
      "            \"TFGPT2ForSequenceClassification\",\n",
      "            \"TFGPT2LMHeadModel\",\n",
      "            \"TFGPT2MainLayer\",\n",
      "            \"TFGPT2Model\",\n",
      "            \"TFGPT2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.gptj\"].extend(\n",
      "        [\n",
      "            \"TFGPTJForCausalLM\",\n",
      "            \"TFGPTJForQuestionAnswering\",\n",
      "            \"TFGPTJForSequenceClassification\",\n",
      "            \"TFGPTJModel\",\n",
      "            \"TFGPTJPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.groupvit\"].extend(\n",
      "        [\n",
      "            \"TFGroupViTModel\",\n",
      "            \"TFGroupViTPreTrainedModel\",\n",
      "            \"TFGroupViTTextModel\",\n",
      "            \"TFGroupViTVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.hubert\"].extend(\n",
      "        [\n",
      "            \"TFHubertForCTC\",\n",
      "            \"TFHubertModel\",\n",
      "            \"TFHubertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    _import_structure[\"models.idefics\"].extend(\n",
      "        [\n",
      "            \"TFIdeficsForVisionText2Text\",\n",
      "            \"TFIdeficsModel\",\n",
      "            \"TFIdeficsPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    _import_structure[\"models.layoutlm\"].extend(\n",
      "        [\n",
      "            \"TFLayoutLMForMaskedLM\",\n",
      "            \"TFLayoutLMForQuestionAnswering\",\n",
      "            \"TFLayoutLMForSequenceClassification\",\n",
      "            \"TFLayoutLMForTokenClassification\",\n",
      "            \"TFLayoutLMMainLayer\",\n",
      "            \"TFLayoutLMModel\",\n",
      "            \"TFLayoutLMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.layoutlmv3\"].extend(\n",
      "        [\n",
      "            \"TFLayoutLMv3ForQuestionAnswering\",\n",
      "            \"TFLayoutLMv3ForSequenceClassification\",\n",
      "            \"TFLayoutLMv3ForTokenClassification\",\n",
      "            \"TFLayoutLMv3Model\",\n",
      "            \"TFLayoutLMv3PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.led\"].extend([\"TFLEDForConditionalGeneration\", \"TFLEDModel\", \"TFLEDPreTrainedModel\"])\n",
      "    _import_structure[\"models.longformer\"].extend(\n",
      "        [\n",
      "            \"TFLongformerForMaskedLM\",\n",
      "            \"TFLongformerForMultipleChoice\",\n",
      "            \"TFLongformerForQuestionAnswering\",\n",
      "            \"TFLongformerForSequenceClassification\",\n",
      "            \"TFLongformerForTokenClassification\",\n",
      "            \"TFLongformerModel\",\n",
      "            \"TFLongformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.lxmert\"].extend(\n",
      "        [\n",
      "            \"TFLxmertForPreTraining\",\n",
      "            \"TFLxmertMainLayer\",\n",
      "            \"TFLxmertModel\",\n",
      "            \"TFLxmertPreTrainedModel\",\n",
      "            \"TFLxmertVisualFeatureEncoder\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.marian\"].extend([\"TFMarianModel\", \"TFMarianMTModel\", \"TFMarianPreTrainedModel\"])\n",
      "    _import_structure[\"models.mbart\"].extend(\n",
      "        [\"TFMBartForConditionalGeneration\", \"TFMBartModel\", \"TFMBartPreTrainedModel\"]\n",
      "    )\n",
      "    _import_structure[\"models.mistral\"].extend(\n",
      "        [\"TFMistralForCausalLM\", \"TFMistralForSequenceClassification\", \"TFMistralModel\", \"TFMistralPreTrainedModel\"]\n",
      "    )\n",
      "    _import_structure[\"models.mobilebert\"].extend(\n",
      "        [\n",
      "            \"TFMobileBertForMaskedLM\",\n",
      "            \"TFMobileBertForMultipleChoice\",\n",
      "            \"TFMobileBertForNextSentencePrediction\",\n",
      "            \"TFMobileBertForPreTraining\",\n",
      "            \"TFMobileBertForQuestionAnswering\",\n",
      "            \"TFMobileBertForSequenceClassification\",\n",
      "            \"TFMobileBertForTokenClassification\",\n",
      "            \"TFMobileBertMainLayer\",\n",
      "            \"TFMobileBertModel\",\n",
      "            \"TFMobileBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mobilevit\"].extend(\n",
      "        [\n",
      "            \"TFMobileViTForImageClassification\",\n",
      "            \"TFMobileViTForSemanticSegmentation\",\n",
      "            \"TFMobileViTModel\",\n",
      "            \"TFMobileViTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mpnet\"].extend(\n",
      "        [\n",
      "            \"TFMPNetForMaskedLM\",\n",
      "            \"TFMPNetForMultipleChoice\",\n",
      "            \"TFMPNetForQuestionAnswering\",\n",
      "            \"TFMPNetForSequenceClassification\",\n",
      "            \"TFMPNetForTokenClassification\",\n",
      "            \"TFMPNetMainLayer\",\n",
      "            \"TFMPNetModel\",\n",
      "            \"TFMPNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mt5\"].extend([\"TFMT5EncoderModel\", \"TFMT5ForConditionalGeneration\", \"TFMT5Model\"])\n",
      "    _import_structure[\"models.openai\"].extend(\n",
      "        [\n",
      "            \"TFOpenAIGPTDoubleHeadsModel\",\n",
      "            \"TFOpenAIGPTForSequenceClassification\",\n",
      "            \"TFOpenAIGPTLMHeadModel\",\n",
      "            \"TFOpenAIGPTMainLayer\",\n",
      "            \"TFOpenAIGPTModel\",\n",
      "            \"TFOpenAIGPTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.opt\"].extend(\n",
      "        [\n",
      "            \"TFOPTForCausalLM\",\n",
      "            \"TFOPTModel\",\n",
      "            \"TFOPTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pegasus\"].extend(\n",
      "        [\n",
      "            \"TFPegasusForConditionalGeneration\",\n",
      "            \"TFPegasusModel\",\n",
      "            \"TFPegasusPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.rag\"].extend(\n",
      "        [\n",
      "            \"TFRagModel\",\n",
      "            \"TFRagPreTrainedModel\",\n",
      "            \"TFRagSequenceForGeneration\",\n",
      "            \"TFRagTokenForGeneration\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.regnet\"].extend(\n",
      "        [\n",
      "            \"TFRegNetForImageClassification\",\n",
      "            \"TFRegNetModel\",\n",
      "            \"TFRegNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.rembert\"].extend(\n",
      "        [\n",
      "            \"TFRemBertForCausalLM\",\n",
      "            \"TFRemBertForMaskedLM\",\n",
      "            \"TFRemBertForMultipleChoice\",\n",
      "            \"TFRemBertForQuestionAnswering\",\n",
      "            \"TFRemBertForSequenceClassification\",\n",
      "            \"TFRemBertForTokenClassification\",\n",
      "            \"TFRemBertModel\",\n",
      "            \"TFRemBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.resnet\"].extend(\n",
      "        [\n",
      "            \"TFResNetForImageClassification\",\n",
      "            \"TFResNetModel\",\n",
      "            \"TFResNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roberta\"].extend(\n",
      "        [\n",
      "            \"TFRobertaForCausalLM\",\n",
      "            \"TFRobertaForMaskedLM\",\n",
      "            \"TFRobertaForMultipleChoice\",\n",
      "            \"TFRobertaForQuestionAnswering\",\n",
      "            \"TFRobertaForSequenceClassification\",\n",
      "            \"TFRobertaForTokenClassification\",\n",
      "            \"TFRobertaMainLayer\",\n",
      "            \"TFRobertaModel\",\n",
      "            \"TFRobertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roberta_prelayernorm\"].extend(\n",
      "        [\n",
      "            \"TFRobertaPreLayerNormForCausalLM\",\n",
      "            \"TFRobertaPreLayerNormForMaskedLM\",\n",
      "            \"TFRobertaPreLayerNormForMultipleChoice\",\n",
      "            \"TFRobertaPreLayerNormForQuestionAnswering\",\n",
      "            \"TFRobertaPreLayerNormForSequenceClassification\",\n",
      "            \"TFRobertaPreLayerNormForTokenClassification\",\n",
      "            \"TFRobertaPreLayerNormMainLayer\",\n",
      "            \"TFRobertaPreLayerNormModel\",\n",
      "            \"TFRobertaPreLayerNormPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roformer\"].extend(\n",
      "        [\n",
      "            \"TFRoFormerForCausalLM\",\n",
      "            \"TFRoFormerForMaskedLM\",\n",
      "            \"TFRoFormerForMultipleChoice\",\n",
      "            \"TFRoFormerForQuestionAnswering\",\n",
      "            \"TFRoFormerForSequenceClassification\",\n",
      "            \"TFRoFormerForTokenClassification\",\n",
      "            \"TFRoFormerModel\",\n",
      "            \"TFRoFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.sam\"].extend(\n",
      "        [\n",
      "            \"TFSamModel\",\n",
      "            \"TFSamPreTrainedModel\",\n",
      "            \"TFSamVisionModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.segformer\"].extend(\n",
      "        [\n",
      "            \"TFSegformerDecodeHead\",\n",
      "            \"TFSegformerForImageClassification\",\n",
      "            \"TFSegformerForSemanticSegmentation\",\n",
      "            \"TFSegformerModel\",\n",
      "            \"TFSegformerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.speech_to_text\"].extend(\n",
      "        [\n",
      "            \"TFSpeech2TextForConditionalGeneration\",\n",
      "            \"TFSpeech2TextModel\",\n",
      "            \"TFSpeech2TextPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.swiftformer\"].extend(\n",
      "        [\n",
      "            \"TFSwiftFormerForImageClassification\",\n",
      "            \"TFSwiftFormerModel\",\n",
      "            \"TFSwiftFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.swin\"].extend(\n",
      "        [\n",
      "            \"TFSwinForImageClassification\",\n",
      "            \"TFSwinForMaskedImageModeling\",\n",
      "            \"TFSwinModel\",\n",
      "            \"TFSwinPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.t5\"].extend(\n",
      "        [\n",
      "            \"TFT5EncoderModel\",\n",
      "            \"TFT5ForConditionalGeneration\",\n",
      "            \"TFT5Model\",\n",
      "            \"TFT5PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.tapas\"].extend(\n",
      "        [\n",
      "            \"TFTapasForMaskedLM\",\n",
      "            \"TFTapasForQuestionAnswering\",\n",
      "            \"TFTapasForSequenceClassification\",\n",
      "            \"TFTapasModel\",\n",
      "            \"TFTapasPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vision_encoder_decoder\"].extend([\"TFVisionEncoderDecoderModel\"])\n",
      "    _import_structure[\"models.vision_text_dual_encoder\"].extend([\"TFVisionTextDualEncoderModel\"])\n",
      "    _import_structure[\"models.vit\"].extend(\n",
      "        [\n",
      "            \"TFViTForImageClassification\",\n",
      "            \"TFViTModel\",\n",
      "            \"TFViTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vit_mae\"].extend(\n",
      "        [\n",
      "            \"TFViTMAEForPreTraining\",\n",
      "            \"TFViTMAEModel\",\n",
      "            \"TFViTMAEPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.wav2vec2\"].extend(\n",
      "        [\n",
      "            \"TFWav2Vec2ForCTC\",\n",
      "            \"TFWav2Vec2ForSequenceClassification\",\n",
      "            \"TFWav2Vec2Model\",\n",
      "            \"TFWav2Vec2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.whisper\"].extend(\n",
      "        [\n",
      "            \"TFWhisperForConditionalGeneration\",\n",
      "            \"TFWhisperModel\",\n",
      "            \"TFWhisperPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xglm\"].extend(\n",
      "        [\n",
      "            \"TFXGLMForCausalLM\",\n",
      "            \"TFXGLMModel\",\n",
      "            \"TFXGLMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlm\"].extend(\n",
      "        [\n",
      "            \"TFXLMForMultipleChoice\",\n",
      "            \"TFXLMForQuestionAnsweringSimple\",\n",
      "            \"TFXLMForSequenceClassification\",\n",
      "            \"TFXLMForTokenClassification\",\n",
      "            \"TFXLMMainLayer\",\n",
      "            \"TFXLMModel\",\n",
      "            \"TFXLMPreTrainedModel\",\n",
      "            \"TFXLMWithLMHeadModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlm_roberta\"].extend(\n",
      "        [\n",
      "            \"TFXLMRobertaForCausalLM\",\n",
      "            \"TFXLMRobertaForMaskedLM\",\n",
      "            \"TFXLMRobertaForMultipleChoice\",\n",
      "            \"TFXLMRobertaForQuestionAnswering\",\n",
      "            \"TFXLMRobertaForSequenceClassification\",\n",
      "            \"TFXLMRobertaForTokenClassification\",\n",
      "            \"TFXLMRobertaModel\",\n",
      "            \"TFXLMRobertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlnet\"].extend(\n",
      "        [\n",
      "            \"TFXLNetForMultipleChoice\",\n",
      "            \"TFXLNetForQuestionAnsweringSimple\",\n",
      "            \"TFXLNetForSequenceClassification\",\n",
      "            \"TFXLNetForTokenClassification\",\n",
      "            \"TFXLNetLMHeadModel\",\n",
      "            \"TFXLNetMainLayer\",\n",
      "            \"TFXLNetModel\",\n",
      "            \"TFXLNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"optimization_tf\"] = [\n",
      "        \"AdamWeightDecay\",\n",
      "        \"GradientAccumulator\",\n",
      "        \"WarmUp\",\n",
      "        \"create_optimizer\",\n",
      "    ]\n",
      "    _import_structure[\"tf_utils\"] = []\n",
      "\n",
      "\n",
      "try:\n",
      "    if not (\n",
      "        is_librosa_available()\n",
      "        and is_essentia_available()\n",
      "        and is_scipy_available()\n",
      "        and is_torch_available()\n",
      "        and is_pretty_midi_available()\n",
      "    ):\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import (\n",
      "        dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects,\n",
      "    )\n",
      "\n",
      "    _import_structure[\"utils.dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects\"] = [\n",
      "        name\n",
      "        for name in dir(dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects)\n",
      "        if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"models.pop2piano\"].append(\"Pop2PianoFeatureExtractor\")\n",
      "    _import_structure[\"models.pop2piano\"].append(\"Pop2PianoTokenizer\")\n",
      "    _import_structure[\"models.pop2piano\"].append(\"Pop2PianoProcessor\")\n",
      "\n",
      "try:\n",
      "    if not is_torchaudio_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import (\n",
      "        dummy_torchaudio_objects,\n",
      "    )\n",
      "\n",
      "    _import_structure[\"utils.dummy_torchaudio_objects\"] = [\n",
      "        name for name in dir(dummy_torchaudio_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"models.musicgen_melody\"].append(\"MusicgenMelodyFeatureExtractor\")\n",
      "    _import_structure[\"models.musicgen_melody\"].append(\"MusicgenMelodyProcessor\")\n",
      "\n",
      "\n",
      "# FLAX-backed objects\n",
      "try:\n",
      "    if not is_flax_available():\n",
      "        raise OptionalDependencyNotAvailable()\n",
      "except OptionalDependencyNotAvailable:\n",
      "    from .utils import dummy_flax_objects\n",
      "\n",
      "    _import_structure[\"utils.dummy_flax_objects\"] = [\n",
      "        name for name in dir(dummy_flax_objects) if not name.startswith(\"_\")\n",
      "    ]\n",
      "else:\n",
      "    _import_structure[\"generation\"].extend(\n",
      "        [\n",
      "            \"FlaxForcedBOSTokenLogitsProcessor\",\n",
      "            \"FlaxForcedEOSTokenLogitsProcessor\",\n",
      "            \"FlaxForceTokensLogitsProcessor\",\n",
      "            \"FlaxGenerationMixin\",\n",
      "            \"FlaxLogitsProcessor\",\n",
      "            \"FlaxLogitsProcessorList\",\n",
      "            \"FlaxLogitsWarper\",\n",
      "            \"FlaxMinLengthLogitsProcessor\",\n",
      "            \"FlaxTemperatureLogitsWarper\",\n",
      "            \"FlaxSuppressTokensAtBeginLogitsProcessor\",\n",
      "            \"FlaxSuppressTokensLogitsProcessor\",\n",
      "            \"FlaxTopKLogitsWarper\",\n",
      "            \"FlaxTopPLogitsWarper\",\n",
      "            \"FlaxWhisperTimeStampLogitsProcessor\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"modeling_flax_outputs\"] = []\n",
      "    _import_structure[\"modeling_flax_utils\"] = [\"FlaxPreTrainedModel\"]\n",
      "    _import_structure[\"models.albert\"].extend(\n",
      "        [\n",
      "            \"FlaxAlbertForMaskedLM\",\n",
      "            \"FlaxAlbertForMultipleChoice\",\n",
      "            \"FlaxAlbertForPreTraining\",\n",
      "            \"FlaxAlbertForQuestionAnswering\",\n",
      "            \"FlaxAlbertForSequenceClassification\",\n",
      "            \"FlaxAlbertForTokenClassification\",\n",
      "            \"FlaxAlbertModel\",\n",
      "            \"FlaxAlbertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.auto\"].extend(\n",
      "        [\n",
      "            \"FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_CAUSAL_LM_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_MASKED_LM_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_PRETRAINING_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\",\n",
      "            \"FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING\",\n",
      "            \"FLAX_MODEL_MAPPING\",\n",
      "            \"FlaxAutoModel\",\n",
      "            \"FlaxAutoModelForCausalLM\",\n",
      "            \"FlaxAutoModelForImageClassification\",\n",
      "            \"FlaxAutoModelForMaskedLM\",\n",
      "            \"FlaxAutoModelForMultipleChoice\",\n",
      "            \"FlaxAutoModelForNextSentencePrediction\",\n",
      "            \"FlaxAutoModelForPreTraining\",\n",
      "            \"FlaxAutoModelForQuestionAnswering\",\n",
      "            \"FlaxAutoModelForSeq2SeqLM\",\n",
      "            \"FlaxAutoModelForSequenceClassification\",\n",
      "            \"FlaxAutoModelForSpeechSeq2Seq\",\n",
      "            \"FlaxAutoModelForTokenClassification\",\n",
      "            \"FlaxAutoModelForVision2Seq\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    # Flax models structure\n",
      "\n",
      "    _import_structure[\"models.bart\"].extend(\n",
      "        [\n",
      "            \"FlaxBartDecoderPreTrainedModel\",\n",
      "            \"FlaxBartForCausalLM\",\n",
      "            \"FlaxBartForConditionalGeneration\",\n",
      "            \"FlaxBartForQuestionAnswering\",\n",
      "            \"FlaxBartForSequenceClassification\",\n",
      "            \"FlaxBartModel\",\n",
      "            \"FlaxBartPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.beit\"].extend(\n",
      "        [\n",
      "            \"FlaxBeitForImageClassification\",\n",
      "            \"FlaxBeitForMaskedImageModeling\",\n",
      "            \"FlaxBeitModel\",\n",
      "            \"FlaxBeitPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    _import_structure[\"models.bert\"].extend(\n",
      "        [\n",
      "            \"FlaxBertForCausalLM\",\n",
      "            \"FlaxBertForMaskedLM\",\n",
      "            \"FlaxBertForMultipleChoice\",\n",
      "            \"FlaxBertForNextSentencePrediction\",\n",
      "            \"FlaxBertForPreTraining\",\n",
      "            \"FlaxBertForQuestionAnswering\",\n",
      "            \"FlaxBertForSequenceClassification\",\n",
      "            \"FlaxBertForTokenClassification\",\n",
      "            \"FlaxBertModel\",\n",
      "            \"FlaxBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.big_bird\"].extend(\n",
      "        [\n",
      "            \"FlaxBigBirdForCausalLM\",\n",
      "            \"FlaxBigBirdForMaskedLM\",\n",
      "            \"FlaxBigBirdForMultipleChoice\",\n",
      "            \"FlaxBigBirdForPreTraining\",\n",
      "            \"FlaxBigBirdForQuestionAnswering\",\n",
      "            \"FlaxBigBirdForSequenceClassification\",\n",
      "            \"FlaxBigBirdForTokenClassification\",\n",
      "            \"FlaxBigBirdModel\",\n",
      "            \"FlaxBigBirdPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blenderbot\"].extend(\n",
      "        [\n",
      "            \"FlaxBlenderbotForConditionalGeneration\",\n",
      "            \"FlaxBlenderbotModel\",\n",
      "            \"FlaxBlenderbotPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.blenderbot_small\"].extend(\n",
      "        [\n",
      "            \"FlaxBlenderbotSmallForConditionalGeneration\",\n",
      "            \"FlaxBlenderbotSmallModel\",\n",
      "            \"FlaxBlenderbotSmallPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.bloom\"].extend(\n",
      "        [\n",
      "            \"FlaxBloomForCausalLM\",\n",
      "            \"FlaxBloomModel\",\n",
      "            \"FlaxBloomPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.clip\"].extend(\n",
      "        [\n",
      "            \"FlaxCLIPModel\",\n",
      "            \"FlaxCLIPPreTrainedModel\",\n",
      "            \"FlaxCLIPTextModel\",\n",
      "            \"FlaxCLIPTextPreTrainedModel\",\n",
      "            \"FlaxCLIPTextModelWithProjection\",\n",
      "            \"FlaxCLIPVisionModel\",\n",
      "            \"FlaxCLIPVisionPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.dinov2\"].extend(\n",
      "        [\n",
      "            \"FlaxDinov2Model\",\n",
      "            \"FlaxDinov2ForImageClassification\",\n",
      "            \"FlaxDinov2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.distilbert\"].extend(\n",
      "        [\n",
      "            \"FlaxDistilBertForMaskedLM\",\n",
      "            \"FlaxDistilBertForMultipleChoice\",\n",
      "            \"FlaxDistilBertForQuestionAnswering\",\n",
      "            \"FlaxDistilBertForSequenceClassification\",\n",
      "            \"FlaxDistilBertForTokenClassification\",\n",
      "            \"FlaxDistilBertModel\",\n",
      "            \"FlaxDistilBertPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.electra\"].extend(\n",
      "        [\n",
      "            \"FlaxElectraForCausalLM\",\n",
      "            \"FlaxElectraForMaskedLM\",\n",
      "            \"FlaxElectraForMultipleChoice\",\n",
      "            \"FlaxElectraForPreTraining\",\n",
      "            \"FlaxElectraForQuestionAnswering\",\n",
      "            \"FlaxElectraForSequenceClassification\",\n",
      "            \"FlaxElectraForTokenClassification\",\n",
      "            \"FlaxElectraModel\",\n",
      "            \"FlaxElectraPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.encoder_decoder\"].append(\"FlaxEncoderDecoderModel\")\n",
      "    _import_structure[\"models.gpt2\"].extend([\"FlaxGPT2LMHeadModel\", \"FlaxGPT2Model\", \"FlaxGPT2PreTrainedModel\"])\n",
      "    _import_structure[\"models.gpt_neo\"].extend(\n",
      "        [\"FlaxGPTNeoForCausalLM\", \"FlaxGPTNeoModel\", \"FlaxGPTNeoPreTrainedModel\"]\n",
      "    )\n",
      "    _import_structure[\"models.gptj\"].extend([\"FlaxGPTJForCausalLM\", \"FlaxGPTJModel\", \"FlaxGPTJPreTrainedModel\"])\n",
      "    _import_structure[\"models.llama\"].extend([\"FlaxLlamaForCausalLM\", \"FlaxLlamaModel\", \"FlaxLlamaPreTrainedModel\"])\n",
      "    _import_structure[\"models.gemma\"].extend([\"FlaxGemmaForCausalLM\", \"FlaxGemmaModel\", \"FlaxGemmaPreTrainedModel\"])\n",
      "    _import_structure[\"models.longt5\"].extend(\n",
      "        [\n",
      "            \"FlaxLongT5ForConditionalGeneration\",\n",
      "            \"FlaxLongT5Model\",\n",
      "            \"FlaxLongT5PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.marian\"].extend(\n",
      "        [\n",
      "            \"FlaxMarianModel\",\n",
      "            \"FlaxMarianMTModel\",\n",
      "            \"FlaxMarianPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mbart\"].extend(\n",
      "        [\n",
      "            \"FlaxMBartForConditionalGeneration\",\n",
      "            \"FlaxMBartForQuestionAnswering\",\n",
      "            \"FlaxMBartForSequenceClassification\",\n",
      "            \"FlaxMBartModel\",\n",
      "            \"FlaxMBartPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mistral\"].extend(\n",
      "        [\n",
      "            \"FlaxMistralForCausalLM\",\n",
      "            \"FlaxMistralModel\",\n",
      "            \"FlaxMistralPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.mt5\"].extend([\"FlaxMT5EncoderModel\", \"FlaxMT5ForConditionalGeneration\", \"FlaxMT5Model\"])\n",
      "    _import_structure[\"models.opt\"].extend(\n",
      "        [\n",
      "            \"FlaxOPTForCausalLM\",\n",
      "            \"FlaxOPTModel\",\n",
      "            \"FlaxOPTPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.pegasus\"].extend(\n",
      "        [\n",
      "            \"FlaxPegasusForConditionalGeneration\",\n",
      "            \"FlaxPegasusModel\",\n",
      "            \"FlaxPegasusPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.regnet\"].extend(\n",
      "        [\n",
      "            \"FlaxRegNetForImageClassification\",\n",
      "            \"FlaxRegNetModel\",\n",
      "            \"FlaxRegNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.resnet\"].extend(\n",
      "        [\n",
      "            \"FlaxResNetForImageClassification\",\n",
      "            \"FlaxResNetModel\",\n",
      "            \"FlaxResNetPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roberta\"].extend(\n",
      "        [\n",
      "            \"FlaxRobertaForCausalLM\",\n",
      "            \"FlaxRobertaForMaskedLM\",\n",
      "            \"FlaxRobertaForMultipleChoice\",\n",
      "            \"FlaxRobertaForQuestionAnswering\",\n",
      "            \"FlaxRobertaForSequenceClassification\",\n",
      "            \"FlaxRobertaForTokenClassification\",\n",
      "            \"FlaxRobertaModel\",\n",
      "            \"FlaxRobertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roberta_prelayernorm\"].extend(\n",
      "        [\n",
      "            \"FlaxRobertaPreLayerNormForCausalLM\",\n",
      "            \"FlaxRobertaPreLayerNormForMaskedLM\",\n",
      "            \"FlaxRobertaPreLayerNormForMultipleChoice\",\n",
      "            \"FlaxRobertaPreLayerNormForQuestionAnswering\",\n",
      "            \"FlaxRobertaPreLayerNormForSequenceClassification\",\n",
      "            \"FlaxRobertaPreLayerNormForTokenClassification\",\n",
      "            \"FlaxRobertaPreLayerNormModel\",\n",
      "            \"FlaxRobertaPreLayerNormPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.roformer\"].extend(\n",
      "        [\n",
      "            \"FlaxRoFormerForMaskedLM\",\n",
      "            \"FlaxRoFormerForMultipleChoice\",\n",
      "            \"FlaxRoFormerForQuestionAnswering\",\n",
      "            \"FlaxRoFormerForSequenceClassification\",\n",
      "            \"FlaxRoFormerForTokenClassification\",\n",
      "            \"FlaxRoFormerModel\",\n",
      "            \"FlaxRoFormerPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.speech_encoder_decoder\"].append(\"FlaxSpeechEncoderDecoderModel\")\n",
      "    _import_structure[\"models.t5\"].extend(\n",
      "        [\n",
      "            \"FlaxT5EncoderModel\",\n",
      "            \"FlaxT5ForConditionalGeneration\",\n",
      "            \"FlaxT5Model\",\n",
      "            \"FlaxT5PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.vision_encoder_decoder\"].append(\"FlaxVisionEncoderDecoderModel\")\n",
      "    _import_structure[\"models.vision_text_dual_encoder\"].extend([\"FlaxVisionTextDualEncoderModel\"])\n",
      "    _import_structure[\"models.vit\"].extend([\"FlaxViTForImageClassification\", \"FlaxViTModel\", \"FlaxViTPreTrainedModel\"])\n",
      "    _import_structure[\"models.wav2vec2\"].extend(\n",
      "        [\n",
      "            \"FlaxWav2Vec2ForCTC\",\n",
      "            \"FlaxWav2Vec2ForPreTraining\",\n",
      "            \"FlaxWav2Vec2Model\",\n",
      "            \"FlaxWav2Vec2PreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.whisper\"].extend(\n",
      "        [\n",
      "            \"FlaxWhisperForConditionalGeneration\",\n",
      "            \"FlaxWhisperModel\",\n",
      "            \"FlaxWhisperPreTrainedModel\",\n",
      "            \"FlaxWhisperForAudioClassification\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xglm\"].extend(\n",
      "        [\n",
      "            \"FlaxXGLMForCausalLM\",\n",
      "            \"FlaxXGLMModel\",\n",
      "            \"FlaxXGLMPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "    _import_structure[\"models.xlm_roberta\"].extend(\n",
      "        [\n",
      "            \"FlaxXLMRobertaForMaskedLM\",\n",
      "            \"FlaxXLMRobertaForMultipleChoice\",\n",
      "            \"FlaxXLMRobertaForQuestionAnswering\",\n",
      "            \"FlaxXLMRobertaForSequenceClassification\",\n",
      "            \"FlaxXLMRobertaForTokenClassification\",\n",
      "            \"FlaxXLMRobertaModel\",\n",
      "            \"FlaxXLMRobertaForCausalLM\",\n",
      "            \"FlaxXLMRobertaPreTrainedModel\",\n",
      "        ]\n",
      "    )\n",
      "\n",
      "\n",
      "# Direct imports for type-checking\n",
      "if TYPE_CHECKING:\n",
      "    # Configuration\n",
      "    # Agents\n",
      "    from .agents import (\n",
      "        Agent,\n",
      "        CodeAgent,\n",
      "        HfApiEngine,\n",
      "        ManagedAgent,\n",
      "        PipelineTool,\n",
      "        ReactAgent,\n",
      "        ReactCodeAgent,\n",
      "        ReactJsonAgent,\n",
      "        Tool,\n",
      "        Toolbox,\n",
      "        ToolCollection,\n",
      "        TransformersEngine,\n",
      "        launch_gradio_demo,\n",
      "        load_tool,\n",
      "        stream_to_gradio,\n",
      "        tool,\n",
      "    )\n",
      "    from .configuration_utils import PretrainedConfig\n",
      "\n",
      "    # Data\n",
      "    from .data import (\n",
      "        DataProcessor,\n",
      "        InputExample,\n",
      "        InputFeatures,\n",
      "        SingleSentenceClassificationProcessor,\n",
      "        SquadExample,\n",
      "        SquadFeatures,\n",
      "        SquadV1Processor,\n",
      "        SquadV2Processor,\n",
      "        glue_compute_metrics,\n",
      "        glue_convert_examples_to_features,\n",
      "        glue_output_modes,\n",
      "        glue_processors,\n",
      "        glue_tasks_num_labels,\n",
      "        squad_convert_examples_to_features,\n",
      "        xnli_compute_metrics,\n",
      "        xnli_output_modes,\n",
      "        xnli_processors,\n",
      "        xnli_tasks_num_labels,\n",
      "    )\n",
      "    from .data.data_collator import (\n",
      "        DataCollator,\n",
      "        DataCollatorForLanguageModeling,\n",
      "        DataCollatorForMultipleChoice,\n",
      "        DataCollatorForPermutationLanguageModeling,\n",
      "        DataCollatorForSeq2Seq,\n",
      "        DataCollatorForSOP,\n",
      "        DataCollatorForTokenClassification,\n",
      "        DataCollatorForWholeWordMask,\n",
      "        DataCollatorWithFlattening,\n",
      "        DataCollatorWithPadding,\n",
      "        DefaultDataCollator,\n",
      "        default_data_collator,\n",
      "    )\n",
      "    from .feature_extraction_sequence_utils import SequenceFeatureExtractor\n",
      "\n",
      "    # Feature Extractor\n",
      "    from .feature_extraction_utils import BatchFeature, FeatureExtractionMixin\n",
      "\n",
      "    # Generation\n",
      "    from .generation import (\n",
      "        AsyncTextIteratorStreamer,\n",
      "        CompileConfig,\n",
      "        GenerationConfig,\n",
      "        TextIteratorStreamer,\n",
      "        TextStreamer,\n",
      "        WatermarkingConfig,\n",
      "    )\n",
      "    from .hf_argparser import HfArgumentParser\n",
      "\n",
      "    # Integrations\n",
      "    from .integrations import (\n",
      "        is_clearml_available,\n",
      "        is_comet_available,\n",
      "        is_dvclive_available,\n",
      "        is_neptune_available,\n",
      "        is_optuna_available,\n",
      "        is_ray_available,\n",
      "        is_ray_tune_available,\n",
      "        is_sigopt_available,\n",
      "        is_swanlab_available,\n",
      "        is_tensorboard_available,\n",
      "        is_wandb_available,\n",
      "    )\n",
      "\n",
      "    # Model Cards\n",
      "    from .modelcard import ModelCard\n",
      "\n",
      "    # TF 2.0 <=> PyTorch conversion utilities\n",
      "    from .modeling_tf_pytorch_utils import (\n",
      "        convert_tf_weight_name_to_pt_weight_name,\n",
      "        load_pytorch_checkpoint_in_tf2_model,\n",
      "        load_pytorch_model_in_tf2_model,\n",
      "        load_pytorch_weights_in_tf2_model,\n",
      "        load_tf2_checkpoint_in_pytorch_model,\n",
      "        load_tf2_model_in_pytorch_model,\n",
      "        load_tf2_weights_in_pytorch_model,\n",
      "    )\n",
      "    from .models.albert import AlbertConfig\n",
      "    from .models.align import (\n",
      "        AlignConfig,\n",
      "        AlignProcessor,\n",
      "        AlignTextConfig,\n",
      "        AlignVisionConfig,\n",
      "    )\n",
      "    from .models.altclip import (\n",
      "        AltCLIPConfig,\n",
      "        AltCLIPProcessor,\n",
      "        AltCLIPTextConfig,\n",
      "        AltCLIPVisionConfig,\n",
      "    )\n",
      "    from .models.aria import (\n",
      "        AriaConfig,\n",
      "        AriaProcessor,\n",
      "        AriaTextConfig,\n",
      "    )\n",
      "    from .models.audio_spectrogram_transformer import (\n",
      "        ASTConfig,\n",
      "        ASTFeatureExtractor,\n",
      "    )\n",
      "    from .models.auto import (\n",
      "        CONFIG_MAPPING,\n",
      "        FEATURE_EXTRACTOR_MAPPING,\n",
      "        IMAGE_PROCESSOR_MAPPING,\n",
      "        MODEL_NAMES_MAPPING,\n",
      "        PROCESSOR_MAPPING,\n",
      "        TOKENIZER_MAPPING,\n",
      "        AutoConfig,\n",
      "        AutoFeatureExtractor,\n",
      "        AutoImageProcessor,\n",
      "        AutoProcessor,\n",
      "        AutoTokenizer,\n",
      "    )\n",
      "    from .models.autoformer import (\n",
      "        AutoformerConfig,\n",
      "    )\n",
      "    from .models.aya_vision import (\n",
      "        AyaVisionConfig,\n",
      "        AyaVisionProcessor,\n",
      "    )\n",
      "    from .models.bamba import BambaConfig\n",
      "    from .models.bark import (\n",
      "        BarkCoarseConfig,\n",
      "        BarkConfig,\n",
      "        BarkFineConfig,\n",
      "        BarkProcessor,\n",
      "        BarkSemanticConfig,\n",
      "    )\n",
      "    from .models.bart import BartConfig, BartTokenizer\n",
      "    from .models.beit import BeitConfig\n",
      "    from .models.bert import (\n",
      "        BasicTokenizer,\n",
      "        BertConfig,\n",
      "        BertTokenizer,\n",
      "        WordpieceTokenizer,\n",
      "    )\n",
      "    from .models.bert_generation import BertGenerationConfig\n",
      "    from .models.bert_japanese import (\n",
      "        BertJapaneseTokenizer,\n",
      "        CharacterTokenizer,\n",
      "        MecabTokenizer,\n",
      "    )\n",
      "    from .models.bertweet import BertweetTokenizer\n",
      "    from .models.big_bird import BigBirdConfig\n",
      "    from .models.bigbird_pegasus import (\n",
      "        BigBirdPegasusConfig,\n",
      "    )\n",
      "    from .models.biogpt import (\n",
      "        BioGptConfig,\n",
      "        BioGptTokenizer,\n",
      "    )\n",
      "    from .models.bit import BitConfig\n",
      "    from .models.blenderbot import (\n",
      "        BlenderbotConfig,\n",
      "        BlenderbotTokenizer,\n",
      "    )\n",
      "    from .models.blenderbot_small import (\n",
      "        BlenderbotSmallConfig,\n",
      "        BlenderbotSmallTokenizer,\n",
      "    )\n",
      "    from .models.blip import (\n",
      "        BlipConfig,\n",
      "        BlipProcessor,\n",
      "        BlipTextConfig,\n",
      "        BlipVisionConfig,\n",
      "    )\n",
      "    from .models.blip_2 import (\n",
      "        Blip2Config,\n",
      "        Blip2Processor,\n",
      "        Blip2QFormerConfig,\n",
      "        Blip2VisionConfig,\n",
      "    )\n",
      "    from .models.bloom import BloomConfig\n",
      "    from .models.bridgetower import (\n",
      "        BridgeTowerConfig,\n",
      "        BridgeTowerProcessor,\n",
      "        BridgeTowerTextConfig,\n",
      "        BridgeTowerVisionConfig,\n",
      "    )\n",
      "    from .models.bros import (\n",
      "        BrosConfig,\n",
      "        BrosProcessor,\n",
      "    )\n",
      "    from .models.byt5 import ByT5Tokenizer\n",
      "    from .models.camembert import (\n",
      "        CamembertConfig,\n",
      "    )\n",
      "    from .models.canine import (\n",
      "        CanineConfig,\n",
      "        CanineTokenizer,\n",
      "    )\n",
      "    from .models.chameleon import (\n",
      "        ChameleonConfig,\n",
      "        ChameleonProcessor,\n",
      "        ChameleonVQVAEConfig,\n",
      "    )\n",
      "    from .models.chinese_clip import (\n",
      "        ChineseCLIPConfig,\n",
      "        ChineseCLIPProcessor,\n",
      "        ChineseCLIPTextConfig,\n",
      "        ChineseCLIPVisionConfig,\n",
      "    )\n",
      "    from .models.clap import (\n",
      "        ClapAudioConfig,\n",
      "        ClapConfig,\n",
      "        ClapProcessor,\n",
      "        ClapTextConfig,\n",
      "    )\n",
      "    from .models.clip import (\n",
      "        CLIPConfig,\n",
      "        CLIPProcessor,\n",
      "        CLIPTextConfig,\n",
      "        CLIPTokenizer,\n",
      "        CLIPVisionConfig,\n",
      "    )\n",
      "    from .models.clipseg import (\n",
      "        CLIPSegConfig,\n",
      "        CLIPSegProcessor,\n",
      "        CLIPSegTextConfig,\n",
      "        CLIPSegVisionConfig,\n",
      "    )\n",
      "    from .models.clvp import (\n",
      "        ClvpConfig,\n",
      "        ClvpDecoderConfig,\n",
      "        ClvpEncoderConfig,\n",
      "        ClvpFeatureExtractor,\n",
      "        ClvpProcessor,\n",
      "        ClvpTokenizer,\n",
      "    )\n",
      "    from .models.codegen import (\n",
      "        CodeGenConfig,\n",
      "        CodeGenTokenizer,\n",
      "    )\n",
      "    from .models.cohere import CohereConfig\n",
      "    from .models.cohere2 import Cohere2Config\n",
      "    from .models.colpali import (\n",
      "        ColPaliConfig,\n",
      "        ColPaliProcessor,\n",
      "    )\n",
      "    from .models.conditional_detr import (\n",
      "        ConditionalDetrConfig,\n",
      "    )\n",
      "    from .models.convbert import (\n",
      "        ConvBertConfig,\n",
      "        ConvBertTokenizer,\n",
      "    )\n",
      "    from .models.convnext import ConvNextConfig\n",
      "    from .models.convnextv2 import (\n",
      "        ConvNextV2Config,\n",
      "    )\n",
      "    from .models.cpmant import (\n",
      "        CpmAntConfig,\n",
      "        CpmAntTokenizer,\n",
      "    )\n",
      "    from .models.ctrl import (\n",
      "        CTRLConfig,\n",
      "        CTRLTokenizer,\n",
      "    )\n",
      "    from .models.cvt import CvtConfig\n",
      "    from .models.dab_detr import (\n",
      "        DabDetrConfig,\n",
      "    )\n",
      "    from .models.dac import (\n",
      "        DacConfig,\n",
      "        DacFeatureExtractor,\n",
      "    )\n",
      "    from .models.data2vec import (\n",
      "        Data2VecAudioConfig,\n",
      "        Data2VecTextConfig,\n",
      "        Data2VecVisionConfig,\n",
      "    )\n",
      "    from .models.dbrx import DbrxConfig\n",
      "    from .models.deberta import (\n",
      "        DebertaConfig,\n",
      "        DebertaTokenizer,\n",
      "    )\n",
      "    from .models.deberta_v2 import (\n",
      "        DebertaV2Config,\n",
      "    )\n",
      "    from .models.decision_transformer import (\n",
      "        DecisionTransformerConfig,\n",
      "    )\n",
      "    from .models.deepseek_v3 import (\n",
      "        DeepseekV3Config,\n",
      "    )\n",
      "    from .models.deformable_detr import (\n",
      "        DeformableDetrConfig,\n",
      "    )\n",
      "    from .models.deit import DeiTConfig\n",
      "    from .models.deprecated.deta import DetaConfig\n",
      "    from .models.deprecated.efficientformer import (\n",
      "        EfficientFormerConfig,\n",
      "    )\n",
      "    from .models.deprecated.ernie_m import ErnieMConfig\n",
      "    from .models.deprecated.gptsan_japanese import (\n",
      "        GPTSanJapaneseConfig,\n",
      "        GPTSanJapaneseTokenizer,\n",
      "    )\n",
      "    from .models.deprecated.graphormer import GraphormerConfig\n",
      "    from .models.deprecated.jukebox import (\n",
      "        JukeboxConfig,\n",
      "        JukeboxPriorConfig,\n",
      "        JukeboxTokenizer,\n",
      "        JukeboxVQVAEConfig,\n",
      "    )\n",
      "    from .models.deprecated.mctct import (\n",
      "        MCTCTConfig,\n",
      "        MCTCTFeatureExtractor,\n",
      "        MCTCTProcessor,\n",
      "    )\n",
      "    from .models.deprecated.mega import MegaConfig\n",
      "    from .models.deprecated.mmbt import MMBTConfig\n",
      "    from .models.deprecated.nat import NatConfig\n",
      "    from .models.deprecated.nezha import NezhaConfig\n",
      "    from .models.deprecated.open_llama import (\n",
      "        OpenLlamaConfig,\n",
      "    )\n",
      "    from .models.deprecated.qdqbert import QDQBertConfig\n",
      "    from .models.deprecated.realm import (\n",
      "        RealmConfig,\n",
      "        RealmTokenizer,\n",
      "    )\n",
      "    from .models.deprecated.retribert import (\n",
      "        RetriBertConfig,\n",
      "        RetriBertTokenizer,\n",
      "    )\n",
      "    from .models.deprecated.speech_to_text_2 import (\n",
      "        Speech2Text2Config,\n",
      "        Speech2Text2Processor,\n",
      "        Speech2Text2Tokenizer,\n",
      "    )\n",
      "    from .models.deprecated.tapex import TapexTokenizer\n",
      "    from .models.deprecated.trajectory_transformer import (\n",
      "        TrajectoryTransformerConfig,\n",
      "    )\n",
      "    from .models.deprecated.transfo_xl import (\n",
      "        TransfoXLConfig,\n",
      "        TransfoXLCorpus,\n",
      "        TransfoXLTokenizer,\n",
      "    )\n",
      "    from .models.deprecated.tvlt import (\n",
      "        TvltConfig,\n",
      "        TvltFeatureExtractor,\n",
      "        TvltProcessor,\n",
      "    )\n",
      "    from .models.deprecated.van import VanConfig\n",
      "    from .models.deprecated.vit_hybrid import (\n",
      "        ViTHybridConfig,\n",
      "    )\n",
      "    from .models.deprecated.xlm_prophetnet import (\n",
      "        XLMProphetNetConfig,\n",
      "    )\n",
      "    from .models.depth_anything import DepthAnythingConfig\n",
      "    from .models.depth_pro import DepthProConfig\n",
      "    from .models.detr import DetrConfig\n",
      "    from .models.diffllama import DiffLlamaConfig\n",
      "    from .models.dinat import DinatConfig\n",
      "    from .models.dinov2 import Dinov2Config\n",
      "    from .models.dinov2_with_registers import Dinov2WithRegistersConfig\n",
      "    from .models.distilbert import (\n",
      "        DistilBertConfig,\n",
      "        DistilBertTokenizer,\n",
      "    )\n",
      "    from .models.donut import (\n",
      "        DonutProcessor,\n",
      "        DonutSwinConfig,\n",
      "    )\n",
      "    from .models.dpr import (\n",
      "        DPRConfig,\n",
      "        DPRContextEncoderTokenizer,\n",
      "        DPRQuestionEncoderTokenizer,\n",
      "        DPRReaderOutput,\n",
      "        DPRReaderTokenizer,\n",
      "    )\n",
      "    from .models.dpt import DPTConfig\n",
      "    from .models.efficientnet import (\n",
      "        EfficientNetConfig,\n",
      "    )\n",
      "    from .models.electra import (\n",
      "        ElectraConfig,\n",
      "        ElectraTokenizer,\n",
      "    )\n",
      "    from .models.emu3 import (\n",
      "        Emu3Config,\n",
      "        Emu3Processor,\n",
      "        Emu3TextConfig,\n",
      "        Emu3VQVAEConfig,\n",
      "    )\n",
      "    from .models.encodec import (\n",
      "        EncodecConfig,\n",
      "        EncodecFeatureExtractor,\n",
      "    )\n",
      "    from .models.encoder_decoder import EncoderDecoderConfig\n",
      "    from .models.ernie import ErnieConfig\n",
      "    from .models.esm import EsmConfig, EsmTokenizer\n",
      "    from .models.falcon import FalconConfig\n",
      "    from .models.falcon_mamba import FalconMambaConfig\n",
      "    from .models.fastspeech2_conformer import (\n",
      "        FastSpeech2ConformerConfig,\n",
      "        FastSpeech2ConformerHifiGanConfig,\n",
      "        FastSpeech2ConformerTokenizer,\n",
      "        FastSpeech2ConformerWithHifiGanConfig,\n",
      "    )\n",
      "    from .models.flaubert import FlaubertConfig, FlaubertTokenizer\n",
      "    from .models.flava import (\n",
      "        FlavaConfig,\n",
      "        FlavaImageCodebookConfig,\n",
      "        FlavaImageConfig,\n",
      "        FlavaMultimodalConfig,\n",
      "        FlavaTextConfig,\n",
      "    )\n",
      "    from .models.fnet import FNetConfig\n",
      "    from .models.focalnet import FocalNetConfig\n",
      "    from .models.fsmt import (\n",
      "        FSMTConfig,\n",
      "        FSMTTokenizer,\n",
      "    )\n",
      "    from .models.funnel import (\n",
      "        FunnelConfig,\n",
      "        FunnelTokenizer,\n",
      "    )\n",
      "    from .models.fuyu import FuyuConfig\n",
      "    from .models.gemma import GemmaConfig\n",
      "    from .models.gemma2 import Gemma2Config\n",
      "    from .models.gemma3 import Gemma3Config, Gemma3Processor, Gemma3TextConfig\n",
      "    from .models.git import (\n",
      "        GitConfig,\n",
      "        GitProcessor,\n",
      "        GitVisionConfig,\n",
      "    )\n",
      "    from .models.glm import GlmConfig\n",
      "    from .models.glm4 import Glm4Config\n",
      "    from .models.glpn import GLPNConfig\n",
      "    from .models.got_ocr2 import GotOcr2Config, GotOcr2Processor, GotOcr2VisionConfig\n",
      "    from .models.gpt2 import (\n",
      "        GPT2Config,\n",
      "        GPT2Tokenizer,\n",
      "    )\n",
      "    from .models.gpt_bigcode import (\n",
      "        GPTBigCodeConfig,\n",
      "    )\n",
      "    from .models.gpt_neo import GPTNeoConfig\n",
      "    from .models.gpt_neox import GPTNeoXConfig\n",
      "    from .models.gpt_neox_japanese import (\n",
      "        GPTNeoXJapaneseConfig,\n",
      "    )\n",
      "    from .models.gptj import GPTJConfig\n",
      "    from .models.granite import GraniteConfig\n",
      "    from .models.granitemoe import GraniteMoeConfig\n",
      "    from .models.granitemoeshared import GraniteMoeSharedConfig\n",
      "    from .models.grounding_dino import (\n",
      "        GroundingDinoConfig,\n",
      "        GroundingDinoProcessor,\n",
      "    )\n",
      "    from .models.groupvit import (\n",
      "        GroupViTConfig,\n",
      "        GroupViTTextConfig,\n",
      "        GroupViTVisionConfig,\n",
      "    )\n",
      "    from .models.helium import HeliumConfig\n",
      "    from .models.herbert import HerbertTokenizer\n",
      "    from .models.hiera import HieraConfig\n",
      "    from .models.hubert import HubertConfig\n",
      "    from .models.ibert import IBertConfig\n",
      "    from .models.idefics import (\n",
      "        IdeficsConfig,\n",
      "    )\n",
      "    from .models.idefics2 import Idefics2Config\n",
      "    from .models.idefics3 import Idefics3Config\n",
      "    from .models.ijepa import IJepaConfig\n",
      "    from .models.imagegpt import ImageGPTConfig\n",
      "    from .models.informer import InformerConfig\n",
      "    from .models.instructblip import (\n",
      "        InstructBlipConfig,\n",
      "        InstructBlipProcessor,\n",
      "        InstructBlipQFormerConfig,\n",
      "        InstructBlipVisionConfig,\n",
      "    )\n",
      "    from .models.instructblipvideo import (\n",
      "        InstructBlipVideoConfig,\n",
      "        InstructBlipVideoProcessor,\n",
      "        InstructBlipVideoQFormerConfig,\n",
      "        InstructBlipVideoVisionConfig,\n",
      "    )\n",
      "    from .models.jamba import JambaConfig\n",
      "    from .models.jetmoe import JetMoeConfig\n",
      "    from .models.kosmos2 import (\n",
      "        Kosmos2Config,\n",
      "        Kosmos2Processor,\n",
      "    )\n",
      "    from .models.layoutlm import (\n",
      "        LayoutLMConfig,\n",
      "        LayoutLMTokenizer,\n",
      "    )\n",
      "    from .models.layoutlmv2 import (\n",
      "        LayoutLMv2Config,\n",
      "        LayoutLMv2FeatureExtractor,\n",
      "        LayoutLMv2ImageProcessor,\n",
      "        LayoutLMv2Processor,\n",
      "        LayoutLMv2Tokenizer,\n",
      "    )\n",
      "    from .models.layoutlmv3 import (\n",
      "        LayoutLMv3Config,\n",
      "        LayoutLMv3FeatureExtractor,\n",
      "        LayoutLMv3ImageProcessor,\n",
      "        LayoutLMv3Processor,\n",
      "        LayoutLMv3Tokenizer,\n",
      "    )\n",
      "    from .models.layoutxlm import LayoutXLMProcessor\n",
      "    from .models.led import LEDConfig, LEDTokenizer\n",
      "    from .models.levit import LevitConfig\n",
      "    from .models.lilt import LiltConfig\n",
      "    from .models.llama import LlamaConfig\n",
      "    from .models.llama4 import (\n",
      "        Llama4Config,\n",
      "        Llama4Processor,\n",
      "        Llama4TextConfig,\n",
      "        Llama4VisionConfig,\n",
      "    )\n",
      "    from .models.llava import (\n",
      "        LlavaConfig,\n",
      "        LlavaProcessor,\n",
      "    )\n",
      "    from .models.llava_next import (\n",
      "        LlavaNextConfig,\n",
      "        LlavaNextProcessor,\n",
      "    )\n",
      "    from .models.llava_next_video import (\n",
      "        LlavaNextVideoConfig,\n",
      "        LlavaNextVideoProcessor,\n",
      "    )\n",
      "    from .models.llava_onevision import (\n",
      "        LlavaOnevisionConfig,\n",
      "        LlavaOnevisionProcessor,\n",
      "    )\n",
      "    from .models.longformer import (\n",
      "        LongformerConfig,\n",
      "        LongformerTokenizer,\n",
      "    )\n",
      "    from .models.longt5 import LongT5Config\n",
      "    from .models.luke import (\n",
      "        LukeConfig,\n",
      "        LukeTokenizer,\n",
      "    )\n",
      "    from .models.lxmert import (\n",
      "        LxmertConfig,\n",
      "        LxmertTokenizer,\n",
      "    )\n",
      "    from .models.m2m_100 import M2M100Config\n",
      "    from .models.mamba import MambaConfig\n",
      "    from .models.mamba2 import Mamba2Config\n",
      "    from .models.marian import MarianConfig\n",
      "    from .models.markuplm import (\n",
      "        MarkupLMConfig,\n",
      "        MarkupLMFeatureExtractor,\n",
      "        MarkupLMProcessor,\n",
      "        MarkupLMTokenizer,\n",
      "    )\n",
      "    from .models.mask2former import (\n",
      "        Mask2FormerConfig,\n",
      "    )\n",
      "    from .models.maskformer import (\n",
      "        MaskFormerConfig,\n",
      "        MaskFormerSwinConfig,\n",
      "    )\n",
      "    from .models.mbart import MBartConfig\n",
      "    from .models.megatron_bert import (\n",
      "        MegatronBertConfig,\n",
      "    )\n",
      "    from .models.mgp_str import (\n",
      "        MgpstrConfig,\n",
      "        MgpstrProcessor,\n",
      "        MgpstrTokenizer,\n",
      "    )\n",
      "    from .models.mimi import (\n",
      "        MimiConfig,\n",
      "    )\n",
      "    from .models.mistral import MistralConfig\n",
      "    from .models.mistral3 import Mistral3Config\n",
      "    from .models.mixtral import MixtralConfig\n",
      "    from .models.mllama import (\n",
      "        MllamaConfig,\n",
      "        MllamaProcessor,\n",
      "    )\n",
      "    from .models.mobilebert import (\n",
      "        MobileBertConfig,\n",
      "        MobileBertTokenizer,\n",
      "    )\n",
      "    from .models.mobilenet_v1 import (\n",
      "        MobileNetV1Config,\n",
      "    )\n",
      "    from .models.mobilenet_v2 import (\n",
      "        MobileNetV2Config,\n",
      "    )\n",
      "    from .models.mobilevit import (\n",
      "        MobileViTConfig,\n",
      "    )\n",
      "    from .models.mobilevitv2 import (\n",
      "        MobileViTV2Config,\n",
      "    )\n",
      "    from .models.modernbert import ModernBertConfig\n",
      "    from .models.moonshine import MoonshineConfig\n",
      "    from .models.moshi import (\n",
      "        MoshiConfig,\n",
      "        MoshiDepthConfig,\n",
      "    )\n",
      "    from .models.mpnet import (\n",
      "        MPNetConfig,\n",
      "        MPNetTokenizer,\n",
      "    )\n",
      "    from .models.mpt import MptConfig\n",
      "    from .models.mra import MraConfig\n",
      "    from .models.mt5 import MT5Config\n",
      "    from .models.musicgen import (\n",
      "        MusicgenConfig,\n",
      "        MusicgenDecoderConfig,\n",
      "    )\n",
      "    from .models.musicgen_melody import (\n",
      "        MusicgenMelodyConfig,\n",
      "        MusicgenMelodyDecoderConfig,\n",
      "    )\n",
      "    from .models.mvp import MvpConfig, MvpTokenizer\n",
      "    from .models.myt5 import MyT5Tokenizer\n",
      "    from .models.nemotron import NemotronConfig\n",
      "    from .models.nllb_moe import NllbMoeConfig\n",
      "    from .models.nougat import NougatProcessor\n",
      "    from .models.nystromformer import (\n",
      "        NystromformerConfig,\n",
      "    )\n",
      "    from .models.olmo import OlmoConfig\n",
      "    from .models.olmo2 import Olmo2Config\n",
      "    from .models.olmoe import OlmoeConfig\n",
      "    from .models.omdet_turbo import (\n",
      "        OmDetTurboConfig,\n",
      "        OmDetTurboProcessor,\n",
      "    )\n",
      "    from .models.oneformer import (\n",
      "        OneFormerConfig,\n",
      "        OneFormerProcessor,\n",
      "    )\n",
      "    from .models.openai import (\n",
      "        OpenAIGPTConfig,\n",
      "        OpenAIGPTTokenizer,\n",
      "    )\n",
      "    from .models.opt import OPTConfig\n",
      "    from .models.owlv2 import (\n",
      "        Owlv2Config,\n",
      "        Owlv2Processor,\n",
      "        Owlv2TextConfig,\n",
      "        Owlv2VisionConfig,\n",
      "    )\n",
      "    from .models.owlvit import (\n",
      "        OwlViTConfig,\n",
      "        OwlViTProcessor,\n",
      "        OwlViTTextConfig,\n",
      "        OwlViTVisionConfig,\n",
      "    )\n",
      "    from .models.paligemma import (\n",
      "        PaliGemmaConfig,\n",
      "    )\n",
      "    from .models.patchtsmixer import (\n",
      "        PatchTSMixerConfig,\n",
      "    )\n",
      "    from .models.patchtst import PatchTSTConfig\n",
      "    from .models.pegasus import (\n",
      "        PegasusConfig,\n",
      "        PegasusTokenizer,\n",
      "    )\n",
      "    from .models.pegasus_x import (\n",
      "        PegasusXConfig,\n",
      "    )\n",
      "    from .models.perceiver import (\n",
      "        PerceiverConfig,\n",
      "        PerceiverTokenizer,\n",
      "    )\n",
      "    from .models.persimmon import (\n",
      "        PersimmonConfig,\n",
      "    )\n",
      "    from .models.phi import PhiConfig\n",
      "    from .models.phi3 import Phi3Config\n",
      "    from .models.phi4_multimodal import (\n",
      "        Phi4MultimodalAudioConfig,\n",
      "        Phi4MultimodalConfig,\n",
      "        Phi4MultimodalFeatureExtractor,\n",
      "        Phi4MultimodalProcessor,\n",
      "        Phi4MultimodalVisionConfig,\n",
      "    )\n",
      "    from .models.phimoe import PhimoeConfig\n",
      "    from .models.phobert import PhobertTokenizer\n",
      "    from .models.pix2struct import (\n",
      "        Pix2StructConfig,\n",
      "        Pix2StructProcessor,\n",
      "        Pix2StructTextConfig,\n",
      "        Pix2StructVisionConfig,\n",
      "    )\n",
      "    from .models.pixtral import (\n",
      "        PixtralProcessor,\n",
      "        PixtralVisionConfig,\n",
      "    )\n",
      "    from .models.plbart import PLBartConfig\n",
      "    from .models.poolformer import (\n",
      "        PoolFormerConfig,\n",
      "    )\n",
      "    from .models.pop2piano import (\n",
      "        Pop2PianoConfig,\n",
      "    )\n",
      "    from .models.prompt_depth_anything import PromptDepthAnythingConfig\n",
      "    from .models.prophetnet import (\n",
      "        ProphetNetConfig,\n",
      "        ProphetNetTokenizer,\n",
      "    )\n",
      "    from .models.pvt import PvtConfig\n",
      "    from .models.pvt_v2 import PvtV2Config\n",
      "    from .models.qwen2 import Qwen2Config, Qwen2Tokenizer\n",
      "    from .models.qwen2_5_vl import (\n",
      "        Qwen2_5_VLConfig,\n",
      "        Qwen2_5_VLProcessor,\n",
      "    )\n",
      "    from .models.qwen2_audio import (\n",
      "        Qwen2AudioConfig,\n",
      "        Qwen2AudioEncoderConfig,\n",
      "        Qwen2AudioProcessor,\n",
      "    )\n",
      "    from .models.qwen2_moe import Qwen2MoeConfig\n",
      "    from .models.qwen2_vl import (\n",
      "        Qwen2VLConfig,\n",
      "        Qwen2VLProcessor,\n",
      "    )\n",
      "    from .models.qwen3 import Qwen3Config\n",
      "    from .models.qwen3_moe import Qwen3MoeConfig\n",
      "    from .models.rag import RagConfig, RagRetriever, RagTokenizer\n",
      "    from .models.recurrent_gemma import RecurrentGemmaConfig\n",
      "    from .models.reformer import ReformerConfig\n",
      "    from .models.regnet import RegNetConfig\n",
      "    from .models.rembert import RemBertConfig\n",
      "    from .models.resnet import ResNetConfig\n",
      "    from .models.roberta import (\n",
      "        RobertaConfig,\n",
      "        RobertaTokenizer,\n",
      "    )\n",
      "    from .models.roberta_prelayernorm import (\n",
      "        RobertaPreLayerNormConfig,\n",
      "    )\n",
      "    from .models.roc_bert import (\n",
      "        RoCBertConfig,\n",
      "        RoCBertTokenizer,\n",
      "    )\n",
      "    from .models.roformer import (\n",
      "        RoFormerConfig,\n",
      "        RoFormerTokenizer,\n",
      "    )\n",
      "    from .models.rt_detr import (\n",
      "        RTDetrConfig,\n",
      "        RTDetrResNetConfig,\n",
      "    )\n",
      "    from .models.rt_detr_v2 import RTDetrV2Config\n",
      "    from .models.rwkv import RwkvConfig\n",
      "    from .models.sam import (\n",
      "        SamConfig,\n",
      "        SamMaskDecoderConfig,\n",
      "        SamProcessor,\n",
      "        SamPromptEncoderConfig,\n",
      "        SamVisionConfig,\n",
      "    )\n",
      "    from .models.seamless_m4t import (\n",
      "        SeamlessM4TConfig,\n",
      "        SeamlessM4TFeatureExtractor,\n",
      "        SeamlessM4TProcessor,\n",
      "    )\n",
      "    from .models.seamless_m4t_v2 import (\n",
      "        SeamlessM4Tv2Config,\n",
      "    )\n",
      "    from .models.segformer import SegformerConfig\n",
      "    from .models.seggpt import SegGptConfig\n",
      "    from .models.sew import SEWConfig\n",
      "    from .models.sew_d import SEWDConfig\n",
      "    from .models.shieldgemma2 import (\n",
      "        ShieldGemma2Config,\n",
      "        ShieldGemma2Processor,\n",
      "    )\n",
      "    from .models.siglip import (\n",
      "        SiglipConfig,\n",
      "        SiglipProcessor,\n",
      "        SiglipTextConfig,\n",
      "        SiglipVisionConfig,\n",
      "    )\n",
      "    from .models.siglip2 import (\n",
      "        Siglip2Config,\n",
      "        Siglip2Processor,\n",
      "        Siglip2TextConfig,\n",
      "        Siglip2VisionConfig,\n",
      "    )\n",
      "    from .models.smolvlm import SmolVLMConfig\n",
      "    from .models.speech_encoder_decoder import SpeechEncoderDecoderConfig\n",
      "    from .models.speech_to_text import (\n",
      "        Speech2TextConfig,\n",
      "        Speech2TextFeatureExtractor,\n",
      "        Speech2TextProcessor,\n",
      "    )\n",
      "    from .models.speecht5 import (\n",
      "        SpeechT5Config,\n",
      "        SpeechT5FeatureExtractor,\n",
      "        SpeechT5HifiGanConfig,\n",
      "        SpeechT5Processor,\n",
      "    )\n",
      "    from .models.splinter import (\n",
      "        SplinterConfig,\n",
      "        SplinterTokenizer,\n",
      "    )\n",
      "    from .models.squeezebert import (\n",
      "        SqueezeBertConfig,\n",
      "        SqueezeBertTokenizer,\n",
      "    )\n",
      "    from .models.stablelm import StableLmConfig\n",
      "    from .models.starcoder2 import Starcoder2Config\n",
      "    from .models.superglue import SuperGlueConfig\n",
      "    from .models.superpoint import SuperPointConfig\n",
      "    from .models.swiftformer import (\n",
      "        SwiftFormerConfig,\n",
      "    )\n",
      "    from .models.swin import SwinConfig\n",
      "    from .models.swin2sr import Swin2SRConfig\n",
      "    from .models.swinv2 import Swinv2Config\n",
      "    from .models.switch_transformers import (\n",
      "        SwitchTransformersConfig,\n",
      "    )\n",
      "    from .models.t5 import T5Config\n",
      "    from .models.table_transformer import (\n",
      "        TableTransformerConfig,\n",
      "    )\n",
      "    from .models.tapas import (\n",
      "        TapasConfig,\n",
      "        TapasTokenizer,\n",
      "    )\n",
      "    from .models.textnet import TextNetConfig\n",
      "    from .models.time_series_transformer import (\n",
      "        TimeSeriesTransformerConfig,\n",
      "    )\n",
      "    from .models.timesformer import (\n",
      "        TimesformerConfig,\n",
      "    )\n",
      "    from .models.timm_backbone import TimmBackboneConfig\n",
      "    from .models.timm_wrapper import TimmWrapperConfig\n",
      "    from .models.trocr import (\n",
      "        TrOCRConfig,\n",
      "        TrOCRProcessor,\n",
      "    )\n",
      "    from .models.tvp import (\n",
      "        TvpConfig,\n",
      "        TvpProcessor,\n",
      "    )\n",
      "    from .models.udop import UdopConfig, UdopProcessor\n",
      "    from .models.umt5 import UMT5Config\n",
      "    from .models.unispeech import (\n",
      "        UniSpeechConfig,\n",
      "    )\n",
      "    from .models.unispeech_sat import (\n",
      "        UniSpeechSatConfig,\n",
      "    )\n",
      "    from .models.univnet import (\n",
      "        UnivNetConfig,\n",
      "        UnivNetFeatureExtractor,\n",
      "    )\n",
      "    from .models.upernet import UperNetConfig\n",
      "    from .models.video_llava import VideoLlavaConfig\n",
      "    from .models.videomae import VideoMAEConfig\n",
      "    from .models.vilt import (\n",
      "        ViltConfig,\n",
      "        ViltFeatureExtractor,\n",
      "        ViltImageProcessor,\n",
      "        ViltProcessor,\n",
      "    )\n",
      "    from .models.vipllava import (\n",
      "        VipLlavaConfig,\n",
      "    )\n",
      "    from .models.vision_encoder_decoder import VisionEncoderDecoderConfig\n",
      "    from .models.vision_text_dual_encoder import (\n",
      "        VisionTextDualEncoderConfig,\n",
      "        VisionTextDualEncoderProcessor,\n",
      "    )\n",
      "    from .models.visual_bert import (\n",
      "        VisualBertConfig,\n",
      "    )\n",
      "    from .models.vit import ViTConfig\n",
      "    from .models.vit_mae import ViTMAEConfig\n",
      "    from .models.vit_msn import ViTMSNConfig\n",
      "    from .models.vitdet import VitDetConfig\n",
      "    from .models.vitmatte import VitMatteConfig\n",
      "    from .models.vitpose import VitPoseConfig\n",
      "    from .models.vitpose_backbone import VitPoseBackboneConfig\n",
      "    from .models.vits import (\n",
      "        VitsConfig,\n",
      "        VitsTokenizer,\n",
      "    )\n",
      "    from .models.vivit import VivitConfig\n",
      "    from .models.wav2vec2 import (\n",
      "        Wav2Vec2Config,\n",
      "        Wav2Vec2CTCTokenizer,\n",
      "        Wav2Vec2FeatureExtractor,\n",
      "        Wav2Vec2Processor,\n",
      "        Wav2Vec2Tokenizer,\n",
      "    )\n",
      "    from .models.wav2vec2_bert import (\n",
      "        Wav2Vec2BertConfig,\n",
      "        Wav2Vec2BertProcessor,\n",
      "    )\n",
      "    from .models.wav2vec2_conformer import (\n",
      "        Wav2Vec2ConformerConfig,\n",
      "    )\n",
      "    from .models.wav2vec2_phoneme import Wav2Vec2PhonemeCTCTokenizer\n",
      "    from .models.wav2vec2_with_lm import Wav2Vec2ProcessorWithLM\n",
      "    from .models.wavlm import WavLMConfig\n",
      "    from .models.whisper import (\n",
      "        WhisperConfig,\n",
      "        WhisperFeatureExtractor,\n",
      "        WhisperProcessor,\n",
      "        WhisperTokenizer,\n",
      "    )\n",
      "    from .models.x_clip import (\n",
      "        XCLIPConfig,\n",
      "        XCLIPProcessor,\n",
      "        XCLIPTextConfig,\n",
      "        XCLIPVisionConfig,\n",
      "    )\n",
      "    from .models.xglm import XGLMConfig\n",
      "    from .models.xlm import XLMConfig, XLMTokenizer\n",
      "    from .models.xlm_roberta import (\n",
      "        XLMRobertaConfig,\n",
      "    )\n",
      "    from .models.xlm_roberta_xl import (\n",
      "        XLMRobertaXLConfig,\n",
      "    )\n",
      "    from .models.xlnet import XLNetConfig\n",
      "    from .models.xmod import XmodConfig\n",
      "    from .models.yolos import YolosConfig\n",
      "    from .models.yoso import YosoConfig\n",
      "    from .models.zamba import ZambaConfig\n",
      "    from .models.zamba2 import Zamba2Config\n",
      "    from .models.zoedepth import ZoeDepthConfig\n",
      "\n",
      "    # Pipelines\n",
      "    from .pipelines import (\n",
      "        AudioClassificationPipeline,\n",
      "        AutomaticSpeechRecognitionPipeline,\n",
      "        CsvPipelineDataFormat,\n",
      "        DepthEstimationPipeline,\n",
      "        DocumentQuestionAnsweringPipeline,\n",
      "        FeatureExtractionPipeline,\n",
      "        FillMaskPipeline,\n",
      "        ImageClassificationPipeline,\n",
      "        ImageFeatureExtractionPipeline,\n",
      "        ImageSegmentationPipeline,\n",
      "        ImageTextToTextPipeline,\n",
      "        ImageToImagePipeline,\n",
      "        ImageToTextPipeline,\n",
      "        JsonPipelineDataFormat,\n",
      "        MaskGenerationPipeline,\n",
      "        NerPipeline,\n",
      "        ObjectDetectionPipeline,\n",
      "        PipedPipelineDataFormat,\n",
      "        Pipeline,\n",
      "        PipelineDataFormat,\n",
      "        QuestionAnsweringPipeline,\n",
      "        SummarizationPipeline,\n",
      "        TableQuestionAnsweringPipeline,\n",
      "        Text2TextGenerationPipeline,\n",
      "        TextClassificationPipeline,\n",
      "        TextGenerationPipeline,\n",
      "        TextToAudioPipeline,\n",
      "        TokenClassificationPipeline,\n",
      "        TranslationPipeline,\n",
      "        VideoClassificationPipeline,\n",
      "        VisualQuestionAnsweringPipeline,\n",
      "        ZeroShotAudioClassificationPipeline,\n",
      "        ZeroShotClassificationPipeline,\n",
      "        ZeroShotImageClassificationPipeline,\n",
      "        ZeroShotObjectDetectionPipeline,\n",
      "        pipeline,\n",
      "    )\n",
      "    from .processing_utils import ProcessorMixin\n",
      "\n",
      "    # Tokenization\n",
      "    from .tokenization_utils import PreTrainedTokenizer\n",
      "    from .tokenization_utils_base import (\n",
      "        AddedToken,\n",
      "        BatchEncoding,\n",
      "        CharSpan,\n",
      "        PreTrainedTokenizerBase,\n",
      "        SpecialTokensMixin,\n",
      "        TokenSpan,\n",
      "    )\n",
      "\n",
      "    # Trainer\n",
      "    from .trainer_callback import (\n",
      "        DefaultFlowCallback,\n",
      "        EarlyStoppingCallback,\n",
      "        PrinterCallback,\n",
      "        ProgressCallback,\n",
      "        TrainerCallback,\n",
      "        TrainerControl,\n",
      "        TrainerState,\n",
      "    )\n",
      "    from .trainer_utils import (\n",
      "        EvalPrediction,\n",
      "        IntervalStrategy,\n",
      "        SchedulerType,\n",
      "        enable_full_determinism,\n",
      "        set_seed,\n",
      "    )\n",
      "    from .training_args import TrainingArguments\n",
      "    from .training_args_seq2seq import Seq2SeqTrainingArguments\n",
      "    from .training_args_tf import TFTrainingArguments\n",
      "\n",
      "    # Files and general utilities\n",
      "    from .utils import (\n",
      "        CONFIG_NAME,\n",
      "        MODEL_CARD_NAME,\n",
      "        PYTORCH_PRETRAINED_BERT_CACHE,\n",
      "        PYTORCH_TRANSFORMERS_CACHE,\n",
      "        SPIECE_UNDERLINE,\n",
      "        TF2_WEIGHTS_NAME,\n",
      "        TF_WEIGHTS_NAME,\n",
      "        TRANSFORMERS_CACHE,\n",
      "        WEIGHTS_NAME,\n",
      "        TensorType,\n",
      "        add_end_docstrings,\n",
      "        add_start_docstrings,\n",
      "        is_apex_available,\n",
      "        is_av_available,\n",
      "        is_bitsandbytes_available,\n",
      "        is_datasets_available,\n",
      "        is_faiss_available,\n",
      "        is_flax_available,\n",
      "        is_keras_nlp_available,\n",
      "        is_phonemizer_available,\n",
      "        is_psutil_available,\n",
      "        is_py3nvml_available,\n",
      "        is_pyctcdecode_available,\n",
      "        is_sacremoses_available,\n",
      "        is_safetensors_available,\n",
      "        is_scipy_available,\n",
      "        is_sentencepiece_available,\n",
      "        is_sklearn_available,\n",
      "        is_speech_available,\n",
      "        is_tensorflow_text_available,\n",
      "        is_tf_available,\n",
      "        is_timm_available,\n",
      "        is_tokenizers_available,\n",
      "        is_torch_available,\n",
      "        is_torch_hpu_available,\n",
      "        is_torch_mlu_available,\n",
      "        is_torch_musa_available,\n",
      "        is_torch_neuroncore_available,\n",
      "        is_torch_npu_available,\n",
      "        is_torch_xla_available,\n",
      "        is_torch_xpu_available,\n",
      "        is_torchvision_available,\n",
      "        is_vision_available,\n",
      "        logging,\n",
      "    )\n",
      "\n",
      "    # bitsandbytes config\n",
      "    from .utils.quantization_config import (\n",
      "        AqlmConfig,\n",
      "        AwqConfig,\n",
      "        BitNetConfig,\n",
      "        BitsAndBytesConfig,\n",
      "        CompressedTensorsConfig,\n",
      "        EetqConfig,\n",
      "        FbgemmFp8Config,\n",
      "        FineGrainedFP8Config,\n",
      "        GPTQConfig,\n",
      "        HiggsConfig,\n",
      "        HqqConfig,\n",
      "        QuantoConfig,\n",
      "        QuarkConfig,\n",
      "        SpQRConfig,\n",
      "        TorchAoConfig,\n",
      "        VptqConfig,\n",
      "    )\n",
      "\n",
      "    try:\n",
      "        if not is_sentencepiece_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_sentencepiece_objects import *\n",
      "    else:\n",
      "        from .models.albert import AlbertTokenizer\n",
      "        from .models.barthez import BarthezTokenizer\n",
      "        from .models.bartpho import BartphoTokenizer\n",
      "        from .models.bert_generation import BertGenerationTokenizer\n",
      "        from .models.big_bird import BigBirdTokenizer\n",
      "        from .models.camembert import CamembertTokenizer\n",
      "        from .models.code_llama import CodeLlamaTokenizer\n",
      "        from .models.cpm import CpmTokenizer\n",
      "        from .models.deberta_v2 import DebertaV2Tokenizer\n",
      "        from .models.deprecated.ernie_m import ErnieMTokenizer\n",
      "        from .models.deprecated.xlm_prophetnet import XLMProphetNetTokenizer\n",
      "        from .models.fnet import FNetTokenizer\n",
      "        from .models.gemma import GemmaTokenizer\n",
      "        from .models.gpt_sw3 import GPTSw3Tokenizer\n",
      "        from .models.layoutxlm import LayoutXLMTokenizer\n",
      "        from .models.llama import LlamaTokenizer\n",
      "        from .models.m2m_100 import M2M100Tokenizer\n",
      "        from .models.marian import MarianTokenizer\n",
      "        from .models.mbart import MBartTokenizer\n",
      "        from .models.mbart50 import MBart50Tokenizer\n",
      "        from .models.mluke import MLukeTokenizer\n",
      "        from .models.mt5 import MT5Tokenizer\n",
      "        from .models.nllb import NllbTokenizer\n",
      "        from .models.pegasus import PegasusTokenizer\n",
      "        from .models.plbart import PLBartTokenizer\n",
      "        from .models.reformer import ReformerTokenizer\n",
      "        from .models.rembert import RemBertTokenizer\n",
      "        from .models.seamless_m4t import SeamlessM4TTokenizer\n",
      "        from .models.siglip import SiglipTokenizer\n",
      "        from .models.speech_to_text import Speech2TextTokenizer\n",
      "        from .models.speecht5 import SpeechT5Tokenizer\n",
      "        from .models.t5 import T5Tokenizer\n",
      "        from .models.udop import UdopTokenizer\n",
      "        from .models.xglm import XGLMTokenizer\n",
      "        from .models.xlm_roberta import XLMRobertaTokenizer\n",
      "        from .models.xlnet import XLNetTokenizer\n",
      "\n",
      "    try:\n",
      "        if not is_tokenizers_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_tokenizers_objects import *\n",
      "    else:\n",
      "        # Fast tokenizers imports\n",
      "        from .models.albert import AlbertTokenizerFast\n",
      "        from .models.bart import BartTokenizerFast\n",
      "        from .models.barthez import BarthezTokenizerFast\n",
      "        from .models.bert import BertTokenizerFast\n",
      "        from .models.big_bird import BigBirdTokenizerFast\n",
      "        from .models.blenderbot import BlenderbotTokenizerFast\n",
      "        from .models.blenderbot_small import BlenderbotSmallTokenizerFast\n",
      "        from .models.bloom import BloomTokenizerFast\n",
      "        from .models.camembert import CamembertTokenizerFast\n",
      "        from .models.clip import CLIPTokenizerFast\n",
      "        from .models.code_llama import CodeLlamaTokenizerFast\n",
      "        from .models.codegen import CodeGenTokenizerFast\n",
      "        from .models.cohere import CohereTokenizerFast\n",
      "        from .models.convbert import ConvBertTokenizerFast\n",
      "        from .models.cpm import CpmTokenizerFast\n",
      "        from .models.deberta import DebertaTokenizerFast\n",
      "        from .models.deberta_v2 import DebertaV2TokenizerFast\n",
      "        from .models.deprecated.realm import RealmTokenizerFast\n",
      "        from .models.deprecated.retribert import RetriBertTokenizerFast\n",
      "        from .models.distilbert import DistilBertTokenizerFast\n",
      "        from .models.dpr import (\n",
      "            DPRContextEncoderTokenizerFast,\n",
      "            DPRQuestionEncoderTokenizerFast,\n",
      "            DPRReaderTokenizerFast,\n",
      "        )\n",
      "        from .models.electra import ElectraTokenizerFast\n",
      "        from .models.fnet import FNetTokenizerFast\n",
      "        from .models.funnel import FunnelTokenizerFast\n",
      "        from .models.gemma import GemmaTokenizerFast\n",
      "        from .models.gpt2 import GPT2TokenizerFast\n",
      "        from .models.gpt_neox import GPTNeoXTokenizerFast\n",
      "        from .models.gpt_neox_japanese import GPTNeoXJapaneseTokenizer\n",
      "        from .models.herbert import HerbertTokenizerFast\n",
      "        from .models.layoutlm import LayoutLMTokenizerFast\n",
      "        from .models.layoutlmv2 import LayoutLMv2TokenizerFast\n",
      "        from .models.layoutlmv3 import LayoutLMv3TokenizerFast\n",
      "        from .models.layoutxlm import LayoutXLMTokenizerFast\n",
      "        from .models.led import LEDTokenizerFast\n",
      "        from .models.llama import LlamaTokenizerFast\n",
      "        from .models.longformer import LongformerTokenizerFast\n",
      "        from .models.lxmert import LxmertTokenizerFast\n",
      "        from .models.markuplm import MarkupLMTokenizerFast\n",
      "        from .models.mbart import MBartTokenizerFast\n",
      "        from .models.mbart50 import MBart50TokenizerFast\n",
      "        from .models.mobilebert import MobileBertTokenizerFast\n",
      "        from .models.mpnet import MPNetTokenizerFast\n",
      "        from .models.mt5 import MT5TokenizerFast\n",
      "        from .models.mvp import MvpTokenizerFast\n",
      "        from .models.nllb import NllbTokenizerFast\n",
      "        from .models.nougat import NougatTokenizerFast\n",
      "        from .models.openai import OpenAIGPTTokenizerFast\n",
      "        from .models.pegasus import PegasusTokenizerFast\n",
      "        from .models.qwen2 import Qwen2TokenizerFast\n",
      "        from .models.reformer import ReformerTokenizerFast\n",
      "        from .models.rembert import RemBertTokenizerFast\n",
      "        from .models.roberta import RobertaTokenizerFast\n",
      "        from .models.roformer import RoFormerTokenizerFast\n",
      "        from .models.seamless_m4t import SeamlessM4TTokenizerFast\n",
      "        from .models.splinter import SplinterTokenizerFast\n",
      "        from .models.squeezebert import SqueezeBertTokenizerFast\n",
      "        from .models.t5 import T5TokenizerFast\n",
      "        from .models.udop import UdopTokenizerFast\n",
      "        from .models.whisper import WhisperTokenizerFast\n",
      "        from .models.xglm import XGLMTokenizerFast\n",
      "        from .models.xlm_roberta import XLMRobertaTokenizerFast\n",
      "        from .models.xlnet import XLNetTokenizerFast\n",
      "        from .tokenization_utils_fast import PreTrainedTokenizerFast\n",
      "\n",
      "    try:\n",
      "        if not (is_sentencepiece_available() and is_tokenizers_available()):\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummies_sentencepiece_and_tokenizers_objects import *\n",
      "    else:\n",
      "        from .convert_slow_tokenizer import (\n",
      "            SLOW_TO_FAST_CONVERTERS,\n",
      "            convert_slow_tokenizer,\n",
      "        )\n",
      "\n",
      "    try:\n",
      "        if not is_tensorflow_text_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_tensorflow_text_objects import *\n",
      "    else:\n",
      "        from .models.bert import TFBertTokenizer\n",
      "\n",
      "    try:\n",
      "        if not is_keras_nlp_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_keras_nlp_objects import *\n",
      "    else:\n",
      "        from .models.gpt2 import TFGPT2Tokenizer\n",
      "\n",
      "    try:\n",
      "        if not is_vision_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_vision_objects import *\n",
      "    else:\n",
      "        from .image_processing_base import ImageProcessingMixin\n",
      "        from .image_processing_utils import BaseImageProcessor\n",
      "        from .image_utils import ImageFeatureExtractionMixin\n",
      "        from .models.aria import AriaImageProcessor\n",
      "        from .models.beit import BeitFeatureExtractor, BeitImageProcessor\n",
      "        from .models.bit import BitImageProcessor\n",
      "        from .models.blip import BlipImageProcessor\n",
      "        from .models.bridgetower import BridgeTowerImageProcessor\n",
      "        from .models.chameleon import ChameleonImageProcessor\n",
      "        from .models.chinese_clip import (\n",
      "            ChineseCLIPFeatureExtractor,\n",
      "            ChineseCLIPImageProcessor,\n",
      "        )\n",
      "        from .models.clip import CLIPFeatureExtractor, CLIPImageProcessor\n",
      "        from .models.conditional_detr import (\n",
      "            ConditionalDetrFeatureExtractor,\n",
      "            ConditionalDetrImageProcessor,\n",
      "        )\n",
      "        from .models.convnext import ConvNextFeatureExtractor, ConvNextImageProcessor\n",
      "        from .models.deformable_detr import DeformableDetrFeatureExtractor, DeformableDetrImageProcessor\n",
      "        from .models.deit import DeiTFeatureExtractor, DeiTImageProcessor\n",
      "        from .models.deprecated.deta import DetaImageProcessor\n",
      "        from .models.deprecated.efficientformer import EfficientFormerImageProcessor\n",
      "        from .models.deprecated.tvlt import TvltImageProcessor\n",
      "        from .models.deprecated.vit_hybrid import ViTHybridImageProcessor\n",
      "        from .models.depth_pro import DepthProImageProcessor, DepthProImageProcessorFast\n",
      "        from .models.detr import DetrFeatureExtractor, DetrImageProcessor\n",
      "        from .models.donut import DonutFeatureExtractor, DonutImageProcessor\n",
      "        from .models.dpt import DPTFeatureExtractor, DPTImageProcessor\n",
      "        from .models.efficientnet import EfficientNetImageProcessor\n",
      "        from .models.emu3 import Emu3ImageProcessor\n",
      "        from .models.flava import (\n",
      "            FlavaFeatureExtractor,\n",
      "            FlavaImageProcessor,\n",
      "            FlavaProcessor,\n",
      "        )\n",
      "        from .models.fuyu import FuyuImageProcessor, FuyuProcessor\n",
      "        from .models.gemma3 import Gemma3ImageProcessor\n",
      "        from .models.glpn import GLPNFeatureExtractor, GLPNImageProcessor\n",
      "        from .models.got_ocr2 import GotOcr2ImageProcessor\n",
      "        from .models.grounding_dino import GroundingDinoImageProcessor\n",
      "        from .models.idefics import IdeficsImageProcessor\n",
      "        from .models.idefics2 import Idefics2ImageProcessor\n",
      "        from .models.idefics3 import Idefics3ImageProcessor\n",
      "        from .models.imagegpt import ImageGPTFeatureExtractor, ImageGPTImageProcessor\n",
      "        from .models.instructblipvideo import InstructBlipVideoImageProcessor\n",
      "        from .models.layoutlmv2 import (\n",
      "            LayoutLMv2FeatureExtractor,\n",
      "            LayoutLMv2ImageProcessor,\n",
      "        )\n",
      "        from .models.layoutlmv3 import (\n",
      "            LayoutLMv3FeatureExtractor,\n",
      "            LayoutLMv3ImageProcessor,\n",
      "        )\n",
      "        from .models.levit import LevitFeatureExtractor, LevitImageProcessor\n",
      "        from .models.llava import LlavaImageProcessor\n",
      "        from .models.llava_next import LlavaNextImageProcessor\n",
      "        from .models.llava_next_video import LlavaNextVideoImageProcessor\n",
      "        from .models.llava_onevision import LlavaOnevisionImageProcessor, LlavaOnevisionVideoProcessor\n",
      "        from .models.mask2former import Mask2FormerImageProcessor\n",
      "        from .models.maskformer import (\n",
      "            MaskFormerFeatureExtractor,\n",
      "            MaskFormerImageProcessor,\n",
      "        )\n",
      "        from .models.mllama import MllamaImageProcessor\n",
      "        from .models.mobilenet_v1 import (\n",
      "            MobileNetV1FeatureExtractor,\n",
      "            MobileNetV1ImageProcessor,\n",
      "        )\n",
      "        from .models.mobilenet_v2 import (\n",
      "            MobileNetV2FeatureExtractor,\n",
      "            MobileNetV2ImageProcessor,\n",
      "        )\n",
      "        from .models.mobilevit import MobileViTFeatureExtractor, MobileViTImageProcessor\n",
      "        from .models.nougat import NougatImageProcessor\n",
      "        from .models.oneformer import OneFormerImageProcessor\n",
      "        from .models.owlv2 import Owlv2ImageProcessor\n",
      "        from .models.owlvit import OwlViTFeatureExtractor, OwlViTImageProcessor\n",
      "        from .models.perceiver import PerceiverFeatureExtractor, PerceiverImageProcessor\n",
      "        from .models.pix2struct import Pix2StructImageProcessor\n",
      "        from .models.pixtral import PixtralImageProcessor\n",
      "        from .models.poolformer import (\n",
      "            PoolFormerFeatureExtractor,\n",
      "            PoolFormerImageProcessor,\n",
      "        )\n",
      "        from .models.prompt_depth_anything import PromptDepthAnythingImageProcessor\n",
      "        from .models.pvt import PvtImageProcessor\n",
      "        from .models.qwen2_vl import Qwen2VLImageProcessor\n",
      "        from .models.rt_detr import RTDetrImageProcessor\n",
      "        from .models.sam import SamImageProcessor\n",
      "        from .models.segformer import SegformerFeatureExtractor, SegformerImageProcessor\n",
      "        from .models.seggpt import SegGptImageProcessor\n",
      "        from .models.siglip import SiglipImageProcessor\n",
      "        from .models.siglip2 import Siglip2ImageProcessor\n",
      "        from .models.smolvlm import SmolVLMImageProcessor\n",
      "        from .models.superglue import SuperGlueImageProcessor\n",
      "        from .models.superpoint import SuperPointImageProcessor\n",
      "        from .models.swin2sr import Swin2SRImageProcessor\n",
      "        from .models.textnet import TextNetImageProcessor\n",
      "        from .models.tvp import TvpImageProcessor\n",
      "        from .models.video_llava import VideoLlavaImageProcessor\n",
      "        from .models.videomae import VideoMAEFeatureExtractor, VideoMAEImageProcessor\n",
      "        from .models.vilt import ViltFeatureExtractor, ViltImageProcessor, ViltProcessor\n",
      "        from .models.vit import ViTFeatureExtractor, ViTImageProcessor\n",
      "        from .models.vitmatte import VitMatteImageProcessor\n",
      "        from .models.vitpose import VitPoseImageProcessor\n",
      "        from .models.vivit import VivitImageProcessor\n",
      "        from .models.yolos import YolosFeatureExtractor, YolosImageProcessor\n",
      "        from .models.zoedepth import ZoeDepthImageProcessor\n",
      "\n",
      "    try:\n",
      "        if not is_torchvision_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_torchvision_objects import *\n",
      "    else:\n",
      "        from .image_processing_utils_fast import BaseImageProcessorFast\n",
      "        from .models.blip import BlipImageProcessorFast\n",
      "        from .models.clip import CLIPImageProcessorFast\n",
      "        from .models.convnext import ConvNextImageProcessorFast\n",
      "        from .models.deformable_detr import DeformableDetrImageProcessorFast\n",
      "        from .models.deit import DeiTImageProcessorFast\n",
      "        from .models.depth_pro import DepthProImageProcessorFast\n",
      "        from .models.detr import DetrImageProcessorFast\n",
      "        from .models.gemma3 import Gemma3ImageProcessorFast\n",
      "        from .models.got_ocr2 import GotOcr2ImageProcessorFast\n",
      "        from .models.llama4 import Llama4ImageProcessorFast\n",
      "        from .models.llava import LlavaImageProcessorFast\n",
      "        from .models.llava_next import LlavaNextImageProcessorFast\n",
      "        from .models.llava_onevision import LlavaOnevisionImageProcessorFast\n",
      "        from .models.phi4_multimodal import Phi4MultimodalImageProcessorFast\n",
      "        from .models.pixtral import PixtralImageProcessorFast\n",
      "        from .models.qwen2_vl import Qwen2VLImageProcessorFast\n",
      "        from .models.rt_detr import RTDetrImageProcessorFast\n",
      "        from .models.siglip import SiglipImageProcessorFast\n",
      "        from .models.siglip2 import Siglip2ImageProcessorFast\n",
      "        from .models.vit import ViTImageProcessorFast\n",
      "\n",
      "    try:\n",
      "        if not (is_torchvision_available() and is_timm_available()):\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_timm_and_torchvision_objects import *\n",
      "    else:\n",
      "        from .models.timm_wrapper import TimmWrapperImageProcessor\n",
      "\n",
      "    # Modeling\n",
      "    try:\n",
      "        if not is_torch_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_pt_objects import *\n",
      "    else:\n",
      "        # Debugging\n",
      "        from .cache_utils import (\n",
      "            Cache,\n",
      "            CacheConfig,\n",
      "            DynamicCache,\n",
      "            EncoderDecoderCache,\n",
      "            HQQQuantizedCache,\n",
      "            HybridCache,\n",
      "            MambaCache,\n",
      "            OffloadedCache,\n",
      "            OffloadedStaticCache,\n",
      "            QuantizedCache,\n",
      "            QuantizedCacheConfig,\n",
      "            QuantoQuantizedCache,\n",
      "            SinkCache,\n",
      "            SlidingWindowCache,\n",
      "            StaticCache,\n",
      "        )\n",
      "        from .data.datasets import (\n",
      "            GlueDataset,\n",
      "            GlueDataTrainingArguments,\n",
      "            LineByLineTextDataset,\n",
      "            LineByLineWithRefDataset,\n",
      "            LineByLineWithSOPTextDataset,\n",
      "            SquadDataset,\n",
      "            SquadDataTrainingArguments,\n",
      "            TextDataset,\n",
      "            TextDatasetForNextSentencePrediction,\n",
      "        )\n",
      "        from .generation import (\n",
      "            AlternatingCodebooksLogitsProcessor,\n",
      "            BayesianDetectorConfig,\n",
      "            BayesianDetectorModel,\n",
      "            BeamScorer,\n",
      "            BeamSearchScorer,\n",
      "            ClassifierFreeGuidanceLogitsProcessor,\n",
      "            ConstrainedBeamSearchScorer,\n",
      "            Constraint,\n",
      "            ConstraintListState,\n",
      "            DisjunctiveConstraint,\n",
      "            EncoderNoRepeatNGramLogitsProcessor,\n",
      "            EncoderRepetitionPenaltyLogitsProcessor,\n",
      "            EosTokenCriteria,\n",
      "            EpsilonLogitsWarper,\n",
      "            EtaLogitsWarper,\n",
      "            ExponentialDecayLengthPenalty,\n",
      "            ForcedBOSTokenLogitsProcessor,\n",
      "            ForcedEOSTokenLogitsProcessor,\n",
      "            GenerationMixin,\n",
      "            HammingDiversityLogitsProcessor,\n",
      "            InfNanRemoveLogitsProcessor,\n",
      "            LogitNormalization,\n",
      "            LogitsProcessor,\n",
      "            LogitsProcessorList,\n",
      "            MaxLengthCriteria,\n",
      "            MaxTimeCriteria,\n",
      "            MinLengthLogitsProcessor,\n",
      "            MinNewTokensLengthLogitsProcessor,\n",
      "            MinPLogitsWarper,\n",
      "            NoBadWordsLogitsProcessor,\n",
      "            NoRepeatNGramLogitsProcessor,\n",
      "            PhrasalConstraint,\n",
      "            PrefixConstrainedLogitsProcessor,\n",
      "            RepetitionPenaltyLogitsProcessor,\n",
      "            SequenceBiasLogitsProcessor,\n",
      "            StoppingCriteria,\n",
      "            StoppingCriteriaList,\n",
      "            StopStringCriteria,\n",
      "            SuppressTokensAtBeginLogitsProcessor,\n",
      "            SuppressTokensLogitsProcessor,\n",
      "            SynthIDTextWatermarkDetector,\n",
      "            SynthIDTextWatermarkingConfig,\n",
      "            SynthIDTextWatermarkLogitsProcessor,\n",
      "            TemperatureLogitsWarper,\n",
      "            TopKLogitsWarper,\n",
      "            TopPLogitsWarper,\n",
      "            TypicalLogitsWarper,\n",
      "            UnbatchedClassifierFreeGuidanceLogitsProcessor,\n",
      "            WatermarkDetector,\n",
      "            WatermarkLogitsProcessor,\n",
      "            WhisperTimeStampLogitsProcessor,\n",
      "        )\n",
      "        from .integrations.executorch import (\n",
      "            TorchExportableModuleWithStaticCache,\n",
      "            convert_and_export_with_cache,\n",
      "        )\n",
      "        from .model_debugging_utils import (\n",
      "            model_addition_debugger,\n",
      "            model_addition_debugger_context,\n",
      "        )\n",
      "        from .modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n",
      "        from .modeling_utils import AttentionInterface, PreTrainedModel\n",
      "        from .models.albert import (\n",
      "            AlbertForMaskedLM,\n",
      "            AlbertForMultipleChoice,\n",
      "            AlbertForPreTraining,\n",
      "            AlbertForQuestionAnswering,\n",
      "            AlbertForSequenceClassification,\n",
      "            AlbertForTokenClassification,\n",
      "            AlbertModel,\n",
      "            AlbertPreTrainedModel,\n",
      "            load_tf_weights_in_albert,\n",
      "        )\n",
      "        from .models.align import (\n",
      "            AlignModel,\n",
      "            AlignPreTrainedModel,\n",
      "            AlignTextModel,\n",
      "            AlignVisionModel,\n",
      "        )\n",
      "        from .models.altclip import (\n",
      "            AltCLIPModel,\n",
      "            AltCLIPPreTrainedModel,\n",
      "            AltCLIPTextModel,\n",
      "            AltCLIPVisionModel,\n",
      "        )\n",
      "        from .models.aria import (\n",
      "            AriaForConditionalGeneration,\n",
      "            AriaPreTrainedModel,\n",
      "            AriaTextForCausalLM,\n",
      "            AriaTextModel,\n",
      "            AriaTextPreTrainedModel,\n",
      "        )\n",
      "        from .models.audio_spectrogram_transformer import (\n",
      "            ASTForAudioClassification,\n",
      "            ASTModel,\n",
      "            ASTPreTrainedModel,\n",
      "        )\n",
      "        from .models.auto import (\n",
      "            MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_AUDIO_XVECTOR_MAPPING,\n",
      "            MODEL_FOR_BACKBONE_MAPPING,\n",
      "            MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING,\n",
      "            MODEL_FOR_CAUSAL_LM_MAPPING,\n",
      "            MODEL_FOR_CTC_MAPPING,\n",
      "            MODEL_FOR_DEPTH_ESTIMATION_MAPPING,\n",
      "            MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING,\n",
      "            MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_IMAGE_MAPPING,\n",
      "            MODEL_FOR_IMAGE_SEGMENTATION_MAPPING,\n",
      "            MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING,\n",
      "            MODEL_FOR_IMAGE_TO_IMAGE_MAPPING,\n",
      "            MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING,\n",
      "            MODEL_FOR_KEYPOINT_DETECTION_MAPPING,\n",
      "            MODEL_FOR_MASK_GENERATION_MAPPING,\n",
      "            MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING,\n",
      "            MODEL_FOR_MASKED_LM_MAPPING,\n",
      "            MODEL_FOR_MULTIPLE_CHOICE_MAPPING,\n",
      "            MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING,\n",
      "            MODEL_FOR_OBJECT_DETECTION_MAPPING,\n",
      "            MODEL_FOR_PRETRAINING_MAPPING,\n",
      "            MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
      "            MODEL_FOR_RETRIEVAL_MAPPING,\n",
      "            MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING,\n",
      "            MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING,\n",
      "            MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING,\n",
      "            MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING,\n",
      "            MODEL_FOR_TEXT_ENCODING_MAPPING,\n",
      "            MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING,\n",
      "            MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING,\n",
      "            MODEL_FOR_TIME_SERIES_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_TIME_SERIES_REGRESSION_MAPPING,\n",
      "            MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING,\n",
      "            MODEL_FOR_VIDEO_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_VISION_2_SEQ_MAPPING,\n",
      "            MODEL_FOR_VISUAL_QUESTION_ANSWERING_MAPPING,\n",
      "            MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING,\n",
      "            MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING,\n",
      "            MODEL_MAPPING,\n",
      "            MODEL_WITH_LM_HEAD_MAPPING,\n",
      "            AutoBackbone,\n",
      "            AutoModel,\n",
      "            AutoModelForAudioClassification,\n",
      "            AutoModelForAudioFrameClassification,\n",
      "            AutoModelForAudioXVector,\n",
      "            AutoModelForCausalLM,\n",
      "            AutoModelForCTC,\n",
      "            AutoModelForDepthEstimation,\n",
      "            AutoModelForDocumentQuestionAnswering,\n",
      "            AutoModelForImageClassification,\n",
      "            AutoModelForImageSegmentation,\n",
      "            AutoModelForImageTextToText,\n",
      "            AutoModelForImageToImage,\n",
      "            AutoModelForInstanceSegmentation,\n",
      "            AutoModelForKeypointDetection,\n",
      "            AutoModelForMaskedImageModeling,\n",
      "            AutoModelForMaskedLM,\n",
      "            AutoModelForMaskGeneration,\n",
      "            AutoModelForMultipleChoice,\n",
      "            AutoModelForNextSentencePrediction,\n",
      "            AutoModelForObjectDetection,\n",
      "            AutoModelForPreTraining,\n",
      "            AutoModelForQuestionAnswering,\n",
      "            AutoModelForSemanticSegmentation,\n",
      "            AutoModelForSeq2SeqLM,\n",
      "            AutoModelForSequenceClassification,\n",
      "            AutoModelForSpeechSeq2Seq,\n",
      "            AutoModelForTableQuestionAnswering,\n",
      "            AutoModelForTextEncoding,\n",
      "            AutoModelForTextToSpectrogram,\n",
      "            AutoModelForTextToWaveform,\n",
      "            AutoModelForTokenClassification,\n",
      "            AutoModelForUniversalSegmentation,\n",
      "            AutoModelForVideoClassification,\n",
      "            AutoModelForVision2Seq,\n",
      "            AutoModelForVisualQuestionAnswering,\n",
      "            AutoModelForZeroShotImageClassification,\n",
      "            AutoModelForZeroShotObjectDetection,\n",
      "            AutoModelWithLMHead,\n",
      "        )\n",
      "        from .models.autoformer import (\n",
      "            AutoformerForPrediction,\n",
      "            AutoformerModel,\n",
      "            AutoformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.aya_vision import AyaVisionForConditionalGeneration, AyaVisionPreTrainedModel\n",
      "        from .models.bamba import BambaForCausalLM, BambaModel, BambaPreTrainedModel\n",
      "        from .models.bark import (\n",
      "            BarkCausalModel,\n",
      "            BarkCoarseModel,\n",
      "            BarkFineModel,\n",
      "            BarkModel,\n",
      "            BarkPreTrainedModel,\n",
      "            BarkSemanticModel,\n",
      "        )\n",
      "        from .models.bart import (\n",
      "            BartForCausalLM,\n",
      "            BartForConditionalGeneration,\n",
      "            BartForQuestionAnswering,\n",
      "            BartForSequenceClassification,\n",
      "            BartModel,\n",
      "            BartPreTrainedModel,\n",
      "            BartPretrainedModel,\n",
      "            PretrainedBartModel,\n",
      "        )\n",
      "        from .models.beit import (\n",
      "            BeitBackbone,\n",
      "            BeitForImageClassification,\n",
      "            BeitForMaskedImageModeling,\n",
      "            BeitForSemanticSegmentation,\n",
      "            BeitModel,\n",
      "            BeitPreTrainedModel,\n",
      "        )\n",
      "        from .models.bert import (\n",
      "            BertForMaskedLM,\n",
      "            BertForMultipleChoice,\n",
      "            BertForNextSentencePrediction,\n",
      "            BertForPreTraining,\n",
      "            BertForQuestionAnswering,\n",
      "            BertForSequenceClassification,\n",
      "            BertForTokenClassification,\n",
      "            BertLMHeadModel,\n",
      "            BertModel,\n",
      "            BertPreTrainedModel,\n",
      "            load_tf_weights_in_bert,\n",
      "        )\n",
      "        from .models.bert_generation import (\n",
      "            BertGenerationDecoder,\n",
      "            BertGenerationEncoder,\n",
      "            BertGenerationPreTrainedModel,\n",
      "            load_tf_weights_in_bert_generation,\n",
      "        )\n",
      "        from .models.big_bird import (\n",
      "            BigBirdForCausalLM,\n",
      "            BigBirdForMaskedLM,\n",
      "            BigBirdForMultipleChoice,\n",
      "            BigBirdForPreTraining,\n",
      "            BigBirdForQuestionAnswering,\n",
      "            BigBirdForSequenceClassification,\n",
      "            BigBirdForTokenClassification,\n",
      "            BigBirdModel,\n",
      "            BigBirdPreTrainedModel,\n",
      "            load_tf_weights_in_big_bird,\n",
      "        )\n",
      "        from .models.bigbird_pegasus import (\n",
      "            BigBirdPegasusForCausalLM,\n",
      "            BigBirdPegasusForConditionalGeneration,\n",
      "            BigBirdPegasusForQuestionAnswering,\n",
      "            BigBirdPegasusForSequenceClassification,\n",
      "            BigBirdPegasusModel,\n",
      "            BigBirdPegasusPreTrainedModel,\n",
      "        )\n",
      "        from .models.biogpt import (\n",
      "            BioGptForCausalLM,\n",
      "            BioGptForSequenceClassification,\n",
      "            BioGptForTokenClassification,\n",
      "            BioGptModel,\n",
      "            BioGptPreTrainedModel,\n",
      "        )\n",
      "        from .models.bit import (\n",
      "            BitBackbone,\n",
      "            BitForImageClassification,\n",
      "            BitModel,\n",
      "            BitPreTrainedModel,\n",
      "        )\n",
      "        from .models.blenderbot import (\n",
      "            BlenderbotForCausalLM,\n",
      "            BlenderbotForConditionalGeneration,\n",
      "            BlenderbotModel,\n",
      "            BlenderbotPreTrainedModel,\n",
      "        )\n",
      "        from .models.blenderbot_small import (\n",
      "            BlenderbotSmallForCausalLM,\n",
      "            BlenderbotSmallForConditionalGeneration,\n",
      "            BlenderbotSmallModel,\n",
      "            BlenderbotSmallPreTrainedModel,\n",
      "        )\n",
      "        from .models.blip import (\n",
      "            BlipForConditionalGeneration,\n",
      "            BlipForImageTextRetrieval,\n",
      "            BlipForQuestionAnswering,\n",
      "            BlipModel,\n",
      "            BlipPreTrainedModel,\n",
      "            BlipTextModel,\n",
      "            BlipVisionModel,\n",
      "        )\n",
      "        from .models.blip_2 import (\n",
      "            Blip2ForConditionalGeneration,\n",
      "            Blip2ForImageTextRetrieval,\n",
      "            Blip2Model,\n",
      "            Blip2PreTrainedModel,\n",
      "            Blip2QFormerModel,\n",
      "            Blip2TextModelWithProjection,\n",
      "            Blip2VisionModel,\n",
      "            Blip2VisionModelWithProjection,\n",
      "        )\n",
      "        from .models.bloom import (\n",
      "            BloomForCausalLM,\n",
      "            BloomForQuestionAnswering,\n",
      "            BloomForSequenceClassification,\n",
      "            BloomForTokenClassification,\n",
      "            BloomModel,\n",
      "            BloomPreTrainedModel,\n",
      "        )\n",
      "        from .models.bridgetower import (\n",
      "            BridgeTowerForContrastiveLearning,\n",
      "            BridgeTowerForImageAndTextRetrieval,\n",
      "            BridgeTowerForMaskedLM,\n",
      "            BridgeTowerModel,\n",
      "            BridgeTowerPreTrainedModel,\n",
      "        )\n",
      "        from .models.bros import (\n",
      "            BrosForTokenClassification,\n",
      "            BrosModel,\n",
      "            BrosPreTrainedModel,\n",
      "            BrosProcessor,\n",
      "            BrosSpadeEEForTokenClassification,\n",
      "            BrosSpadeELForTokenClassification,\n",
      "        )\n",
      "        from .models.camembert import (\n",
      "            CamembertForCausalLM,\n",
      "            CamembertForMaskedLM,\n",
      "            CamembertForMultipleChoice,\n",
      "            CamembertForQuestionAnswering,\n",
      "            CamembertForSequenceClassification,\n",
      "            CamembertForTokenClassification,\n",
      "            CamembertModel,\n",
      "            CamembertPreTrainedModel,\n",
      "        )\n",
      "        from .models.canine import (\n",
      "            CanineForMultipleChoice,\n",
      "            CanineForQuestionAnswering,\n",
      "            CanineForSequenceClassification,\n",
      "            CanineForTokenClassification,\n",
      "            CanineModel,\n",
      "            CaninePreTrainedModel,\n",
      "            load_tf_weights_in_canine,\n",
      "        )\n",
      "        from .models.chameleon import (\n",
      "            ChameleonForConditionalGeneration,\n",
      "            ChameleonModel,\n",
      "            ChameleonPreTrainedModel,\n",
      "            ChameleonProcessor,\n",
      "            ChameleonVQVAE,\n",
      "        )\n",
      "        from .models.chinese_clip import (\n",
      "            ChineseCLIPModel,\n",
      "            ChineseCLIPPreTrainedModel,\n",
      "            ChineseCLIPTextModel,\n",
      "            ChineseCLIPVisionModel,\n",
      "        )\n",
      "        from .models.clap import (\n",
      "            ClapAudioModel,\n",
      "            ClapAudioModelWithProjection,\n",
      "            ClapFeatureExtractor,\n",
      "            ClapModel,\n",
      "            ClapPreTrainedModel,\n",
      "            ClapTextModel,\n",
      "            ClapTextModelWithProjection,\n",
      "        )\n",
      "        from .models.clip import (\n",
      "            CLIPForImageClassification,\n",
      "            CLIPModel,\n",
      "            CLIPPreTrainedModel,\n",
      "            CLIPTextModel,\n",
      "            CLIPTextModelWithProjection,\n",
      "            CLIPVisionModel,\n",
      "            CLIPVisionModelWithProjection,\n",
      "        )\n",
      "        from .models.clipseg import (\n",
      "            CLIPSegForImageSegmentation,\n",
      "            CLIPSegModel,\n",
      "            CLIPSegPreTrainedModel,\n",
      "            CLIPSegTextModel,\n",
      "            CLIPSegVisionModel,\n",
      "        )\n",
      "        from .models.clvp import (\n",
      "            ClvpDecoder,\n",
      "            ClvpEncoder,\n",
      "            ClvpForCausalLM,\n",
      "            ClvpModel,\n",
      "            ClvpModelForConditionalGeneration,\n",
      "            ClvpPreTrainedModel,\n",
      "        )\n",
      "        from .models.codegen import (\n",
      "            CodeGenForCausalLM,\n",
      "            CodeGenModel,\n",
      "            CodeGenPreTrainedModel,\n",
      "        )\n",
      "        from .models.cohere import (\n",
      "            CohereForCausalLM,\n",
      "            CohereModel,\n",
      "            CoherePreTrainedModel,\n",
      "        )\n",
      "        from .models.cohere2 import (\n",
      "            Cohere2ForCausalLM,\n",
      "            Cohere2Model,\n",
      "            Cohere2PreTrainedModel,\n",
      "        )\n",
      "        from .models.colpali import (\n",
      "            ColPaliForRetrieval,\n",
      "            ColPaliPreTrainedModel,\n",
      "        )\n",
      "        from .models.conditional_detr import (\n",
      "            ConditionalDetrForObjectDetection,\n",
      "            ConditionalDetrForSegmentation,\n",
      "            ConditionalDetrModel,\n",
      "            ConditionalDetrPreTrainedModel,\n",
      "        )\n",
      "        from .models.convbert import (\n",
      "            ConvBertForMaskedLM,\n",
      "            ConvBertForMultipleChoice,\n",
      "            ConvBertForQuestionAnswering,\n",
      "            ConvBertForSequenceClassification,\n",
      "            ConvBertForTokenClassification,\n",
      "            ConvBertModel,\n",
      "            ConvBertPreTrainedModel,\n",
      "            load_tf_weights_in_convbert,\n",
      "        )\n",
      "        from .models.convnext import (\n",
      "            ConvNextBackbone,\n",
      "            ConvNextForImageClassification,\n",
      "            ConvNextModel,\n",
      "            ConvNextPreTrainedModel,\n",
      "        )\n",
      "        from .models.convnextv2 import (\n",
      "            ConvNextV2Backbone,\n",
      "            ConvNextV2ForImageClassification,\n",
      "            ConvNextV2Model,\n",
      "            ConvNextV2PreTrainedModel,\n",
      "        )\n",
      "        from .models.cpmant import (\n",
      "            CpmAntForCausalLM,\n",
      "            CpmAntModel,\n",
      "            CpmAntPreTrainedModel,\n",
      "        )\n",
      "        from .models.ctrl import (\n",
      "            CTRLForSequenceClassification,\n",
      "            CTRLLMHeadModel,\n",
      "            CTRLModel,\n",
      "            CTRLPreTrainedModel,\n",
      "        )\n",
      "        from .models.cvt import (\n",
      "            CvtForImageClassification,\n",
      "            CvtModel,\n",
      "            CvtPreTrainedModel,\n",
      "        )\n",
      "        from .models.dab_detr import (\n",
      "            DabDetrForObjectDetection,\n",
      "            DabDetrModel,\n",
      "            DabDetrPreTrainedModel,\n",
      "        )\n",
      "        from .models.dac import (\n",
      "            DacModel,\n",
      "            DacPreTrainedModel,\n",
      "        )\n",
      "        from .models.data2vec import (\n",
      "            Data2VecAudioForAudioFrameClassification,\n",
      "            Data2VecAudioForCTC,\n",
      "            Data2VecAudioForSequenceClassification,\n",
      "            Data2VecAudioForXVector,\n",
      "            Data2VecAudioModel,\n",
      "            Data2VecAudioPreTrainedModel,\n",
      "            Data2VecTextForCausalLM,\n",
      "            Data2VecTextForMaskedLM,\n",
      "            Data2VecTextForMultipleChoice,\n",
      "            Data2VecTextForQuestionAnswering,\n",
      "            Data2VecTextForSequenceClassification,\n",
      "            Data2VecTextForTokenClassification,\n",
      "            Data2VecTextModel,\n",
      "            Data2VecTextPreTrainedModel,\n",
      "            Data2VecVisionForImageClassification,\n",
      "            Data2VecVisionForSemanticSegmentation,\n",
      "            Data2VecVisionModel,\n",
      "            Data2VecVisionPreTrainedModel,\n",
      "        )\n",
      "\n",
      "        # PyTorch model imports\n",
      "        from .models.dbrx import (\n",
      "            DbrxForCausalLM,\n",
      "            DbrxModel,\n",
      "            DbrxPreTrainedModel,\n",
      "        )\n",
      "        from .models.deberta import (\n",
      "            DebertaForMaskedLM,\n",
      "            DebertaForQuestionAnswering,\n",
      "            DebertaForSequenceClassification,\n",
      "            DebertaForTokenClassification,\n",
      "            DebertaModel,\n",
      "            DebertaPreTrainedModel,\n",
      "        )\n",
      "        from .models.deberta_v2 import (\n",
      "            DebertaV2ForMaskedLM,\n",
      "            DebertaV2ForMultipleChoice,\n",
      "            DebertaV2ForQuestionAnswering,\n",
      "            DebertaV2ForSequenceClassification,\n",
      "            DebertaV2ForTokenClassification,\n",
      "            DebertaV2Model,\n",
      "            DebertaV2PreTrainedModel,\n",
      "        )\n",
      "        from .models.decision_transformer import (\n",
      "            DecisionTransformerGPT2Model,\n",
      "            DecisionTransformerGPT2PreTrainedModel,\n",
      "            DecisionTransformerModel,\n",
      "            DecisionTransformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.deepseek_v3 import (\n",
      "            DeepseekV3ForCausalLM,\n",
      "            DeepseekV3Model,\n",
      "            DeepseekV3PreTrainedModel,\n",
      "        )\n",
      "        from .models.deformable_detr import (\n",
      "            DeformableDetrForObjectDetection,\n",
      "            DeformableDetrModel,\n",
      "            DeformableDetrPreTrainedModel,\n",
      "        )\n",
      "        from .models.deit import (\n",
      "            DeiTForImageClassification,\n",
      "            DeiTForImageClassificationWithTeacher,\n",
      "            DeiTForMaskedImageModeling,\n",
      "            DeiTModel,\n",
      "            DeiTPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.deta import (\n",
      "            DetaForObjectDetection,\n",
      "            DetaModel,\n",
      "            DetaPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.efficientformer import (\n",
      "            EfficientFormerForImageClassification,\n",
      "            EfficientFormerForImageClassificationWithTeacher,\n",
      "            EfficientFormerModel,\n",
      "            EfficientFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.ernie_m import (\n",
      "            ErnieMForInformationExtraction,\n",
      "            ErnieMForMultipleChoice,\n",
      "            ErnieMForQuestionAnswering,\n",
      "            ErnieMForSequenceClassification,\n",
      "            ErnieMForTokenClassification,\n",
      "            ErnieMModel,\n",
      "            ErnieMPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.gptsan_japanese import (\n",
      "            GPTSanJapaneseForConditionalGeneration,\n",
      "            GPTSanJapaneseModel,\n",
      "            GPTSanJapanesePreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.graphormer import (\n",
      "            GraphormerForGraphClassification,\n",
      "            GraphormerModel,\n",
      "            GraphormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.jukebox import (\n",
      "            JukeboxModel,\n",
      "            JukeboxPreTrainedModel,\n",
      "            JukeboxPrior,\n",
      "            JukeboxVQVAE,\n",
      "        )\n",
      "        from .models.deprecated.mctct import (\n",
      "            MCTCTForCTC,\n",
      "            MCTCTModel,\n",
      "            MCTCTPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.mega import (\n",
      "            MegaForCausalLM,\n",
      "            MegaForMaskedLM,\n",
      "            MegaForMultipleChoice,\n",
      "            MegaForQuestionAnswering,\n",
      "            MegaForSequenceClassification,\n",
      "            MegaForTokenClassification,\n",
      "            MegaModel,\n",
      "            MegaPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.mmbt import (\n",
      "            MMBTForClassification,\n",
      "            MMBTModel,\n",
      "            ModalEmbeddings,\n",
      "        )\n",
      "        from .models.deprecated.nat import (\n",
      "            NatBackbone,\n",
      "            NatForImageClassification,\n",
      "            NatModel,\n",
      "            NatPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.nezha import (\n",
      "            NezhaForMaskedLM,\n",
      "            NezhaForMultipleChoice,\n",
      "            NezhaForNextSentencePrediction,\n",
      "            NezhaForPreTraining,\n",
      "            NezhaForQuestionAnswering,\n",
      "            NezhaForSequenceClassification,\n",
      "            NezhaForTokenClassification,\n",
      "            NezhaModel,\n",
      "            NezhaPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.open_llama import (\n",
      "            OpenLlamaForCausalLM,\n",
      "            OpenLlamaForSequenceClassification,\n",
      "            OpenLlamaModel,\n",
      "            OpenLlamaPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.qdqbert import (\n",
      "            QDQBertForMaskedLM,\n",
      "            QDQBertForMultipleChoice,\n",
      "            QDQBertForNextSentencePrediction,\n",
      "            QDQBertForQuestionAnswering,\n",
      "            QDQBertForSequenceClassification,\n",
      "            QDQBertForTokenClassification,\n",
      "            QDQBertLMHeadModel,\n",
      "            QDQBertModel,\n",
      "            QDQBertPreTrainedModel,\n",
      "            load_tf_weights_in_qdqbert,\n",
      "        )\n",
      "        from .models.deprecated.realm import (\n",
      "            RealmEmbedder,\n",
      "            RealmForOpenQA,\n",
      "            RealmKnowledgeAugEncoder,\n",
      "            RealmPreTrainedModel,\n",
      "            RealmReader,\n",
      "            RealmRetriever,\n",
      "            RealmScorer,\n",
      "            load_tf_weights_in_realm,\n",
      "        )\n",
      "        from .models.deprecated.retribert import (\n",
      "            RetriBertModel,\n",
      "            RetriBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.speech_to_text_2 import (\n",
      "            Speech2Text2ForCausalLM,\n",
      "            Speech2Text2PreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.trajectory_transformer import (\n",
      "            TrajectoryTransformerModel,\n",
      "            TrajectoryTransformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.transfo_xl import (\n",
      "            AdaptiveEmbedding,\n",
      "            TransfoXLForSequenceClassification,\n",
      "            TransfoXLLMHeadModel,\n",
      "            TransfoXLModel,\n",
      "            TransfoXLPreTrainedModel,\n",
      "            load_tf_weights_in_transfo_xl,\n",
      "        )\n",
      "        from .models.deprecated.tvlt import (\n",
      "            TvltForAudioVisualClassification,\n",
      "            TvltForPreTraining,\n",
      "            TvltModel,\n",
      "            TvltPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.van import (\n",
      "            VanForImageClassification,\n",
      "            VanModel,\n",
      "            VanPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.vit_hybrid import (\n",
      "            ViTHybridForImageClassification,\n",
      "            ViTHybridModel,\n",
      "            ViTHybridPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.xlm_prophetnet import (\n",
      "            XLMProphetNetDecoder,\n",
      "            XLMProphetNetEncoder,\n",
      "            XLMProphetNetForCausalLM,\n",
      "            XLMProphetNetForConditionalGeneration,\n",
      "            XLMProphetNetModel,\n",
      "            XLMProphetNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.depth_anything import (\n",
      "            DepthAnythingForDepthEstimation,\n",
      "            DepthAnythingPreTrainedModel,\n",
      "        )\n",
      "        from .models.depth_pro import (\n",
      "            DepthProForDepthEstimation,\n",
      "            DepthProModel,\n",
      "            DepthProPreTrainedModel,\n",
      "        )\n",
      "        from .models.detr import (\n",
      "            DetrForObjectDetection,\n",
      "            DetrForSegmentation,\n",
      "            DetrModel,\n",
      "            DetrPreTrainedModel,\n",
      "        )\n",
      "        from .models.diffllama import (\n",
      "            DiffLlamaForCausalLM,\n",
      "            DiffLlamaForQuestionAnswering,\n",
      "            DiffLlamaForSequenceClassification,\n",
      "            DiffLlamaForTokenClassification,\n",
      "            DiffLlamaModel,\n",
      "            DiffLlamaPreTrainedModel,\n",
      "        )\n",
      "        from .models.dinat import (\n",
      "            DinatBackbone,\n",
      "            DinatForImageClassification,\n",
      "            DinatModel,\n",
      "            DinatPreTrainedModel,\n",
      "        )\n",
      "        from .models.dinov2 import (\n",
      "            Dinov2Backbone,\n",
      "            Dinov2ForImageClassification,\n",
      "            Dinov2Model,\n",
      "            Dinov2PreTrainedModel,\n",
      "        )\n",
      "        from .models.dinov2_with_registers import (\n",
      "            Dinov2WithRegistersBackbone,\n",
      "            Dinov2WithRegistersForImageClassification,\n",
      "            Dinov2WithRegistersModel,\n",
      "            Dinov2WithRegistersPreTrainedModel,\n",
      "        )\n",
      "        from .models.distilbert import (\n",
      "            DistilBertForMaskedLM,\n",
      "            DistilBertForMultipleChoice,\n",
      "            DistilBertForQuestionAnswering,\n",
      "            DistilBertForSequenceClassification,\n",
      "            DistilBertForTokenClassification,\n",
      "            DistilBertModel,\n",
      "            DistilBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.donut import (\n",
      "            DonutSwinModel,\n",
      "            DonutSwinPreTrainedModel,\n",
      "        )\n",
      "        from .models.dpr import (\n",
      "            DPRContextEncoder,\n",
      "            DPRPretrainedContextEncoder,\n",
      "            DPRPreTrainedModel,\n",
      "            DPRPretrainedQuestionEncoder,\n",
      "            DPRPretrainedReader,\n",
      "            DPRQuestionEncoder,\n",
      "            DPRReader,\n",
      "        )\n",
      "        from .models.dpt import (\n",
      "            DPTForDepthEstimation,\n",
      "            DPTForSemanticSegmentation,\n",
      "            DPTModel,\n",
      "            DPTPreTrainedModel,\n",
      "        )\n",
      "        from .models.efficientnet import (\n",
      "            EfficientNetForImageClassification,\n",
      "            EfficientNetModel,\n",
      "            EfficientNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.electra import (\n",
      "            ElectraForCausalLM,\n",
      "            ElectraForMaskedLM,\n",
      "            ElectraForMultipleChoice,\n",
      "            ElectraForPreTraining,\n",
      "            ElectraForQuestionAnswering,\n",
      "            ElectraForSequenceClassification,\n",
      "            ElectraForTokenClassification,\n",
      "            ElectraModel,\n",
      "            ElectraPreTrainedModel,\n",
      "            load_tf_weights_in_electra,\n",
      "        )\n",
      "        from .models.emu3 import (\n",
      "            Emu3ForCausalLM,\n",
      "            Emu3ForConditionalGeneration,\n",
      "            Emu3PreTrainedModel,\n",
      "            Emu3TextModel,\n",
      "            Emu3VQVAE,\n",
      "        )\n",
      "        from .models.encodec import (\n",
      "            EncodecModel,\n",
      "            EncodecPreTrainedModel,\n",
      "        )\n",
      "        from .models.encoder_decoder import EncoderDecoderModel\n",
      "        from .models.ernie import (\n",
      "            ErnieForCausalLM,\n",
      "            ErnieForMaskedLM,\n",
      "            ErnieForMultipleChoice,\n",
      "            ErnieForNextSentencePrediction,\n",
      "            ErnieForPreTraining,\n",
      "            ErnieForQuestionAnswering,\n",
      "            ErnieForSequenceClassification,\n",
      "            ErnieForTokenClassification,\n",
      "            ErnieModel,\n",
      "            ErniePreTrainedModel,\n",
      "        )\n",
      "        from .models.esm import (\n",
      "            EsmFoldPreTrainedModel,\n",
      "            EsmForMaskedLM,\n",
      "            EsmForProteinFolding,\n",
      "            EsmForSequenceClassification,\n",
      "            EsmForTokenClassification,\n",
      "            EsmModel,\n",
      "            EsmPreTrainedModel,\n",
      "        )\n",
      "        from .models.falcon import (\n",
      "            FalconForCausalLM,\n",
      "            FalconForQuestionAnswering,\n",
      "            FalconForSequenceClassification,\n",
      "            FalconForTokenClassification,\n",
      "            FalconModel,\n",
      "            FalconPreTrainedModel,\n",
      "        )\n",
      "        from .models.falcon_mamba import (\n",
      "            FalconMambaForCausalLM,\n",
      "            FalconMambaModel,\n",
      "            FalconMambaPreTrainedModel,\n",
      "        )\n",
      "        from .models.fastspeech2_conformer import (\n",
      "            FastSpeech2ConformerHifiGan,\n",
      "            FastSpeech2ConformerModel,\n",
      "            FastSpeech2ConformerPreTrainedModel,\n",
      "            FastSpeech2ConformerWithHifiGan,\n",
      "        )\n",
      "        from .models.flaubert import (\n",
      "            FlaubertForMultipleChoice,\n",
      "            FlaubertForQuestionAnswering,\n",
      "            FlaubertForQuestionAnsweringSimple,\n",
      "            FlaubertForSequenceClassification,\n",
      "            FlaubertForTokenClassification,\n",
      "            FlaubertModel,\n",
      "            FlaubertPreTrainedModel,\n",
      "            FlaubertWithLMHeadModel,\n",
      "        )\n",
      "        from .models.flava import (\n",
      "            FlavaForPreTraining,\n",
      "            FlavaImageCodebook,\n",
      "            FlavaImageModel,\n",
      "            FlavaModel,\n",
      "            FlavaMultimodalModel,\n",
      "            FlavaPreTrainedModel,\n",
      "            FlavaTextModel,\n",
      "        )\n",
      "        from .models.fnet import (\n",
      "            FNetForMaskedLM,\n",
      "            FNetForMultipleChoice,\n",
      "            FNetForNextSentencePrediction,\n",
      "            FNetForPreTraining,\n",
      "            FNetForQuestionAnswering,\n",
      "            FNetForSequenceClassification,\n",
      "            FNetForTokenClassification,\n",
      "            FNetModel,\n",
      "            FNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.focalnet import (\n",
      "            FocalNetBackbone,\n",
      "            FocalNetForImageClassification,\n",
      "            FocalNetForMaskedImageModeling,\n",
      "            FocalNetModel,\n",
      "            FocalNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.fsmt import (\n",
      "            FSMTForConditionalGeneration,\n",
      "            FSMTModel,\n",
      "            PretrainedFSMTModel,\n",
      "        )\n",
      "        from .models.funnel import (\n",
      "            FunnelBaseModel,\n",
      "            FunnelForMaskedLM,\n",
      "            FunnelForMultipleChoice,\n",
      "            FunnelForPreTraining,\n",
      "            FunnelForQuestionAnswering,\n",
      "            FunnelForSequenceClassification,\n",
      "            FunnelForTokenClassification,\n",
      "            FunnelModel,\n",
      "            FunnelPreTrainedModel,\n",
      "            load_tf_weights_in_funnel,\n",
      "        )\n",
      "        from .models.fuyu import (\n",
      "            FuyuForCausalLM,\n",
      "            FuyuPreTrainedModel,\n",
      "        )\n",
      "        from .models.gemma import (\n",
      "            GemmaForCausalLM,\n",
      "            GemmaForSequenceClassification,\n",
      "            GemmaForTokenClassification,\n",
      "            GemmaModel,\n",
      "            GemmaPreTrainedModel,\n",
      "        )\n",
      "        from .models.gemma2 import (\n",
      "            Gemma2ForCausalLM,\n",
      "            Gemma2ForSequenceClassification,\n",
      "            Gemma2ForTokenClassification,\n",
      "            Gemma2Model,\n",
      "            Gemma2PreTrainedModel,\n",
      "        )\n",
      "        from .models.gemma3 import (\n",
      "            Gemma3ForCausalLM,\n",
      "            Gemma3ForConditionalGeneration,\n",
      "            Gemma3PreTrainedModel,\n",
      "            Gemma3TextModel,\n",
      "        )\n",
      "        from .models.git import (\n",
      "            GitForCausalLM,\n",
      "            GitModel,\n",
      "            GitPreTrainedModel,\n",
      "            GitVisionModel,\n",
      "        )\n",
      "        from .models.glm import (\n",
      "            GlmForCausalLM,\n",
      "            GlmForSequenceClassification,\n",
      "            GlmForTokenClassification,\n",
      "            GlmModel,\n",
      "            GlmPreTrainedModel,\n",
      "        )\n",
      "        from .models.glm4 import (\n",
      "            Glm4ForCausalLM,\n",
      "            Glm4ForSequenceClassification,\n",
      "            Glm4ForTokenClassification,\n",
      "            Glm4Model,\n",
      "            Glm4PreTrainedModel,\n",
      "        )\n",
      "        from .models.glpn import (\n",
      "            GLPNForDepthEstimation,\n",
      "            GLPNModel,\n",
      "            GLPNPreTrainedModel,\n",
      "        )\n",
      "        from .models.got_ocr2 import (\n",
      "            GotOcr2ForConditionalGeneration,\n",
      "            GotOcr2PreTrainedModel,\n",
      "        )\n",
      "        from .models.gpt2 import (\n",
      "            GPT2DoubleHeadsModel,\n",
      "            GPT2ForQuestionAnswering,\n",
      "            GPT2ForSequenceClassification,\n",
      "            GPT2ForTokenClassification,\n",
      "            GPT2LMHeadModel,\n",
      "            GPT2Model,\n",
      "            GPT2PreTrainedModel,\n",
      "            load_tf_weights_in_gpt2,\n",
      "        )\n",
      "        from .models.gpt_bigcode import (\n",
      "            GPTBigCodeForCausalLM,\n",
      "            GPTBigCodeForSequenceClassification,\n",
      "            GPTBigCodeForTokenClassification,\n",
      "            GPTBigCodeModel,\n",
      "            GPTBigCodePreTrainedModel,\n",
      "        )\n",
      "        from .models.gpt_neo import (\n",
      "            GPTNeoForCausalLM,\n",
      "            GPTNeoForQuestionAnswering,\n",
      "            GPTNeoForSequenceClassification,\n",
      "            GPTNeoForTokenClassification,\n",
      "            GPTNeoModel,\n",
      "            GPTNeoPreTrainedModel,\n",
      "            load_tf_weights_in_gpt_neo,\n",
      "        )\n",
      "        from .models.gpt_neox import (\n",
      "            GPTNeoXForCausalLM,\n",
      "            GPTNeoXForQuestionAnswering,\n",
      "            GPTNeoXForSequenceClassification,\n",
      "            GPTNeoXForTokenClassification,\n",
      "            GPTNeoXModel,\n",
      "            GPTNeoXPreTrainedModel,\n",
      "        )\n",
      "        from .models.gpt_neox_japanese import (\n",
      "            GPTNeoXJapaneseForCausalLM,\n",
      "            GPTNeoXJapaneseModel,\n",
      "            GPTNeoXJapanesePreTrainedModel,\n",
      "        )\n",
      "        from .models.gptj import (\n",
      "            GPTJForCausalLM,\n",
      "            GPTJForQuestionAnswering,\n",
      "            GPTJForSequenceClassification,\n",
      "            GPTJModel,\n",
      "            GPTJPreTrainedModel,\n",
      "        )\n",
      "        from .models.granite import (\n",
      "            GraniteForCausalLM,\n",
      "            GraniteModel,\n",
      "            GranitePreTrainedModel,\n",
      "        )\n",
      "        from .models.granitemoe import (\n",
      "            GraniteMoeForCausalLM,\n",
      "            GraniteMoeModel,\n",
      "            GraniteMoePreTrainedModel,\n",
      "        )\n",
      "        from .models.granitemoeshared import (\n",
      "            GraniteMoeSharedForCausalLM,\n",
      "            GraniteMoeSharedModel,\n",
      "            GraniteMoeSharedPreTrainedModel,\n",
      "        )\n",
      "        from .models.grounding_dino import (\n",
      "            GroundingDinoForObjectDetection,\n",
      "            GroundingDinoModel,\n",
      "            GroundingDinoPreTrainedModel,\n",
      "        )\n",
      "        from .models.groupvit import (\n",
      "            GroupViTModel,\n",
      "            GroupViTPreTrainedModel,\n",
      "            GroupViTTextModel,\n",
      "            GroupViTVisionModel,\n",
      "        )\n",
      "        from .models.helium import (\n",
      "            HeliumForCausalLM,\n",
      "            HeliumForSequenceClassification,\n",
      "            HeliumForTokenClassification,\n",
      "            HeliumModel,\n",
      "            HeliumPreTrainedModel,\n",
      "        )\n",
      "        from .models.hiera import (\n",
      "            HieraBackbone,\n",
      "            HieraForImageClassification,\n",
      "            HieraForPreTraining,\n",
      "            HieraModel,\n",
      "            HieraPreTrainedModel,\n",
      "        )\n",
      "        from .models.hubert import (\n",
      "            HubertForCTC,\n",
      "            HubertForSequenceClassification,\n",
      "            HubertModel,\n",
      "            HubertPreTrainedModel,\n",
      "        )\n",
      "        from .models.ibert import (\n",
      "            IBertForMaskedLM,\n",
      "            IBertForMultipleChoice,\n",
      "            IBertForQuestionAnswering,\n",
      "            IBertForSequenceClassification,\n",
      "            IBertForTokenClassification,\n",
      "            IBertModel,\n",
      "            IBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.idefics import (\n",
      "            IdeficsForVisionText2Text,\n",
      "            IdeficsModel,\n",
      "            IdeficsPreTrainedModel,\n",
      "            IdeficsProcessor,\n",
      "        )\n",
      "        from .models.idefics2 import (\n",
      "            Idefics2ForConditionalGeneration,\n",
      "            Idefics2Model,\n",
      "            Idefics2PreTrainedModel,\n",
      "            Idefics2Processor,\n",
      "        )\n",
      "        from .models.idefics3 import (\n",
      "            Idefics3ForConditionalGeneration,\n",
      "            Idefics3Model,\n",
      "            Idefics3PreTrainedModel,\n",
      "            Idefics3Processor,\n",
      "            Idefics3VisionConfig,\n",
      "            Idefics3VisionTransformer,\n",
      "        )\n",
      "        from .models.ijepa import (\n",
      "            IJepaForImageClassification,\n",
      "            IJepaModel,\n",
      "            IJepaPreTrainedModel,\n",
      "        )\n",
      "        from .models.imagegpt import (\n",
      "            ImageGPTForCausalImageModeling,\n",
      "            ImageGPTForImageClassification,\n",
      "            ImageGPTModel,\n",
      "            ImageGPTPreTrainedModel,\n",
      "            load_tf_weights_in_imagegpt,\n",
      "        )\n",
      "        from .models.informer import (\n",
      "            InformerForPrediction,\n",
      "            InformerModel,\n",
      "            InformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.instructblip import (\n",
      "            InstructBlipForConditionalGeneration,\n",
      "            InstructBlipPreTrainedModel,\n",
      "            InstructBlipQFormerModel,\n",
      "            InstructBlipVisionModel,\n",
      "        )\n",
      "        from .models.instructblipvideo import (\n",
      "            InstructBlipVideoForConditionalGeneration,\n",
      "            InstructBlipVideoPreTrainedModel,\n",
      "            InstructBlipVideoQFormerModel,\n",
      "            InstructBlipVideoVisionModel,\n",
      "        )\n",
      "        from .models.jamba import (\n",
      "            JambaForCausalLM,\n",
      "            JambaForSequenceClassification,\n",
      "            JambaModel,\n",
      "            JambaPreTrainedModel,\n",
      "        )\n",
      "        from .models.jetmoe import (\n",
      "            JetMoeForCausalLM,\n",
      "            JetMoeForSequenceClassification,\n",
      "            JetMoeModel,\n",
      "            JetMoePreTrainedModel,\n",
      "        )\n",
      "        from .models.kosmos2 import (\n",
      "            Kosmos2ForConditionalGeneration,\n",
      "            Kosmos2Model,\n",
      "            Kosmos2PreTrainedModel,\n",
      "        )\n",
      "        from .models.layoutlm import (\n",
      "            LayoutLMForMaskedLM,\n",
      "            LayoutLMForQuestionAnswering,\n",
      "            LayoutLMForSequenceClassification,\n",
      "            LayoutLMForTokenClassification,\n",
      "            LayoutLMModel,\n",
      "            LayoutLMPreTrainedModel,\n",
      "        )\n",
      "        from .models.layoutlmv2 import (\n",
      "            LayoutLMv2ForQuestionAnswering,\n",
      "            LayoutLMv2ForSequenceClassification,\n",
      "            LayoutLMv2ForTokenClassification,\n",
      "            LayoutLMv2Model,\n",
      "            LayoutLMv2PreTrainedModel,\n",
      "        )\n",
      "        from .models.layoutlmv3 import (\n",
      "            LayoutLMv3ForQuestionAnswering,\n",
      "            LayoutLMv3ForSequenceClassification,\n",
      "            LayoutLMv3ForTokenClassification,\n",
      "            LayoutLMv3Model,\n",
      "            LayoutLMv3PreTrainedModel,\n",
      "        )\n",
      "        from .models.led import (\n",
      "            LEDForConditionalGeneration,\n",
      "            LEDForQuestionAnswering,\n",
      "            LEDForSequenceClassification,\n",
      "            LEDModel,\n",
      "            LEDPreTrainedModel,\n",
      "        )\n",
      "        from .models.levit import (\n",
      "            LevitForImageClassification,\n",
      "            LevitForImageClassificationWithTeacher,\n",
      "            LevitModel,\n",
      "            LevitPreTrainedModel,\n",
      "        )\n",
      "        from .models.lilt import (\n",
      "            LiltForQuestionAnswering,\n",
      "            LiltForSequenceClassification,\n",
      "            LiltForTokenClassification,\n",
      "            LiltModel,\n",
      "            LiltPreTrainedModel,\n",
      "        )\n",
      "        from .models.llama import (\n",
      "            LlamaForCausalLM,\n",
      "            LlamaForQuestionAnswering,\n",
      "            LlamaForSequenceClassification,\n",
      "            LlamaForTokenClassification,\n",
      "            LlamaModel,\n",
      "            LlamaPreTrainedModel,\n",
      "        )\n",
      "        from .models.llama4 import (\n",
      "            Llama4ForCausalLM,\n",
      "            Llama4ForConditionalGeneration,\n",
      "            Llama4PreTrainedModel,\n",
      "            Llama4TextModel,\n",
      "            Llama4VisionModel,\n",
      "        )\n",
      "        from .models.llava import (\n",
      "            LlavaForConditionalGeneration,\n",
      "            LlavaPreTrainedModel,\n",
      "        )\n",
      "        from .models.llava_next import (\n",
      "            LlavaNextForConditionalGeneration,\n",
      "            LlavaNextPreTrainedModel,\n",
      "        )\n",
      "        from .models.llava_next_video import (\n",
      "            LlavaNextVideoForConditionalGeneration,\n",
      "            LlavaNextVideoPreTrainedModel,\n",
      "        )\n",
      "        from .models.llava_onevision import (\n",
      "            LlavaOnevisionForConditionalGeneration,\n",
      "            LlavaOnevisionPreTrainedModel,\n",
      "        )\n",
      "        from .models.longformer import (\n",
      "            LongformerForMaskedLM,\n",
      "            LongformerForMultipleChoice,\n",
      "            LongformerForQuestionAnswering,\n",
      "            LongformerForSequenceClassification,\n",
      "            LongformerForTokenClassification,\n",
      "            LongformerModel,\n",
      "            LongformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.longt5 import (\n",
      "            LongT5EncoderModel,\n",
      "            LongT5ForConditionalGeneration,\n",
      "            LongT5Model,\n",
      "            LongT5PreTrainedModel,\n",
      "        )\n",
      "        from .models.luke import (\n",
      "            LukeForEntityClassification,\n",
      "            LukeForEntityPairClassification,\n",
      "            LukeForEntitySpanClassification,\n",
      "            LukeForMaskedLM,\n",
      "            LukeForMultipleChoice,\n",
      "            LukeForQuestionAnswering,\n",
      "            LukeForSequenceClassification,\n",
      "            LukeForTokenClassification,\n",
      "            LukeModel,\n",
      "            LukePreTrainedModel,\n",
      "        )\n",
      "        from .models.lxmert import (\n",
      "            LxmertEncoder,\n",
      "            LxmertForPreTraining,\n",
      "            LxmertForQuestionAnswering,\n",
      "            LxmertModel,\n",
      "            LxmertPreTrainedModel,\n",
      "            LxmertVisualFeatureEncoder,\n",
      "        )\n",
      "        from .models.m2m_100 import (\n",
      "            M2M100ForConditionalGeneration,\n",
      "            M2M100Model,\n",
      "            M2M100PreTrainedModel,\n",
      "        )\n",
      "        from .models.mamba import (\n",
      "            MambaForCausalLM,\n",
      "            MambaModel,\n",
      "            MambaPreTrainedModel,\n",
      "        )\n",
      "        from .models.mamba2 import (\n",
      "            Mamba2ForCausalLM,\n",
      "            Mamba2Model,\n",
      "            Mamba2PreTrainedModel,\n",
      "        )\n",
      "        from .models.marian import MarianForCausalLM, MarianModel, MarianMTModel, MarianPreTrainedModel\n",
      "        from .models.markuplm import (\n",
      "            MarkupLMForQuestionAnswering,\n",
      "            MarkupLMForSequenceClassification,\n",
      "            MarkupLMForTokenClassification,\n",
      "            MarkupLMModel,\n",
      "            MarkupLMPreTrainedModel,\n",
      "        )\n",
      "        from .models.mask2former import (\n",
      "            Mask2FormerForUniversalSegmentation,\n",
      "            Mask2FormerModel,\n",
      "            Mask2FormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.maskformer import (\n",
      "            MaskFormerForInstanceSegmentation,\n",
      "            MaskFormerModel,\n",
      "            MaskFormerPreTrainedModel,\n",
      "            MaskFormerSwinBackbone,\n",
      "        )\n",
      "        from .models.mbart import (\n",
      "            MBartForCausalLM,\n",
      "            MBartForConditionalGeneration,\n",
      "            MBartForQuestionAnswering,\n",
      "            MBartForSequenceClassification,\n",
      "            MBartModel,\n",
      "            MBartPreTrainedModel,\n",
      "        )\n",
      "        from .models.megatron_bert import (\n",
      "            MegatronBertForCausalLM,\n",
      "            MegatronBertForMaskedLM,\n",
      "            MegatronBertForMultipleChoice,\n",
      "            MegatronBertForNextSentencePrediction,\n",
      "            MegatronBertForPreTraining,\n",
      "            MegatronBertForQuestionAnswering,\n",
      "            MegatronBertForSequenceClassification,\n",
      "            MegatronBertForTokenClassification,\n",
      "            MegatronBertModel,\n",
      "            MegatronBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.mgp_str import (\n",
      "            MgpstrForSceneTextRecognition,\n",
      "            MgpstrModel,\n",
      "            MgpstrPreTrainedModel,\n",
      "        )\n",
      "        from .models.mimi import (\n",
      "            MimiModel,\n",
      "            MimiPreTrainedModel,\n",
      "        )\n",
      "        from .models.mistral import (\n",
      "            MistralForCausalLM,\n",
      "            MistralForQuestionAnswering,\n",
      "            MistralForSequenceClassification,\n",
      "            MistralForTokenClassification,\n",
      "            MistralModel,\n",
      "            MistralPreTrainedModel,\n",
      "        )\n",
      "        from .models.mistral3 import (\n",
      "            Mistral3ForConditionalGeneration,\n",
      "            Mistral3PreTrainedModel,\n",
      "        )\n",
      "        from .models.mixtral import (\n",
      "            MixtralForCausalLM,\n",
      "            MixtralForQuestionAnswering,\n",
      "            MixtralForSequenceClassification,\n",
      "            MixtralForTokenClassification,\n",
      "            MixtralModel,\n",
      "            MixtralPreTrainedModel,\n",
      "        )\n",
      "        from .models.mllama import (\n",
      "            MllamaForCausalLM,\n",
      "            MllamaForConditionalGeneration,\n",
      "            MllamaPreTrainedModel,\n",
      "            MllamaProcessor,\n",
      "            MllamaTextModel,\n",
      "            MllamaVisionModel,\n",
      "        )\n",
      "        from .models.mobilebert import (\n",
      "            MobileBertForMaskedLM,\n",
      "            MobileBertForMultipleChoice,\n",
      "            MobileBertForNextSentencePrediction,\n",
      "            MobileBertForPreTraining,\n",
      "            MobileBertForQuestionAnswering,\n",
      "            MobileBertForSequenceClassification,\n",
      "            MobileBertForTokenClassification,\n",
      "            MobileBertModel,\n",
      "            MobileBertPreTrainedModel,\n",
      "            load_tf_weights_in_mobilebert,\n",
      "        )\n",
      "        from .models.mobilenet_v1 import (\n",
      "            MobileNetV1ForImageClassification,\n",
      "            MobileNetV1Model,\n",
      "            MobileNetV1PreTrainedModel,\n",
      "            load_tf_weights_in_mobilenet_v1,\n",
      "        )\n",
      "        from .models.mobilenet_v2 import (\n",
      "            MobileNetV2ForImageClassification,\n",
      "            MobileNetV2ForSemanticSegmentation,\n",
      "            MobileNetV2Model,\n",
      "            MobileNetV2PreTrainedModel,\n",
      "            load_tf_weights_in_mobilenet_v2,\n",
      "        )\n",
      "        from .models.mobilevit import (\n",
      "            MobileViTForImageClassification,\n",
      "            MobileViTForSemanticSegmentation,\n",
      "            MobileViTModel,\n",
      "            MobileViTPreTrainedModel,\n",
      "        )\n",
      "        from .models.mobilevitv2 import (\n",
      "            MobileViTV2ForImageClassification,\n",
      "            MobileViTV2ForSemanticSegmentation,\n",
      "            MobileViTV2Model,\n",
      "            MobileViTV2PreTrainedModel,\n",
      "        )\n",
      "        from .models.modernbert import (\n",
      "            ModernBertForMaskedLM,\n",
      "            ModernBertForQuestionAnswering,\n",
      "            ModernBertForSequenceClassification,\n",
      "            ModernBertForTokenClassification,\n",
      "            ModernBertModel,\n",
      "            ModernBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.moonshine import (\n",
      "            MoonshineForConditionalGeneration,\n",
      "            MoonshineModel,\n",
      "            MoonshinePreTrainedModel,\n",
      "        )\n",
      "        from .models.moshi import (\n",
      "            MoshiForCausalLM,\n",
      "            MoshiForConditionalGeneration,\n",
      "            MoshiModel,\n",
      "            MoshiPreTrainedModel,\n",
      "        )\n",
      "        from .models.mpnet import (\n",
      "            MPNetForMaskedLM,\n",
      "            MPNetForMultipleChoice,\n",
      "            MPNetForQuestionAnswering,\n",
      "            MPNetForSequenceClassification,\n",
      "            MPNetForTokenClassification,\n",
      "            MPNetModel,\n",
      "            MPNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.mpt import (\n",
      "            MptForCausalLM,\n",
      "            MptForQuestionAnswering,\n",
      "            MptForSequenceClassification,\n",
      "            MptForTokenClassification,\n",
      "            MptModel,\n",
      "            MptPreTrainedModel,\n",
      "        )\n",
      "        from .models.mra import (\n",
      "            MraForMaskedLM,\n",
      "            MraForMultipleChoice,\n",
      "            MraForQuestionAnswering,\n",
      "            MraForSequenceClassification,\n",
      "            MraForTokenClassification,\n",
      "            MraModel,\n",
      "            MraPreTrainedModel,\n",
      "        )\n",
      "        from .models.mt5 import (\n",
      "            MT5EncoderModel,\n",
      "            MT5ForConditionalGeneration,\n",
      "            MT5ForQuestionAnswering,\n",
      "            MT5ForSequenceClassification,\n",
      "            MT5ForTokenClassification,\n",
      "            MT5Model,\n",
      "            MT5PreTrainedModel,\n",
      "        )\n",
      "        from .models.musicgen import (\n",
      "            MusicgenForCausalLM,\n",
      "            MusicgenForConditionalGeneration,\n",
      "            MusicgenModel,\n",
      "            MusicgenPreTrainedModel,\n",
      "            MusicgenProcessor,\n",
      "        )\n",
      "        from .models.musicgen_melody import (\n",
      "            MusicgenMelodyForCausalLM,\n",
      "            MusicgenMelodyForConditionalGeneration,\n",
      "            MusicgenMelodyModel,\n",
      "            MusicgenMelodyPreTrainedModel,\n",
      "        )\n",
      "        from .models.mvp import (\n",
      "            MvpForCausalLM,\n",
      "            MvpForConditionalGeneration,\n",
      "            MvpForQuestionAnswering,\n",
      "            MvpForSequenceClassification,\n",
      "            MvpModel,\n",
      "            MvpPreTrainedModel,\n",
      "        )\n",
      "        from .models.nemotron import (\n",
      "            NemotronForCausalLM,\n",
      "            NemotronForQuestionAnswering,\n",
      "            NemotronForSequenceClassification,\n",
      "            NemotronForTokenClassification,\n",
      "            NemotronModel,\n",
      "            NemotronPreTrainedModel,\n",
      "        )\n",
      "        from .models.nllb_moe import (\n",
      "            NllbMoeForConditionalGeneration,\n",
      "            NllbMoeModel,\n",
      "            NllbMoePreTrainedModel,\n",
      "            NllbMoeSparseMLP,\n",
      "            NllbMoeTop2Router,\n",
      "        )\n",
      "        from .models.nystromformer import (\n",
      "            NystromformerForMaskedLM,\n",
      "            NystromformerForMultipleChoice,\n",
      "            NystromformerForQuestionAnswering,\n",
      "            NystromformerForSequenceClassification,\n",
      "            NystromformerForTokenClassification,\n",
      "            NystromformerModel,\n",
      "            NystromformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.olmo import (\n",
      "            OlmoForCausalLM,\n",
      "            OlmoModel,\n",
      "            OlmoPreTrainedModel,\n",
      "        )\n",
      "        from .models.olmo2 import (\n",
      "            Olmo2ForCausalLM,\n",
      "            Olmo2Model,\n",
      "            Olmo2PreTrainedModel,\n",
      "        )\n",
      "        from .models.olmoe import (\n",
      "            OlmoeForCausalLM,\n",
      "            OlmoeModel,\n",
      "            OlmoePreTrainedModel,\n",
      "        )\n",
      "        from .models.omdet_turbo import (\n",
      "            OmDetTurboForObjectDetection,\n",
      "            OmDetTurboPreTrainedModel,\n",
      "        )\n",
      "        from .models.oneformer import (\n",
      "            OneFormerForUniversalSegmentation,\n",
      "            OneFormerModel,\n",
      "            OneFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.openai import (\n",
      "            OpenAIGPTDoubleHeadsModel,\n",
      "            OpenAIGPTForSequenceClassification,\n",
      "            OpenAIGPTLMHeadModel,\n",
      "            OpenAIGPTModel,\n",
      "            OpenAIGPTPreTrainedModel,\n",
      "            load_tf_weights_in_openai_gpt,\n",
      "        )\n",
      "        from .models.opt import (\n",
      "            OPTForCausalLM,\n",
      "            OPTForQuestionAnswering,\n",
      "            OPTForSequenceClassification,\n",
      "            OPTModel,\n",
      "            OPTPreTrainedModel,\n",
      "        )\n",
      "        from .models.owlv2 import (\n",
      "            Owlv2ForObjectDetection,\n",
      "            Owlv2Model,\n",
      "            Owlv2PreTrainedModel,\n",
      "            Owlv2TextModel,\n",
      "            Owlv2VisionModel,\n",
      "        )\n",
      "        from .models.owlvit import (\n",
      "            OwlViTForObjectDetection,\n",
      "            OwlViTModel,\n",
      "            OwlViTPreTrainedModel,\n",
      "            OwlViTTextModel,\n",
      "            OwlViTVisionModel,\n",
      "        )\n",
      "        from .models.paligemma import (\n",
      "            PaliGemmaForConditionalGeneration,\n",
      "            PaliGemmaPreTrainedModel,\n",
      "            PaliGemmaProcessor,\n",
      "        )\n",
      "        from .models.patchtsmixer import (\n",
      "            PatchTSMixerForPrediction,\n",
      "            PatchTSMixerForPretraining,\n",
      "            PatchTSMixerForRegression,\n",
      "            PatchTSMixerForTimeSeriesClassification,\n",
      "            PatchTSMixerModel,\n",
      "            PatchTSMixerPreTrainedModel,\n",
      "        )\n",
      "        from .models.patchtst import (\n",
      "            PatchTSTForClassification,\n",
      "            PatchTSTForPrediction,\n",
      "            PatchTSTForPretraining,\n",
      "            PatchTSTForRegression,\n",
      "            PatchTSTModel,\n",
      "            PatchTSTPreTrainedModel,\n",
      "        )\n",
      "        from .models.pegasus import (\n",
      "            PegasusForCausalLM,\n",
      "            PegasusForConditionalGeneration,\n",
      "            PegasusModel,\n",
      "            PegasusPreTrainedModel,\n",
      "        )\n",
      "        from .models.pegasus_x import (\n",
      "            PegasusXForConditionalGeneration,\n",
      "            PegasusXModel,\n",
      "            PegasusXPreTrainedModel,\n",
      "        )\n",
      "        from .models.perceiver import (\n",
      "            PerceiverForImageClassificationConvProcessing,\n",
      "            PerceiverForImageClassificationFourier,\n",
      "            PerceiverForImageClassificationLearned,\n",
      "            PerceiverForMaskedLM,\n",
      "            PerceiverForMultimodalAutoencoding,\n",
      "            PerceiverForOpticalFlow,\n",
      "            PerceiverForSequenceClassification,\n",
      "            PerceiverModel,\n",
      "            PerceiverPreTrainedModel,\n",
      "        )\n",
      "        from .models.persimmon import (\n",
      "            PersimmonForCausalLM,\n",
      "            PersimmonForSequenceClassification,\n",
      "            PersimmonForTokenClassification,\n",
      "            PersimmonModel,\n",
      "            PersimmonPreTrainedModel,\n",
      "        )\n",
      "        from .models.phi import (\n",
      "            PhiForCausalLM,\n",
      "            PhiForSequenceClassification,\n",
      "            PhiForTokenClassification,\n",
      "            PhiModel,\n",
      "            PhiPreTrainedModel,\n",
      "        )\n",
      "        from .models.phi3 import (\n",
      "            Phi3ForCausalLM,\n",
      "            Phi3ForSequenceClassification,\n",
      "            Phi3ForTokenClassification,\n",
      "            Phi3Model,\n",
      "            Phi3PreTrainedModel,\n",
      "        )\n",
      "        from .models.phi4_multimodal import (\n",
      "            Phi4MultimodalAudioModel,\n",
      "            Phi4MultimodalAudioPreTrainedModel,\n",
      "            Phi4MultimodalForCausalLM,\n",
      "            Phi4MultimodalModel,\n",
      "            Phi4MultimodalPreTrainedModel,\n",
      "            Phi4MultimodalVisionModel,\n",
      "            Phi4MultimodalVisionPreTrainedModel,\n",
      "        )\n",
      "        from .models.phimoe import (\n",
      "            PhimoeForCausalLM,\n",
      "            PhimoeForSequenceClassification,\n",
      "            PhimoeModel,\n",
      "            PhimoePreTrainedModel,\n",
      "        )\n",
      "        from .models.pix2struct import (\n",
      "            Pix2StructForConditionalGeneration,\n",
      "            Pix2StructPreTrainedModel,\n",
      "            Pix2StructTextModel,\n",
      "            Pix2StructVisionModel,\n",
      "        )\n",
      "        from .models.pixtral import (\n",
      "            PixtralPreTrainedModel,\n",
      "            PixtralVisionModel,\n",
      "        )\n",
      "        from .models.plbart import (\n",
      "            PLBartForCausalLM,\n",
      "            PLBartForConditionalGeneration,\n",
      "            PLBartForSequenceClassification,\n",
      "            PLBartModel,\n",
      "            PLBartPreTrainedModel,\n",
      "        )\n",
      "        from .models.poolformer import (\n",
      "            PoolFormerForImageClassification,\n",
      "            PoolFormerModel,\n",
      "            PoolFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.pop2piano import (\n",
      "            Pop2PianoForConditionalGeneration,\n",
      "            Pop2PianoPreTrainedModel,\n",
      "        )\n",
      "        from .models.prompt_depth_anything import (\n",
      "            PromptDepthAnythingForDepthEstimation,\n",
      "            PromptDepthAnythingPreTrainedModel,\n",
      "        )\n",
      "        from .models.prophetnet import (\n",
      "            ProphetNetDecoder,\n",
      "            ProphetNetEncoder,\n",
      "            ProphetNetForCausalLM,\n",
      "            ProphetNetForConditionalGeneration,\n",
      "            ProphetNetModel,\n",
      "            ProphetNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.pvt import (\n",
      "            PvtForImageClassification,\n",
      "            PvtModel,\n",
      "            PvtPreTrainedModel,\n",
      "        )\n",
      "        from .models.pvt_v2 import (\n",
      "            PvtV2Backbone,\n",
      "            PvtV2ForImageClassification,\n",
      "            PvtV2Model,\n",
      "            PvtV2PreTrainedModel,\n",
      "        )\n",
      "        from .models.qwen2 import (\n",
      "            Qwen2ForCausalLM,\n",
      "            Qwen2ForQuestionAnswering,\n",
      "            Qwen2ForSequenceClassification,\n",
      "            Qwen2ForTokenClassification,\n",
      "            Qwen2Model,\n",
      "            Qwen2PreTrainedModel,\n",
      "        )\n",
      "        from .models.qwen2_5_vl import (\n",
      "            Qwen2_5_VLForConditionalGeneration,\n",
      "            Qwen2_5_VLModel,\n",
      "            Qwen2_5_VLPreTrainedModel,\n",
      "        )\n",
      "        from .models.qwen2_audio import (\n",
      "            Qwen2AudioEncoder,\n",
      "            Qwen2AudioForConditionalGeneration,\n",
      "            Qwen2AudioPreTrainedModel,\n",
      "        )\n",
      "        from .models.qwen2_moe import (\n",
      "            Qwen2MoeForCausalLM,\n",
      "            Qwen2MoeForQuestionAnswering,\n",
      "            Qwen2MoeForSequenceClassification,\n",
      "            Qwen2MoeForTokenClassification,\n",
      "            Qwen2MoeModel,\n",
      "            Qwen2MoePreTrainedModel,\n",
      "        )\n",
      "        from .models.qwen2_vl import (\n",
      "            Qwen2VLForConditionalGeneration,\n",
      "            Qwen2VLModel,\n",
      "            Qwen2VLPreTrainedModel,\n",
      "        )\n",
      "        from .models.qwen3 import (\n",
      "            Qwen3ForCausalLM,\n",
      "            Qwen3ForQuestionAnswering,\n",
      "            Qwen3ForSequenceClassification,\n",
      "            Qwen3ForTokenClassification,\n",
      "            Qwen3Model,\n",
      "            Qwen3PreTrainedModel,\n",
      "        )\n",
      "        from .models.qwen3_moe import (\n",
      "            Qwen3MoeForCausalLM,\n",
      "            Qwen3MoeForQuestionAnswering,\n",
      "            Qwen3MoeForSequenceClassification,\n",
      "            Qwen3MoeForTokenClassification,\n",
      "            Qwen3MoeModel,\n",
      "            Qwen3MoePreTrainedModel,\n",
      "        )\n",
      "        from .models.rag import (\n",
      "            RagModel,\n",
      "            RagPreTrainedModel,\n",
      "            RagSequenceForGeneration,\n",
      "            RagTokenForGeneration,\n",
      "        )\n",
      "        from .models.recurrent_gemma import (\n",
      "            RecurrentGemmaForCausalLM,\n",
      "            RecurrentGemmaModel,\n",
      "            RecurrentGemmaPreTrainedModel,\n",
      "        )\n",
      "        from .models.reformer import (\n",
      "            ReformerForMaskedLM,\n",
      "            ReformerForQuestionAnswering,\n",
      "            ReformerForSequenceClassification,\n",
      "            ReformerModel,\n",
      "            ReformerModelWithLMHead,\n",
      "            ReformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.regnet import (\n",
      "            RegNetForImageClassification,\n",
      "            RegNetModel,\n",
      "            RegNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.rembert import (\n",
      "            RemBertForCausalLM,\n",
      "            RemBertForMaskedLM,\n",
      "            RemBertForMultipleChoice,\n",
      "            RemBertForQuestionAnswering,\n",
      "            RemBertForSequenceClassification,\n",
      "            RemBertForTokenClassification,\n",
      "            RemBertModel,\n",
      "            RemBertPreTrainedModel,\n",
      "            load_tf_weights_in_rembert,\n",
      "        )\n",
      "        from .models.resnet import (\n",
      "            ResNetBackbone,\n",
      "            ResNetForImageClassification,\n",
      "            ResNetModel,\n",
      "            ResNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.roberta import (\n",
      "            RobertaForCausalLM,\n",
      "            RobertaForMaskedLM,\n",
      "            RobertaForMultipleChoice,\n",
      "            RobertaForQuestionAnswering,\n",
      "            RobertaForSequenceClassification,\n",
      "            RobertaForTokenClassification,\n",
      "            RobertaModel,\n",
      "            RobertaPreTrainedModel,\n",
      "        )\n",
      "        from .models.roberta_prelayernorm import (\n",
      "            RobertaPreLayerNormForCausalLM,\n",
      "            RobertaPreLayerNormForMaskedLM,\n",
      "            RobertaPreLayerNormForMultipleChoice,\n",
      "            RobertaPreLayerNormForQuestionAnswering,\n",
      "            RobertaPreLayerNormForSequenceClassification,\n",
      "            RobertaPreLayerNormForTokenClassification,\n",
      "            RobertaPreLayerNormModel,\n",
      "            RobertaPreLayerNormPreTrainedModel,\n",
      "        )\n",
      "        from .models.roc_bert import (\n",
      "            RoCBertForCausalLM,\n",
      "            RoCBertForMaskedLM,\n",
      "            RoCBertForMultipleChoice,\n",
      "            RoCBertForPreTraining,\n",
      "            RoCBertForQuestionAnswering,\n",
      "            RoCBertForSequenceClassification,\n",
      "            RoCBertForTokenClassification,\n",
      "            RoCBertModel,\n",
      "            RoCBertPreTrainedModel,\n",
      "            load_tf_weights_in_roc_bert,\n",
      "        )\n",
      "        from .models.roformer import (\n",
      "            RoFormerForCausalLM,\n",
      "            RoFormerForMaskedLM,\n",
      "            RoFormerForMultipleChoice,\n",
      "            RoFormerForQuestionAnswering,\n",
      "            RoFormerForSequenceClassification,\n",
      "            RoFormerForTokenClassification,\n",
      "            RoFormerModel,\n",
      "            RoFormerPreTrainedModel,\n",
      "            load_tf_weights_in_roformer,\n",
      "        )\n",
      "        from .models.rt_detr import (\n",
      "            RTDetrForObjectDetection,\n",
      "            RTDetrModel,\n",
      "            RTDetrPreTrainedModel,\n",
      "            RTDetrResNetBackbone,\n",
      "            RTDetrResNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.rt_detr_v2 import RTDetrV2ForObjectDetection, RTDetrV2Model, RTDetrV2PreTrainedModel\n",
      "        from .models.rwkv import (\n",
      "            RwkvForCausalLM,\n",
      "            RwkvModel,\n",
      "            RwkvPreTrainedModel,\n",
      "        )\n",
      "        from .models.sam import (\n",
      "            SamModel,\n",
      "            SamPreTrainedModel,\n",
      "            SamVisionModel,\n",
      "        )\n",
      "        from .models.seamless_m4t import (\n",
      "            SeamlessM4TCodeHifiGan,\n",
      "            SeamlessM4TForSpeechToSpeech,\n",
      "            SeamlessM4TForSpeechToText,\n",
      "            SeamlessM4TForTextToSpeech,\n",
      "            SeamlessM4TForTextToText,\n",
      "            SeamlessM4THifiGan,\n",
      "            SeamlessM4TModel,\n",
      "            SeamlessM4TPreTrainedModel,\n",
      "            SeamlessM4TTextToUnitForConditionalGeneration,\n",
      "            SeamlessM4TTextToUnitModel,\n",
      "        )\n",
      "        from .models.seamless_m4t_v2 import (\n",
      "            SeamlessM4Tv2ForSpeechToSpeech,\n",
      "            SeamlessM4Tv2ForSpeechToText,\n",
      "            SeamlessM4Tv2ForTextToSpeech,\n",
      "            SeamlessM4Tv2ForTextToText,\n",
      "            SeamlessM4Tv2Model,\n",
      "            SeamlessM4Tv2PreTrainedModel,\n",
      "        )\n",
      "        from .models.segformer import (\n",
      "            SegformerDecodeHead,\n",
      "            SegformerForImageClassification,\n",
      "            SegformerForSemanticSegmentation,\n",
      "            SegformerModel,\n",
      "            SegformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.seggpt import (\n",
      "            SegGptForImageSegmentation,\n",
      "            SegGptModel,\n",
      "            SegGptPreTrainedModel,\n",
      "        )\n",
      "        from .models.sew import (\n",
      "            SEWForCTC,\n",
      "            SEWForSequenceClassification,\n",
      "            SEWModel,\n",
      "            SEWPreTrainedModel,\n",
      "        )\n",
      "        from .models.sew_d import (\n",
      "            SEWDForCTC,\n",
      "            SEWDForSequenceClassification,\n",
      "            SEWDModel,\n",
      "            SEWDPreTrainedModel,\n",
      "        )\n",
      "        from .models.shieldgemma2 import (\n",
      "            ShieldGemma2ForImageClassification,\n",
      "        )\n",
      "        from .models.siglip import (\n",
      "            SiglipForImageClassification,\n",
      "            SiglipModel,\n",
      "            SiglipPreTrainedModel,\n",
      "            SiglipTextModel,\n",
      "            SiglipVisionModel,\n",
      "        )\n",
      "        from .models.siglip2 import (\n",
      "            Siglip2ForImageClassification,\n",
      "            Siglip2Model,\n",
      "            Siglip2PreTrainedModel,\n",
      "            Siglip2TextModel,\n",
      "            Siglip2VisionModel,\n",
      "        )\n",
      "        from .models.smolvlm import (\n",
      "            SmolVLMForConditionalGeneration,\n",
      "            SmolVLMModel,\n",
      "            SmolVLMPreTrainedModel,\n",
      "            SmolVLMProcessor,\n",
      "            SmolVLMVisionConfig,\n",
      "            SmolVLMVisionTransformer,\n",
      "        )\n",
      "        from .models.speech_encoder_decoder import SpeechEncoderDecoderModel\n",
      "        from .models.speech_to_text import (\n",
      "            Speech2TextForConditionalGeneration,\n",
      "            Speech2TextModel,\n",
      "            Speech2TextPreTrainedModel,\n",
      "        )\n",
      "        from .models.speecht5 import (\n",
      "            SpeechT5ForSpeechToSpeech,\n",
      "            SpeechT5ForSpeechToText,\n",
      "            SpeechT5ForTextToSpeech,\n",
      "            SpeechT5HifiGan,\n",
      "            SpeechT5Model,\n",
      "            SpeechT5PreTrainedModel,\n",
      "        )\n",
      "        from .models.splinter import (\n",
      "            SplinterForPreTraining,\n",
      "            SplinterForQuestionAnswering,\n",
      "            SplinterModel,\n",
      "            SplinterPreTrainedModel,\n",
      "        )\n",
      "        from .models.squeezebert import (\n",
      "            SqueezeBertForMaskedLM,\n",
      "            SqueezeBertForMultipleChoice,\n",
      "            SqueezeBertForQuestionAnswering,\n",
      "            SqueezeBertForSequenceClassification,\n",
      "            SqueezeBertForTokenClassification,\n",
      "            SqueezeBertModel,\n",
      "            SqueezeBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.stablelm import (\n",
      "            StableLmForCausalLM,\n",
      "            StableLmForSequenceClassification,\n",
      "            StableLmForTokenClassification,\n",
      "            StableLmModel,\n",
      "            StableLmPreTrainedModel,\n",
      "        )\n",
      "        from .models.starcoder2 import (\n",
      "            Starcoder2ForCausalLM,\n",
      "            Starcoder2ForSequenceClassification,\n",
      "            Starcoder2ForTokenClassification,\n",
      "            Starcoder2Model,\n",
      "            Starcoder2PreTrainedModel,\n",
      "        )\n",
      "        from .models.superglue import (\n",
      "            SuperGlueForKeypointMatching,\n",
      "            SuperGluePreTrainedModel,\n",
      "        )\n",
      "        from .models.superpoint import (\n",
      "            SuperPointForKeypointDetection,\n",
      "            SuperPointPreTrainedModel,\n",
      "        )\n",
      "        from .models.swiftformer import (\n",
      "            SwiftFormerForImageClassification,\n",
      "            SwiftFormerModel,\n",
      "            SwiftFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.swin import (\n",
      "            SwinBackbone,\n",
      "            SwinForImageClassification,\n",
      "            SwinForMaskedImageModeling,\n",
      "            SwinModel,\n",
      "            SwinPreTrainedModel,\n",
      "        )\n",
      "        from .models.swin2sr import (\n",
      "            Swin2SRForImageSuperResolution,\n",
      "            Swin2SRModel,\n",
      "            Swin2SRPreTrainedModel,\n",
      "        )\n",
      "        from .models.swinv2 import (\n",
      "            Swinv2Backbone,\n",
      "            Swinv2ForImageClassification,\n",
      "            Swinv2ForMaskedImageModeling,\n",
      "            Swinv2Model,\n",
      "            Swinv2PreTrainedModel,\n",
      "        )\n",
      "        from .models.switch_transformers import (\n",
      "            SwitchTransformersEncoderModel,\n",
      "            SwitchTransformersForConditionalGeneration,\n",
      "            SwitchTransformersModel,\n",
      "            SwitchTransformersPreTrainedModel,\n",
      "            SwitchTransformersSparseMLP,\n",
      "            SwitchTransformersTop1Router,\n",
      "        )\n",
      "        from .models.t5 import (\n",
      "            T5EncoderModel,\n",
      "            T5ForConditionalGeneration,\n",
      "            T5ForQuestionAnswering,\n",
      "            T5ForSequenceClassification,\n",
      "            T5ForTokenClassification,\n",
      "            T5Model,\n",
      "            T5PreTrainedModel,\n",
      "            load_tf_weights_in_t5,\n",
      "        )\n",
      "        from .models.table_transformer import (\n",
      "            TableTransformerForObjectDetection,\n",
      "            TableTransformerModel,\n",
      "            TableTransformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.tapas import (\n",
      "            TapasForMaskedLM,\n",
      "            TapasForQuestionAnswering,\n",
      "            TapasForSequenceClassification,\n",
      "            TapasModel,\n",
      "            TapasPreTrainedModel,\n",
      "            load_tf_weights_in_tapas,\n",
      "        )\n",
      "        from .models.textnet import (\n",
      "            TextNetBackbone,\n",
      "            TextNetForImageClassification,\n",
      "            TextNetModel,\n",
      "            TextNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.time_series_transformer import (\n",
      "            TimeSeriesTransformerForPrediction,\n",
      "            TimeSeriesTransformerModel,\n",
      "            TimeSeriesTransformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.timesformer import (\n",
      "            TimesformerForVideoClassification,\n",
      "            TimesformerModel,\n",
      "            TimesformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.timm_backbone import TimmBackbone\n",
      "        from .models.timm_wrapper import (\n",
      "            TimmWrapperForImageClassification,\n",
      "            TimmWrapperModel,\n",
      "            TimmWrapperPreTrainedModel,\n",
      "        )\n",
      "        from .models.trocr import (\n",
      "            TrOCRForCausalLM,\n",
      "            TrOCRPreTrainedModel,\n",
      "        )\n",
      "        from .models.tvp import (\n",
      "            TvpForVideoGrounding,\n",
      "            TvpModel,\n",
      "            TvpPreTrainedModel,\n",
      "        )\n",
      "        from .models.udop import (\n",
      "            UdopEncoderModel,\n",
      "            UdopForConditionalGeneration,\n",
      "            UdopModel,\n",
      "            UdopPreTrainedModel,\n",
      "        )\n",
      "        from .models.umt5 import (\n",
      "            UMT5EncoderModel,\n",
      "            UMT5ForConditionalGeneration,\n",
      "            UMT5ForQuestionAnswering,\n",
      "            UMT5ForSequenceClassification,\n",
      "            UMT5ForTokenClassification,\n",
      "            UMT5Model,\n",
      "            UMT5PreTrainedModel,\n",
      "        )\n",
      "        from .models.unispeech import (\n",
      "            UniSpeechForCTC,\n",
      "            UniSpeechForPreTraining,\n",
      "            UniSpeechForSequenceClassification,\n",
      "            UniSpeechModel,\n",
      "            UniSpeechPreTrainedModel,\n",
      "        )\n",
      "        from .models.unispeech_sat import (\n",
      "            UniSpeechSatForAudioFrameClassification,\n",
      "            UniSpeechSatForCTC,\n",
      "            UniSpeechSatForPreTraining,\n",
      "            UniSpeechSatForSequenceClassification,\n",
      "            UniSpeechSatForXVector,\n",
      "            UniSpeechSatModel,\n",
      "            UniSpeechSatPreTrainedModel,\n",
      "        )\n",
      "        from .models.univnet import UnivNetModel\n",
      "        from .models.upernet import (\n",
      "            UperNetForSemanticSegmentation,\n",
      "            UperNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.video_llava import (\n",
      "            VideoLlavaForConditionalGeneration,\n",
      "            VideoLlavaPreTrainedModel,\n",
      "            VideoLlavaProcessor,\n",
      "        )\n",
      "        from .models.videomae import (\n",
      "            VideoMAEForPreTraining,\n",
      "            VideoMAEForVideoClassification,\n",
      "            VideoMAEModel,\n",
      "            VideoMAEPreTrainedModel,\n",
      "        )\n",
      "        from .models.vilt import (\n",
      "            ViltForImageAndTextRetrieval,\n",
      "            ViltForImagesAndTextClassification,\n",
      "            ViltForMaskedLM,\n",
      "            ViltForQuestionAnswering,\n",
      "            ViltForTokenClassification,\n",
      "            ViltModel,\n",
      "            ViltPreTrainedModel,\n",
      "        )\n",
      "        from .models.vipllava import (\n",
      "            VipLlavaForConditionalGeneration,\n",
      "            VipLlavaPreTrainedModel,\n",
      "        )\n",
      "        from .models.vision_encoder_decoder import VisionEncoderDecoderModel\n",
      "        from .models.vision_text_dual_encoder import VisionTextDualEncoderModel\n",
      "        from .models.visual_bert import (\n",
      "            VisualBertForMultipleChoice,\n",
      "            VisualBertForPreTraining,\n",
      "            VisualBertForQuestionAnswering,\n",
      "            VisualBertForRegionToPhraseAlignment,\n",
      "            VisualBertForVisualReasoning,\n",
      "            VisualBertModel,\n",
      "            VisualBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.vit import (\n",
      "            ViTForImageClassification,\n",
      "            ViTForMaskedImageModeling,\n",
      "            ViTModel,\n",
      "            ViTPreTrainedModel,\n",
      "        )\n",
      "        from .models.vit_mae import (\n",
      "            ViTMAEForPreTraining,\n",
      "            ViTMAEModel,\n",
      "            ViTMAEPreTrainedModel,\n",
      "        )\n",
      "        from .models.vit_msn import (\n",
      "            ViTMSNForImageClassification,\n",
      "            ViTMSNModel,\n",
      "            ViTMSNPreTrainedModel,\n",
      "        )\n",
      "        from .models.vitdet import (\n",
      "            VitDetBackbone,\n",
      "            VitDetModel,\n",
      "            VitDetPreTrainedModel,\n",
      "        )\n",
      "        from .models.vitmatte import (\n",
      "            VitMatteForImageMatting,\n",
      "            VitMattePreTrainedModel,\n",
      "        )\n",
      "        from .models.vitpose import (\n",
      "            VitPoseForPoseEstimation,\n",
      "            VitPosePreTrainedModel,\n",
      "        )\n",
      "        from .models.vitpose_backbone import VitPoseBackbone, VitPoseBackbonePreTrainedModel\n",
      "        from .models.vits import (\n",
      "            VitsModel,\n",
      "            VitsPreTrainedModel,\n",
      "        )\n",
      "        from .models.vivit import (\n",
      "            VivitForVideoClassification,\n",
      "            VivitModel,\n",
      "            VivitPreTrainedModel,\n",
      "        )\n",
      "        from .models.wav2vec2 import (\n",
      "            Wav2Vec2ForAudioFrameClassification,\n",
      "            Wav2Vec2ForCTC,\n",
      "            Wav2Vec2ForMaskedLM,\n",
      "            Wav2Vec2ForPreTraining,\n",
      "            Wav2Vec2ForSequenceClassification,\n",
      "            Wav2Vec2ForXVector,\n",
      "            Wav2Vec2Model,\n",
      "            Wav2Vec2PreTrainedModel,\n",
      "        )\n",
      "        from .models.wav2vec2_bert import (\n",
      "            Wav2Vec2BertForAudioFrameClassification,\n",
      "            Wav2Vec2BertForCTC,\n",
      "            Wav2Vec2BertForSequenceClassification,\n",
      "            Wav2Vec2BertForXVector,\n",
      "            Wav2Vec2BertModel,\n",
      "            Wav2Vec2BertPreTrainedModel,\n",
      "        )\n",
      "        from .models.wav2vec2_conformer import (\n",
      "            Wav2Vec2ConformerForAudioFrameClassification,\n",
      "            Wav2Vec2ConformerForCTC,\n",
      "            Wav2Vec2ConformerForPreTraining,\n",
      "            Wav2Vec2ConformerForSequenceClassification,\n",
      "            Wav2Vec2ConformerForXVector,\n",
      "            Wav2Vec2ConformerModel,\n",
      "            Wav2Vec2ConformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.wavlm import (\n",
      "            WavLMForAudioFrameClassification,\n",
      "            WavLMForCTC,\n",
      "            WavLMForSequenceClassification,\n",
      "            WavLMForXVector,\n",
      "            WavLMModel,\n",
      "            WavLMPreTrainedModel,\n",
      "        )\n",
      "        from .models.whisper import (\n",
      "            WhisperForAudioClassification,\n",
      "            WhisperForCausalLM,\n",
      "            WhisperForConditionalGeneration,\n",
      "            WhisperModel,\n",
      "            WhisperPreTrainedModel,\n",
      "        )\n",
      "        from .models.x_clip import (\n",
      "            XCLIPModel,\n",
      "            XCLIPPreTrainedModel,\n",
      "            XCLIPTextModel,\n",
      "            XCLIPVisionModel,\n",
      "        )\n",
      "        from .models.xglm import (\n",
      "            XGLMForCausalLM,\n",
      "            XGLMModel,\n",
      "            XGLMPreTrainedModel,\n",
      "        )\n",
      "        from .models.xlm import (\n",
      "            XLMForMultipleChoice,\n",
      "            XLMForQuestionAnswering,\n",
      "            XLMForQuestionAnsweringSimple,\n",
      "            XLMForSequenceClassification,\n",
      "            XLMForTokenClassification,\n",
      "            XLMModel,\n",
      "            XLMPreTrainedModel,\n",
      "            XLMWithLMHeadModel,\n",
      "        )\n",
      "        from .models.xlm_roberta import (\n",
      "            XLMRobertaForCausalLM,\n",
      "            XLMRobertaForMaskedLM,\n",
      "            XLMRobertaForMultipleChoice,\n",
      "            XLMRobertaForQuestionAnswering,\n",
      "            XLMRobertaForSequenceClassification,\n",
      "            XLMRobertaForTokenClassification,\n",
      "            XLMRobertaModel,\n",
      "            XLMRobertaPreTrainedModel,\n",
      "        )\n",
      "        from .models.xlm_roberta_xl import (\n",
      "            XLMRobertaXLForCausalLM,\n",
      "            XLMRobertaXLForMaskedLM,\n",
      "            XLMRobertaXLForMultipleChoice,\n",
      "            XLMRobertaXLForQuestionAnswering,\n",
      "            XLMRobertaXLForSequenceClassification,\n",
      "            XLMRobertaXLForTokenClassification,\n",
      "            XLMRobertaXLModel,\n",
      "            XLMRobertaXLPreTrainedModel,\n",
      "        )\n",
      "        from .models.xlnet import (\n",
      "            XLNetForMultipleChoice,\n",
      "            XLNetForQuestionAnswering,\n",
      "            XLNetForQuestionAnsweringSimple,\n",
      "            XLNetForSequenceClassification,\n",
      "            XLNetForTokenClassification,\n",
      "            XLNetLMHeadModel,\n",
      "            XLNetModel,\n",
      "            XLNetPreTrainedModel,\n",
      "            load_tf_weights_in_xlnet,\n",
      "        )\n",
      "        from .models.xmod import (\n",
      "            XmodForCausalLM,\n",
      "            XmodForMaskedLM,\n",
      "            XmodForMultipleChoice,\n",
      "            XmodForQuestionAnswering,\n",
      "            XmodForSequenceClassification,\n",
      "            XmodForTokenClassification,\n",
      "            XmodModel,\n",
      "            XmodPreTrainedModel,\n",
      "        )\n",
      "        from .models.yolos import (\n",
      "            YolosForObjectDetection,\n",
      "            YolosModel,\n",
      "            YolosPreTrainedModel,\n",
      "        )\n",
      "        from .models.yoso import (\n",
      "            YosoForMaskedLM,\n",
      "            YosoForMultipleChoice,\n",
      "            YosoForQuestionAnswering,\n",
      "            YosoForSequenceClassification,\n",
      "            YosoForTokenClassification,\n",
      "            YosoModel,\n",
      "            YosoPreTrainedModel,\n",
      "        )\n",
      "        from .models.zamba import (\n",
      "            ZambaForCausalLM,\n",
      "            ZambaForSequenceClassification,\n",
      "            ZambaModel,\n",
      "            ZambaPreTrainedModel,\n",
      "        )\n",
      "        from .models.zamba2 import (\n",
      "            Zamba2ForCausalLM,\n",
      "            Zamba2ForSequenceClassification,\n",
      "            Zamba2Model,\n",
      "            Zamba2PreTrainedModel,\n",
      "        )\n",
      "        from .models.zoedepth import (\n",
      "            ZoeDepthForDepthEstimation,\n",
      "            ZoeDepthPreTrainedModel,\n",
      "        )\n",
      "\n",
      "        # Optimization\n",
      "        from .optimization import (\n",
      "            Adafactor,\n",
      "            get_constant_schedule,\n",
      "            get_constant_schedule_with_warmup,\n",
      "            get_cosine_schedule_with_warmup,\n",
      "            get_cosine_with_hard_restarts_schedule_with_warmup,\n",
      "            get_inverse_sqrt_schedule,\n",
      "            get_linear_schedule_with_warmup,\n",
      "            get_polynomial_decay_schedule_with_warmup,\n",
      "            get_scheduler,\n",
      "            get_wsd_schedule,\n",
      "        )\n",
      "        from .pytorch_utils import Conv1D, apply_chunking_to_forward, prune_layer\n",
      "\n",
      "        # Trainer\n",
      "        from .trainer import Trainer\n",
      "        from .trainer_pt_utils import torch_distributed_zero_first\n",
      "        from .trainer_seq2seq import Seq2SeqTrainer\n",
      "\n",
      "    # TensorFlow\n",
      "    try:\n",
      "        if not is_tf_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        # Import the same objects as dummies to get them in the namespace.\n",
      "        # They will raise an import error if the user tries to instantiate / use them.\n",
      "        from .utils.dummy_tf_objects import *\n",
      "    else:\n",
      "        from .generation import (\n",
      "            TFForcedBOSTokenLogitsProcessor,\n",
      "            TFForcedEOSTokenLogitsProcessor,\n",
      "            TFForceTokensLogitsProcessor,\n",
      "            TFGenerationMixin,\n",
      "            TFLogitsProcessor,\n",
      "            TFLogitsProcessorList,\n",
      "            TFLogitsWarper,\n",
      "            TFMinLengthLogitsProcessor,\n",
      "            TFNoBadWordsLogitsProcessor,\n",
      "            TFNoRepeatNGramLogitsProcessor,\n",
      "            TFRepetitionPenaltyLogitsProcessor,\n",
      "            TFSuppressTokensAtBeginLogitsProcessor,\n",
      "            TFSuppressTokensLogitsProcessor,\n",
      "            TFTemperatureLogitsWarper,\n",
      "            TFTopKLogitsWarper,\n",
      "            TFTopPLogitsWarper,\n",
      "        )\n",
      "        from .keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
      "        from .modeling_tf_utils import (\n",
      "            TFPreTrainedModel,\n",
      "            TFSequenceSummary,\n",
      "            TFSharedEmbeddings,\n",
      "            shape_list,\n",
      "        )\n",
      "\n",
      "        # TensorFlow model imports\n",
      "        from .models.albert import (\n",
      "            TFAlbertForMaskedLM,\n",
      "            TFAlbertForMultipleChoice,\n",
      "            TFAlbertForPreTraining,\n",
      "            TFAlbertForQuestionAnswering,\n",
      "            TFAlbertForSequenceClassification,\n",
      "            TFAlbertForTokenClassification,\n",
      "            TFAlbertMainLayer,\n",
      "            TFAlbertModel,\n",
      "            TFAlbertPreTrainedModel,\n",
      "        )\n",
      "        from .models.auto import (\n",
      "            TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING,\n",
      "            TF_MODEL_FOR_CAUSAL_LM_MAPPING,\n",
      "            TF_MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING,\n",
      "            TF_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
      "            TF_MODEL_FOR_MASK_GENERATION_MAPPING,\n",
      "            TF_MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING,\n",
      "            TF_MODEL_FOR_MASKED_LM_MAPPING,\n",
      "            TF_MODEL_FOR_MULTIPLE_CHOICE_MAPPING,\n",
      "            TF_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING,\n",
      "            TF_MODEL_FOR_PRETRAINING_MAPPING,\n",
      "            TF_MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
      "            TF_MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING,\n",
      "            TF_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING,\n",
      "            TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING,\n",
      "            TF_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING,\n",
      "            TF_MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING,\n",
      "            TF_MODEL_FOR_TEXT_ENCODING_MAPPING,\n",
      "            TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING,\n",
      "            TF_MODEL_FOR_VISION_2_SEQ_MAPPING,\n",
      "            TF_MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING,\n",
      "            TF_MODEL_MAPPING,\n",
      "            TF_MODEL_WITH_LM_HEAD_MAPPING,\n",
      "            TFAutoModel,\n",
      "            TFAutoModelForAudioClassification,\n",
      "            TFAutoModelForCausalLM,\n",
      "            TFAutoModelForDocumentQuestionAnswering,\n",
      "            TFAutoModelForImageClassification,\n",
      "            TFAutoModelForMaskedImageModeling,\n",
      "            TFAutoModelForMaskedLM,\n",
      "            TFAutoModelForMaskGeneration,\n",
      "            TFAutoModelForMultipleChoice,\n",
      "            TFAutoModelForNextSentencePrediction,\n",
      "            TFAutoModelForPreTraining,\n",
      "            TFAutoModelForQuestionAnswering,\n",
      "            TFAutoModelForSemanticSegmentation,\n",
      "            TFAutoModelForSeq2SeqLM,\n",
      "            TFAutoModelForSequenceClassification,\n",
      "            TFAutoModelForSpeechSeq2Seq,\n",
      "            TFAutoModelForTableQuestionAnswering,\n",
      "            TFAutoModelForTextEncoding,\n",
      "            TFAutoModelForTokenClassification,\n",
      "            TFAutoModelForVision2Seq,\n",
      "            TFAutoModelForZeroShotImageClassification,\n",
      "            TFAutoModelWithLMHead,\n",
      "        )\n",
      "        from .models.bart import (\n",
      "            TFBartForConditionalGeneration,\n",
      "            TFBartForSequenceClassification,\n",
      "            TFBartModel,\n",
      "            TFBartPretrainedModel,\n",
      "        )\n",
      "        from .models.bert import (\n",
      "            TFBertForMaskedLM,\n",
      "            TFBertForMultipleChoice,\n",
      "            TFBertForNextSentencePrediction,\n",
      "            TFBertForPreTraining,\n",
      "            TFBertForQuestionAnswering,\n",
      "            TFBertForSequenceClassification,\n",
      "            TFBertForTokenClassification,\n",
      "            TFBertLMHeadModel,\n",
      "            TFBertMainLayer,\n",
      "            TFBertModel,\n",
      "            TFBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.blenderbot import (\n",
      "            TFBlenderbotForConditionalGeneration,\n",
      "            TFBlenderbotModel,\n",
      "            TFBlenderbotPreTrainedModel,\n",
      "        )\n",
      "        from .models.blenderbot_small import (\n",
      "            TFBlenderbotSmallForConditionalGeneration,\n",
      "            TFBlenderbotSmallModel,\n",
      "            TFBlenderbotSmallPreTrainedModel,\n",
      "        )\n",
      "        from .models.blip import (\n",
      "            TFBlipForConditionalGeneration,\n",
      "            TFBlipForImageTextRetrieval,\n",
      "            TFBlipForQuestionAnswering,\n",
      "            TFBlipModel,\n",
      "            TFBlipPreTrainedModel,\n",
      "            TFBlipTextModel,\n",
      "            TFBlipVisionModel,\n",
      "        )\n",
      "        from .models.camembert import (\n",
      "            TFCamembertForCausalLM,\n",
      "            TFCamembertForMaskedLM,\n",
      "            TFCamembertForMultipleChoice,\n",
      "            TFCamembertForQuestionAnswering,\n",
      "            TFCamembertForSequenceClassification,\n",
      "            TFCamembertForTokenClassification,\n",
      "            TFCamembertModel,\n",
      "            TFCamembertPreTrainedModel,\n",
      "        )\n",
      "        from .models.clip import (\n",
      "            TFCLIPModel,\n",
      "            TFCLIPPreTrainedModel,\n",
      "            TFCLIPTextModel,\n",
      "            TFCLIPVisionModel,\n",
      "        )\n",
      "        from .models.convbert import (\n",
      "            TFConvBertForMaskedLM,\n",
      "            TFConvBertForMultipleChoice,\n",
      "            TFConvBertForQuestionAnswering,\n",
      "            TFConvBertForSequenceClassification,\n",
      "            TFConvBertForTokenClassification,\n",
      "            TFConvBertModel,\n",
      "            TFConvBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.convnext import (\n",
      "            TFConvNextForImageClassification,\n",
      "            TFConvNextModel,\n",
      "            TFConvNextPreTrainedModel,\n",
      "        )\n",
      "        from .models.convnextv2 import (\n",
      "            TFConvNextV2ForImageClassification,\n",
      "            TFConvNextV2Model,\n",
      "            TFConvNextV2PreTrainedModel,\n",
      "        )\n",
      "        from .models.ctrl import (\n",
      "            TFCTRLForSequenceClassification,\n",
      "            TFCTRLLMHeadModel,\n",
      "            TFCTRLModel,\n",
      "            TFCTRLPreTrainedModel,\n",
      "        )\n",
      "        from .models.cvt import (\n",
      "            TFCvtForImageClassification,\n",
      "            TFCvtModel,\n",
      "            TFCvtPreTrainedModel,\n",
      "        )\n",
      "        from .models.data2vec import (\n",
      "            TFData2VecVisionForImageClassification,\n",
      "            TFData2VecVisionForSemanticSegmentation,\n",
      "            TFData2VecVisionModel,\n",
      "            TFData2VecVisionPreTrainedModel,\n",
      "        )\n",
      "        from .models.deberta import (\n",
      "            TFDebertaForMaskedLM,\n",
      "            TFDebertaForQuestionAnswering,\n",
      "            TFDebertaForSequenceClassification,\n",
      "            TFDebertaForTokenClassification,\n",
      "            TFDebertaModel,\n",
      "            TFDebertaPreTrainedModel,\n",
      "        )\n",
      "        from .models.deberta_v2 import (\n",
      "            TFDebertaV2ForMaskedLM,\n",
      "            TFDebertaV2ForMultipleChoice,\n",
      "            TFDebertaV2ForQuestionAnswering,\n",
      "            TFDebertaV2ForSequenceClassification,\n",
      "            TFDebertaV2ForTokenClassification,\n",
      "            TFDebertaV2Model,\n",
      "            TFDebertaV2PreTrainedModel,\n",
      "        )\n",
      "        from .models.deit import (\n",
      "            TFDeiTForImageClassification,\n",
      "            TFDeiTForImageClassificationWithTeacher,\n",
      "            TFDeiTForMaskedImageModeling,\n",
      "            TFDeiTModel,\n",
      "            TFDeiTPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.efficientformer import (\n",
      "            TFEfficientFormerForImageClassification,\n",
      "            TFEfficientFormerForImageClassificationWithTeacher,\n",
      "            TFEfficientFormerModel,\n",
      "            TFEfficientFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.deprecated.transfo_xl import (\n",
      "            TFAdaptiveEmbedding,\n",
      "            TFTransfoXLForSequenceClassification,\n",
      "            TFTransfoXLLMHeadModel,\n",
      "            TFTransfoXLMainLayer,\n",
      "            TFTransfoXLModel,\n",
      "            TFTransfoXLPreTrainedModel,\n",
      "        )\n",
      "        from .models.distilbert import (\n",
      "            TFDistilBertForMaskedLM,\n",
      "            TFDistilBertForMultipleChoice,\n",
      "            TFDistilBertForQuestionAnswering,\n",
      "            TFDistilBertForSequenceClassification,\n",
      "            TFDistilBertForTokenClassification,\n",
      "            TFDistilBertMainLayer,\n",
      "            TFDistilBertModel,\n",
      "            TFDistilBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.dpr import (\n",
      "            TFDPRContextEncoder,\n",
      "            TFDPRPretrainedContextEncoder,\n",
      "            TFDPRPretrainedQuestionEncoder,\n",
      "            TFDPRPretrainedReader,\n",
      "            TFDPRQuestionEncoder,\n",
      "            TFDPRReader,\n",
      "        )\n",
      "        from .models.electra import (\n",
      "            TFElectraForMaskedLM,\n",
      "            TFElectraForMultipleChoice,\n",
      "            TFElectraForPreTraining,\n",
      "            TFElectraForQuestionAnswering,\n",
      "            TFElectraForSequenceClassification,\n",
      "            TFElectraForTokenClassification,\n",
      "            TFElectraModel,\n",
      "            TFElectraPreTrainedModel,\n",
      "        )\n",
      "        from .models.encoder_decoder import TFEncoderDecoderModel\n",
      "        from .models.esm import (\n",
      "            TFEsmForMaskedLM,\n",
      "            TFEsmForSequenceClassification,\n",
      "            TFEsmForTokenClassification,\n",
      "            TFEsmModel,\n",
      "            TFEsmPreTrainedModel,\n",
      "        )\n",
      "        from .models.flaubert import (\n",
      "            TFFlaubertForMultipleChoice,\n",
      "            TFFlaubertForQuestionAnsweringSimple,\n",
      "            TFFlaubertForSequenceClassification,\n",
      "            TFFlaubertForTokenClassification,\n",
      "            TFFlaubertModel,\n",
      "            TFFlaubertPreTrainedModel,\n",
      "            TFFlaubertWithLMHeadModel,\n",
      "        )\n",
      "        from .models.funnel import (\n",
      "            TFFunnelBaseModel,\n",
      "            TFFunnelForMaskedLM,\n",
      "            TFFunnelForMultipleChoice,\n",
      "            TFFunnelForPreTraining,\n",
      "            TFFunnelForQuestionAnswering,\n",
      "            TFFunnelForSequenceClassification,\n",
      "            TFFunnelForTokenClassification,\n",
      "            TFFunnelModel,\n",
      "            TFFunnelPreTrainedModel,\n",
      "        )\n",
      "        from .models.gpt2 import (\n",
      "            TFGPT2DoubleHeadsModel,\n",
      "            TFGPT2ForSequenceClassification,\n",
      "            TFGPT2LMHeadModel,\n",
      "            TFGPT2MainLayer,\n",
      "            TFGPT2Model,\n",
      "            TFGPT2PreTrainedModel,\n",
      "        )\n",
      "        from .models.gptj import (\n",
      "            TFGPTJForCausalLM,\n",
      "            TFGPTJForQuestionAnswering,\n",
      "            TFGPTJForSequenceClassification,\n",
      "            TFGPTJModel,\n",
      "            TFGPTJPreTrainedModel,\n",
      "        )\n",
      "        from .models.groupvit import (\n",
      "            TFGroupViTModel,\n",
      "            TFGroupViTPreTrainedModel,\n",
      "            TFGroupViTTextModel,\n",
      "            TFGroupViTVisionModel,\n",
      "        )\n",
      "        from .models.hubert import (\n",
      "            TFHubertForCTC,\n",
      "            TFHubertModel,\n",
      "            TFHubertPreTrainedModel,\n",
      "        )\n",
      "        from .models.idefics import (\n",
      "            TFIdeficsForVisionText2Text,\n",
      "            TFIdeficsModel,\n",
      "            TFIdeficsPreTrainedModel,\n",
      "        )\n",
      "        from .models.layoutlm import (\n",
      "            TFLayoutLMForMaskedLM,\n",
      "            TFLayoutLMForQuestionAnswering,\n",
      "            TFLayoutLMForSequenceClassification,\n",
      "            TFLayoutLMForTokenClassification,\n",
      "            TFLayoutLMMainLayer,\n",
      "            TFLayoutLMModel,\n",
      "            TFLayoutLMPreTrainedModel,\n",
      "        )\n",
      "        from .models.layoutlmv3 import (\n",
      "            TFLayoutLMv3ForQuestionAnswering,\n",
      "            TFLayoutLMv3ForSequenceClassification,\n",
      "            TFLayoutLMv3ForTokenClassification,\n",
      "            TFLayoutLMv3Model,\n",
      "            TFLayoutLMv3PreTrainedModel,\n",
      "        )\n",
      "        from .models.led import (\n",
      "            TFLEDForConditionalGeneration,\n",
      "            TFLEDModel,\n",
      "            TFLEDPreTrainedModel,\n",
      "        )\n",
      "        from .models.longformer import (\n",
      "            TFLongformerForMaskedLM,\n",
      "            TFLongformerForMultipleChoice,\n",
      "            TFLongformerForQuestionAnswering,\n",
      "            TFLongformerForSequenceClassification,\n",
      "            TFLongformerForTokenClassification,\n",
      "            TFLongformerModel,\n",
      "            TFLongformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.lxmert import (\n",
      "            TFLxmertForPreTraining,\n",
      "            TFLxmertMainLayer,\n",
      "            TFLxmertModel,\n",
      "            TFLxmertPreTrainedModel,\n",
      "            TFLxmertVisualFeatureEncoder,\n",
      "        )\n",
      "        from .models.marian import (\n",
      "            TFMarianModel,\n",
      "            TFMarianMTModel,\n",
      "            TFMarianPreTrainedModel,\n",
      "        )\n",
      "        from .models.mbart import (\n",
      "            TFMBartForConditionalGeneration,\n",
      "            TFMBartModel,\n",
      "            TFMBartPreTrainedModel,\n",
      "        )\n",
      "        from .models.mistral import (\n",
      "            TFMistralForCausalLM,\n",
      "            TFMistralForSequenceClassification,\n",
      "            TFMistralModel,\n",
      "            TFMistralPreTrainedModel,\n",
      "        )\n",
      "        from .models.mobilebert import (\n",
      "            TFMobileBertForMaskedLM,\n",
      "            TFMobileBertForMultipleChoice,\n",
      "            TFMobileBertForNextSentencePrediction,\n",
      "            TFMobileBertForPreTraining,\n",
      "            TFMobileBertForQuestionAnswering,\n",
      "            TFMobileBertForSequenceClassification,\n",
      "            TFMobileBertForTokenClassification,\n",
      "            TFMobileBertMainLayer,\n",
      "            TFMobileBertModel,\n",
      "            TFMobileBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.mobilevit import (\n",
      "            TFMobileViTForImageClassification,\n",
      "            TFMobileViTForSemanticSegmentation,\n",
      "            TFMobileViTModel,\n",
      "            TFMobileViTPreTrainedModel,\n",
      "        )\n",
      "        from .models.mpnet import (\n",
      "            TFMPNetForMaskedLM,\n",
      "            TFMPNetForMultipleChoice,\n",
      "            TFMPNetForQuestionAnswering,\n",
      "            TFMPNetForSequenceClassification,\n",
      "            TFMPNetForTokenClassification,\n",
      "            TFMPNetMainLayer,\n",
      "            TFMPNetModel,\n",
      "            TFMPNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.mt5 import (\n",
      "            TFMT5EncoderModel,\n",
      "            TFMT5ForConditionalGeneration,\n",
      "            TFMT5Model,\n",
      "        )\n",
      "        from .models.openai import (\n",
      "            TFOpenAIGPTDoubleHeadsModel,\n",
      "            TFOpenAIGPTForSequenceClassification,\n",
      "            TFOpenAIGPTLMHeadModel,\n",
      "            TFOpenAIGPTMainLayer,\n",
      "            TFOpenAIGPTModel,\n",
      "            TFOpenAIGPTPreTrainedModel,\n",
      "        )\n",
      "        from .models.opt import TFOPTForCausalLM, TFOPTModel, TFOPTPreTrainedModel\n",
      "        from .models.pegasus import (\n",
      "            TFPegasusForConditionalGeneration,\n",
      "            TFPegasusModel,\n",
      "            TFPegasusPreTrainedModel,\n",
      "        )\n",
      "        from .models.rag import (\n",
      "            TFRagModel,\n",
      "            TFRagPreTrainedModel,\n",
      "            TFRagSequenceForGeneration,\n",
      "            TFRagTokenForGeneration,\n",
      "        )\n",
      "        from .models.regnet import (\n",
      "            TFRegNetForImageClassification,\n",
      "            TFRegNetModel,\n",
      "            TFRegNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.rembert import (\n",
      "            TFRemBertForCausalLM,\n",
      "            TFRemBertForMaskedLM,\n",
      "            TFRemBertForMultipleChoice,\n",
      "            TFRemBertForQuestionAnswering,\n",
      "            TFRemBertForSequenceClassification,\n",
      "            TFRemBertForTokenClassification,\n",
      "            TFRemBertModel,\n",
      "            TFRemBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.resnet import (\n",
      "            TFResNetForImageClassification,\n",
      "            TFResNetModel,\n",
      "            TFResNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.roberta import (\n",
      "            TFRobertaForCausalLM,\n",
      "            TFRobertaForMaskedLM,\n",
      "            TFRobertaForMultipleChoice,\n",
      "            TFRobertaForQuestionAnswering,\n",
      "            TFRobertaForSequenceClassification,\n",
      "            TFRobertaForTokenClassification,\n",
      "            TFRobertaMainLayer,\n",
      "            TFRobertaModel,\n",
      "            TFRobertaPreTrainedModel,\n",
      "        )\n",
      "        from .models.roberta_prelayernorm import (\n",
      "            TFRobertaPreLayerNormForCausalLM,\n",
      "            TFRobertaPreLayerNormForMaskedLM,\n",
      "            TFRobertaPreLayerNormForMultipleChoice,\n",
      "            TFRobertaPreLayerNormForQuestionAnswering,\n",
      "            TFRobertaPreLayerNormForSequenceClassification,\n",
      "            TFRobertaPreLayerNormForTokenClassification,\n",
      "            TFRobertaPreLayerNormMainLayer,\n",
      "            TFRobertaPreLayerNormModel,\n",
      "            TFRobertaPreLayerNormPreTrainedModel,\n",
      "        )\n",
      "        from .models.roformer import (\n",
      "            TFRoFormerForCausalLM,\n",
      "            TFRoFormerForMaskedLM,\n",
      "            TFRoFormerForMultipleChoice,\n",
      "            TFRoFormerForQuestionAnswering,\n",
      "            TFRoFormerForSequenceClassification,\n",
      "            TFRoFormerForTokenClassification,\n",
      "            TFRoFormerModel,\n",
      "            TFRoFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.sam import (\n",
      "            TFSamModel,\n",
      "            TFSamPreTrainedModel,\n",
      "            TFSamVisionModel,\n",
      "        )\n",
      "        from .models.segformer import (\n",
      "            TFSegformerDecodeHead,\n",
      "            TFSegformerForImageClassification,\n",
      "            TFSegformerForSemanticSegmentation,\n",
      "            TFSegformerModel,\n",
      "            TFSegformerPreTrainedModel,\n",
      "        )\n",
      "        from .models.speech_to_text import (\n",
      "            TFSpeech2TextForConditionalGeneration,\n",
      "            TFSpeech2TextModel,\n",
      "            TFSpeech2TextPreTrainedModel,\n",
      "        )\n",
      "        from .models.swiftformer import (\n",
      "            TFSwiftFormerForImageClassification,\n",
      "            TFSwiftFormerModel,\n",
      "            TFSwiftFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.swin import (\n",
      "            TFSwinForImageClassification,\n",
      "            TFSwinForMaskedImageModeling,\n",
      "            TFSwinModel,\n",
      "            TFSwinPreTrainedModel,\n",
      "        )\n",
      "        from .models.t5 import (\n",
      "            TFT5EncoderModel,\n",
      "            TFT5ForConditionalGeneration,\n",
      "            TFT5Model,\n",
      "            TFT5PreTrainedModel,\n",
      "        )\n",
      "        from .models.tapas import (\n",
      "            TFTapasForMaskedLM,\n",
      "            TFTapasForQuestionAnswering,\n",
      "            TFTapasForSequenceClassification,\n",
      "            TFTapasModel,\n",
      "            TFTapasPreTrainedModel,\n",
      "        )\n",
      "        from .models.vision_encoder_decoder import TFVisionEncoderDecoderModel\n",
      "        from .models.vision_text_dual_encoder import TFVisionTextDualEncoderModel\n",
      "        from .models.vit import (\n",
      "            TFViTForImageClassification,\n",
      "            TFViTModel,\n",
      "            TFViTPreTrainedModel,\n",
      "        )\n",
      "        from .models.vit_mae import (\n",
      "            TFViTMAEForPreTraining,\n",
      "            TFViTMAEModel,\n",
      "            TFViTMAEPreTrainedModel,\n",
      "        )\n",
      "        from .models.wav2vec2 import (\n",
      "            TFWav2Vec2ForCTC,\n",
      "            TFWav2Vec2ForSequenceClassification,\n",
      "            TFWav2Vec2Model,\n",
      "            TFWav2Vec2PreTrainedModel,\n",
      "        )\n",
      "        from .models.whisper import (\n",
      "            TFWhisperForConditionalGeneration,\n",
      "            TFWhisperModel,\n",
      "            TFWhisperPreTrainedModel,\n",
      "        )\n",
      "        from .models.xglm import (\n",
      "            TFXGLMForCausalLM,\n",
      "            TFXGLMModel,\n",
      "            TFXGLMPreTrainedModel,\n",
      "        )\n",
      "        from .models.xlm import (\n",
      "            TFXLMForMultipleChoice,\n",
      "            TFXLMForQuestionAnsweringSimple,\n",
      "            TFXLMForSequenceClassification,\n",
      "            TFXLMForTokenClassification,\n",
      "            TFXLMMainLayer,\n",
      "            TFXLMModel,\n",
      "            TFXLMPreTrainedModel,\n",
      "            TFXLMWithLMHeadModel,\n",
      "        )\n",
      "        from .models.xlm_roberta import (\n",
      "            TFXLMRobertaForCausalLM,\n",
      "            TFXLMRobertaForMaskedLM,\n",
      "            TFXLMRobertaForMultipleChoice,\n",
      "            TFXLMRobertaForQuestionAnswering,\n",
      "            TFXLMRobertaForSequenceClassification,\n",
      "            TFXLMRobertaForTokenClassification,\n",
      "            TFXLMRobertaModel,\n",
      "            TFXLMRobertaPreTrainedModel,\n",
      "        )\n",
      "        from .models.xlnet import (\n",
      "            TFXLNetForMultipleChoice,\n",
      "            TFXLNetForQuestionAnsweringSimple,\n",
      "            TFXLNetForSequenceClassification,\n",
      "            TFXLNetForTokenClassification,\n",
      "            TFXLNetLMHeadModel,\n",
      "            TFXLNetMainLayer,\n",
      "            TFXLNetModel,\n",
      "            TFXLNetPreTrainedModel,\n",
      "        )\n",
      "\n",
      "        # Optimization\n",
      "        from .optimization_tf import (\n",
      "            AdamWeightDecay,\n",
      "            GradientAccumulator,\n",
      "            WarmUp,\n",
      "            create_optimizer,\n",
      "        )\n",
      "\n",
      "    try:\n",
      "        if not (\n",
      "            is_librosa_available()\n",
      "            and is_essentia_available()\n",
      "            and is_scipy_available()\n",
      "            and is_torch_available()\n",
      "            and is_pretty_midi_available()\n",
      "        ):\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects import *\n",
      "    else:\n",
      "        from .models.pop2piano import (\n",
      "            Pop2PianoFeatureExtractor,\n",
      "            Pop2PianoProcessor,\n",
      "            Pop2PianoTokenizer,\n",
      "        )\n",
      "\n",
      "    try:\n",
      "        if not is_torchaudio_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        from .utils.dummy_torchaudio_objects import *\n",
      "    else:\n",
      "        from .models.musicgen_melody import MusicgenMelodyFeatureExtractor, MusicgenMelodyProcessor\n",
      "    try:\n",
      "        if not is_flax_available():\n",
      "            raise OptionalDependencyNotAvailable()\n",
      "    except OptionalDependencyNotAvailable:\n",
      "        # Import the same objects as dummies to get them in the namespace.\n",
      "        # They will raise an import error if the user tries to instantiate / use them.\n",
      "        from .utils.dummy_flax_objects import *\n",
      "    else:\n",
      "        from .generation import (\n",
      "            FlaxForcedBOSTokenLogitsProcessor,\n",
      "            FlaxForcedEOSTokenLogitsProcessor,\n",
      "            FlaxForceTokensLogitsProcessor,\n",
      "            FlaxGenerationMixin,\n",
      "            FlaxLogitsProcessor,\n",
      "            FlaxLogitsProcessorList,\n",
      "            FlaxLogitsWarper,\n",
      "            FlaxMinLengthLogitsProcessor,\n",
      "            FlaxSuppressTokensAtBeginLogitsProcessor,\n",
      "            FlaxSuppressTokensLogitsProcessor,\n",
      "            FlaxTemperatureLogitsWarper,\n",
      "            FlaxTopKLogitsWarper,\n",
      "            FlaxTopPLogitsWarper,\n",
      "            FlaxWhisperTimeStampLogitsProcessor,\n",
      "        )\n",
      "        from .modeling_flax_utils import FlaxPreTrainedModel\n",
      "\n",
      "        # Flax model imports\n",
      "        from .models.albert import (\n",
      "            FlaxAlbertForMaskedLM,\n",
      "            FlaxAlbertForMultipleChoice,\n",
      "            FlaxAlbertForPreTraining,\n",
      "            FlaxAlbertForQuestionAnswering,\n",
      "            FlaxAlbertForSequenceClassification,\n",
      "            FlaxAlbertForTokenClassification,\n",
      "            FlaxAlbertModel,\n",
      "            FlaxAlbertPreTrainedModel,\n",
      "        )\n",
      "        from .models.auto import (\n",
      "            FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING,\n",
      "            FLAX_MODEL_FOR_CAUSAL_LM_MAPPING,\n",
      "            FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
      "            FLAX_MODEL_FOR_MASKED_LM_MAPPING,\n",
      "            FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING,\n",
      "            FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING,\n",
      "            FLAX_MODEL_FOR_PRETRAINING_MAPPING,\n",
      "            FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
      "            FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING,\n",
      "            FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING,\n",
      "            FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING,\n",
      "            FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING,\n",
      "            FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING,\n",
      "            FLAX_MODEL_MAPPING,\n",
      "            FlaxAutoModel,\n",
      "            FlaxAutoModelForCausalLM,\n",
      "            FlaxAutoModelForImageClassification,\n",
      "            FlaxAutoModelForMaskedLM,\n",
      "            FlaxAutoModelForMultipleChoice,\n",
      "            FlaxAutoModelForNextSentencePrediction,\n",
      "            FlaxAutoModelForPreTraining,\n",
      "            FlaxAutoModelForQuestionAnswering,\n",
      "            FlaxAutoModelForSeq2SeqLM,\n",
      "            FlaxAutoModelForSequenceClassification,\n",
      "            FlaxAutoModelForSpeechSeq2Seq,\n",
      "            FlaxAutoModelForTokenClassification,\n",
      "            FlaxAutoModelForVision2Seq,\n",
      "        )\n",
      "        from .models.bart import (\n",
      "            FlaxBartDecoderPreTrainedModel,\n",
      "            FlaxBartForCausalLM,\n",
      "            FlaxBartForConditionalGeneration,\n",
      "            FlaxBartForQuestionAnswering,\n",
      "            FlaxBartForSequenceClassification,\n",
      "            FlaxBartModel,\n",
      "            FlaxBartPreTrainedModel,\n",
      "        )\n",
      "        from .models.beit import (\n",
      "            FlaxBeitForImageClassification,\n",
      "            FlaxBeitForMaskedImageModeling,\n",
      "            FlaxBeitModel,\n",
      "            FlaxBeitPreTrainedModel,\n",
      "        )\n",
      "        from .models.bert import (\n",
      "            FlaxBertForCausalLM,\n",
      "            FlaxBertForMaskedLM,\n",
      "            FlaxBertForMultipleChoice,\n",
      "            FlaxBertForNextSentencePrediction,\n",
      "            FlaxBertForPreTraining,\n",
      "            FlaxBertForQuestionAnswering,\n",
      "            FlaxBertForSequenceClassification,\n",
      "            FlaxBertForTokenClassification,\n",
      "            FlaxBertModel,\n",
      "            FlaxBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.big_bird import (\n",
      "            FlaxBigBirdForCausalLM,\n",
      "            FlaxBigBirdForMaskedLM,\n",
      "            FlaxBigBirdForMultipleChoice,\n",
      "            FlaxBigBirdForPreTraining,\n",
      "            FlaxBigBirdForQuestionAnswering,\n",
      "            FlaxBigBirdForSequenceClassification,\n",
      "            FlaxBigBirdForTokenClassification,\n",
      "            FlaxBigBirdModel,\n",
      "            FlaxBigBirdPreTrainedModel,\n",
      "        )\n",
      "        from .models.blenderbot import (\n",
      "            FlaxBlenderbotForConditionalGeneration,\n",
      "            FlaxBlenderbotModel,\n",
      "            FlaxBlenderbotPreTrainedModel,\n",
      "        )\n",
      "        from .models.blenderbot_small import (\n",
      "            FlaxBlenderbotSmallForConditionalGeneration,\n",
      "            FlaxBlenderbotSmallModel,\n",
      "            FlaxBlenderbotSmallPreTrainedModel,\n",
      "        )\n",
      "        from .models.bloom import (\n",
      "            FlaxBloomForCausalLM,\n",
      "            FlaxBloomModel,\n",
      "            FlaxBloomPreTrainedModel,\n",
      "        )\n",
      "        from .models.clip import (\n",
      "            FlaxCLIPModel,\n",
      "            FlaxCLIPPreTrainedModel,\n",
      "            FlaxCLIPTextModel,\n",
      "            FlaxCLIPTextModelWithProjection,\n",
      "            FlaxCLIPTextPreTrainedModel,\n",
      "            FlaxCLIPVisionModel,\n",
      "            FlaxCLIPVisionPreTrainedModel,\n",
      "        )\n",
      "        from .models.dinov2 import (\n",
      "            FlaxDinov2ForImageClassification,\n",
      "            FlaxDinov2Model,\n",
      "            FlaxDinov2PreTrainedModel,\n",
      "        )\n",
      "        from .models.distilbert import (\n",
      "            FlaxDistilBertForMaskedLM,\n",
      "            FlaxDistilBertForMultipleChoice,\n",
      "            FlaxDistilBertForQuestionAnswering,\n",
      "            FlaxDistilBertForSequenceClassification,\n",
      "            FlaxDistilBertForTokenClassification,\n",
      "            FlaxDistilBertModel,\n",
      "            FlaxDistilBertPreTrainedModel,\n",
      "        )\n",
      "        from .models.electra import (\n",
      "            FlaxElectraForCausalLM,\n",
      "            FlaxElectraForMaskedLM,\n",
      "            FlaxElectraForMultipleChoice,\n",
      "            FlaxElectraForPreTraining,\n",
      "            FlaxElectraForQuestionAnswering,\n",
      "            FlaxElectraForSequenceClassification,\n",
      "            FlaxElectraForTokenClassification,\n",
      "            FlaxElectraModel,\n",
      "            FlaxElectraPreTrainedModel,\n",
      "        )\n",
      "        from .models.encoder_decoder import FlaxEncoderDecoderModel\n",
      "        from .models.gemma import (\n",
      "            FlaxGemmaForCausalLM,\n",
      "            FlaxGemmaModel,\n",
      "            FlaxGemmaPreTrainedModel,\n",
      "        )\n",
      "        from .models.gpt2 import (\n",
      "            FlaxGPT2LMHeadModel,\n",
      "            FlaxGPT2Model,\n",
      "            FlaxGPT2PreTrainedModel,\n",
      "        )\n",
      "        from .models.gpt_neo import (\n",
      "            FlaxGPTNeoForCausalLM,\n",
      "            FlaxGPTNeoModel,\n",
      "            FlaxGPTNeoPreTrainedModel,\n",
      "        )\n",
      "        from .models.gptj import (\n",
      "            FlaxGPTJForCausalLM,\n",
      "            FlaxGPTJModel,\n",
      "            FlaxGPTJPreTrainedModel,\n",
      "        )\n",
      "        from .models.llama import (\n",
      "            FlaxLlamaForCausalLM,\n",
      "            FlaxLlamaModel,\n",
      "            FlaxLlamaPreTrainedModel,\n",
      "        )\n",
      "        from .models.longt5 import (\n",
      "            FlaxLongT5ForConditionalGeneration,\n",
      "            FlaxLongT5Model,\n",
      "            FlaxLongT5PreTrainedModel,\n",
      "        )\n",
      "        from .models.marian import (\n",
      "            FlaxMarianModel,\n",
      "            FlaxMarianMTModel,\n",
      "            FlaxMarianPreTrainedModel,\n",
      "        )\n",
      "        from .models.mbart import (\n",
      "            FlaxMBartForConditionalGeneration,\n",
      "            FlaxMBartForQuestionAnswering,\n",
      "            FlaxMBartForSequenceClassification,\n",
      "            FlaxMBartModel,\n",
      "            FlaxMBartPreTrainedModel,\n",
      "        )\n",
      "        from .models.mistral import (\n",
      "            FlaxMistralForCausalLM,\n",
      "            FlaxMistralModel,\n",
      "            FlaxMistralPreTrainedModel,\n",
      "        )\n",
      "        from .models.mt5 import (\n",
      "            FlaxMT5EncoderModel,\n",
      "            FlaxMT5ForConditionalGeneration,\n",
      "            FlaxMT5Model,\n",
      "        )\n",
      "        from .models.opt import FlaxOPTForCausalLM, FlaxOPTModel, FlaxOPTPreTrainedModel\n",
      "        from .models.pegasus import (\n",
      "            FlaxPegasusForConditionalGeneration,\n",
      "            FlaxPegasusModel,\n",
      "            FlaxPegasusPreTrainedModel,\n",
      "        )\n",
      "        from .models.regnet import (\n",
      "            FlaxRegNetForImageClassification,\n",
      "            FlaxRegNetModel,\n",
      "            FlaxRegNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.resnet import (\n",
      "            FlaxResNetForImageClassification,\n",
      "            FlaxResNetModel,\n",
      "            FlaxResNetPreTrainedModel,\n",
      "        )\n",
      "        from .models.roberta import (\n",
      "            FlaxRobertaForCausalLM,\n",
      "            FlaxRobertaForMaskedLM,\n",
      "            FlaxRobertaForMultipleChoice,\n",
      "            FlaxRobertaForQuestionAnswering,\n",
      "            FlaxRobertaForSequenceClassification,\n",
      "            FlaxRobertaForTokenClassification,\n",
      "            FlaxRobertaModel,\n",
      "            FlaxRobertaPreTrainedModel,\n",
      "        )\n",
      "        from .models.roberta_prelayernorm import (\n",
      "            FlaxRobertaPreLayerNormForCausalLM,\n",
      "            FlaxRobertaPreLayerNormForMaskedLM,\n",
      "            FlaxRobertaPreLayerNormForMultipleChoice,\n",
      "            FlaxRobertaPreLayerNormForQuestionAnswering,\n",
      "            FlaxRobertaPreLayerNormForSequenceClassification,\n",
      "            FlaxRobertaPreLayerNormForTokenClassification,\n",
      "            FlaxRobertaPreLayerNormModel,\n",
      "            FlaxRobertaPreLayerNormPreTrainedModel,\n",
      "        )\n",
      "        from .models.roformer import (\n",
      "            FlaxRoFormerForMaskedLM,\n",
      "            FlaxRoFormerForMultipleChoice,\n",
      "            FlaxRoFormerForQuestionAnswering,\n",
      "            FlaxRoFormerForSequenceClassification,\n",
      "            FlaxRoFormerForTokenClassification,\n",
      "            FlaxRoFormerModel,\n",
      "            FlaxRoFormerPreTrainedModel,\n",
      "        )\n",
      "        from .models.speech_encoder_decoder import FlaxSpeechEncoderDecoderModel\n",
      "        from .models.t5 import (\n",
      "            FlaxT5EncoderModel,\n",
      "            FlaxT5ForConditionalGeneration,\n",
      "            FlaxT5Model,\n",
      "            FlaxT5PreTrainedModel,\n",
      "        )\n",
      "        from .models.vision_encoder_decoder import FlaxVisionEncoderDecoderModel\n",
      "        from .models.vision_text_dual_encoder import FlaxVisionTextDualEncoderModel\n",
      "        from .models.vit import (\n",
      "            FlaxViTForImageClassification,\n",
      "            FlaxViTModel,\n",
      "            FlaxViTPreTrainedModel,\n",
      "        )\n",
      "        from .models.wav2vec2 import (\n",
      "            FlaxWav2Vec2ForCTC,\n",
      "            FlaxWav2Vec2ForPreTraining,\n",
      "            FlaxWav2Vec2Model,\n",
      "            FlaxWav2Vec2PreTrainedModel,\n",
      "        )\n",
      "        from .models.whisper import (\n",
      "            FlaxWhisperForAudioClassification,\n",
      "            FlaxWhisperForConditionalGeneration,\n",
      "            FlaxWhisperModel,\n",
      "            FlaxWhisperPreTrainedModel,\n",
      "        )\n",
      "        from .models.xglm import (\n",
      "            FlaxXGLMForCausalLM,\n",
      "            FlaxXGLMModel,\n",
      "            FlaxXGLMPreTrainedModel,\n",
      "        )\n",
      "        from .models.xlm_roberta import (\n",
      "            FlaxXLMRobertaForCausalLM,\n",
      "            FlaxXLMRobertaForMaskedLM,\n",
      "            FlaxXLMRobertaForMultipleChoice,\n",
      "            FlaxXLMRobertaForQuestionAnswering,\n",
      "            FlaxXLMRobertaForSequenceClassification,\n",
      "            FlaxXLMRobertaForTokenClassification,\n",
      "            FlaxXLMRobertaModel,\n",
      "            FlaxXLMRobertaPreTrainedModel,\n",
      "        )\n",
      "\n",
      "\n",
      "else:\n",
      "    import sys\n",
      "\n",
      "    sys.modules[__name__] = _LazyModule(\n",
      "        __name__,\n",
      "        globals()[\"__file__\"],\n",
      "        _import_structure,\n",
      "        module_spec=__spec__,\n",
      "        extra_objects={\"__version__\": __version__},\n",
      "    )\n",
      "\n",
      "\n",
      "if not is_tf_available() and not is_torch_available() and not is_flax_available():\n",
      "    logger.warning_advice(\n",
      "        \"None of PyTorch, TensorFlow >= 2.0, or Flax have been found. \"\n",
      "        \"Models won't be available and only tokenizers, configuration \"\n",
      "        \"and file/data utilities can be used.\"\n",
      "    )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76adab95-8d87-4fb9-a9de-f0dcde7a72fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.51.3\n",
      "Uninstalling transformers-4.51.3:\n",
      "  Successfully uninstalled transformers-4.51.3\n",
      "Found existing installation: tokenizers 0.21.4\n",
      "Uninstalling tokenizers-0.21.4:\n",
      "  Successfully uninstalled tokenizers-0.21.4\n",
      "Collecting transformers==4.41.2\n",
      "  Using cached transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tokenizers==0.19.1\n",
      "  Using cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.41.2) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.41.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.41.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.41.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.41.2) (2025.1.31)\n",
      "Using cached transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "Using cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.19.1 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers tokenizers -y\n",
    "!pip install transformers==4.41.2 tokenizers==0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e92ea7-7c4e-4f34-a434-8db7c9422190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/ai_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.11\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              pkgs/main/osx-arm64::bzip2-1.0.8-h80987f9_6 \n",
      "  ca-certificates    pkgs/main/osx-arm64::ca-certificates-2025.9.9-hca03da5_0 \n",
      "  expat              pkgs/main/osx-arm64::expat-2.7.1-h313beb8_0 \n",
      "  libcxx             pkgs/main/osx-arm64::libcxx-20.1.8-h8869778_0 \n",
      "  libffi             pkgs/main/osx-arm64::libffi-3.4.4-hca03da5_1 \n",
      "  libzlib            pkgs/main/osx-arm64::libzlib-1.3.1-h5f15de7_0 \n",
      "  ncurses            pkgs/main/osx-arm64::ncurses-6.5-hee39554_0 \n",
      "  openssl            pkgs/main/osx-arm64::openssl-3.0.18-h9b4081a_0 \n",
      "  pip                pkgs/main/noarch::pip-25.2-pyhc872135_0 \n",
      "  python             pkgs/main/osx-arm64::python-3.11.13-h19e8193_0 \n",
      "  readline           pkgs/main/osx-arm64::readline-8.3-h0b18652_0 \n",
      "  setuptools         pkgs/main/osx-arm64::setuptools-78.1.1-py311hca03da5_0 \n",
      "  sqlite             pkgs/main/osx-arm64::sqlite-3.50.2-h79febb2_1 \n",
      "  tk                 pkgs/main/osx-arm64::tk-8.6.15-hcd8a7d5_0 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "  wheel              pkgs/main/osx-arm64::wheel-0.45.1-py311hca03da5_0 \n",
      "  xz                 pkgs/main/osx-arm64::xz-5.6.4-h80987f9_1 \n",
      "  zlib               pkgs/main/osx-arm64::zlib-1.3.1-h5f15de7_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate ai_env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/ai_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipykernel\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  appnope            pkgs/main/osx-arm64::appnope-0.1.4-py311hca03da5_0 \n",
      "  asttokens          pkgs/main/osx-arm64::asttokens-3.0.0-py311hca03da5_0 \n",
      "  comm               pkgs/main/osx-arm64::comm-0.2.1-py311hca03da5_0 \n",
      "  debugpy            pkgs/main/osx-arm64::debugpy-1.8.16-py311h0962b89_0 \n",
      "  decorator          pkgs/main/osx-arm64::decorator-5.2.1-py311hca03da5_0 \n",
      "  executing          pkgs/main/osx-arm64::executing-2.2.1-py311hca03da5_0 \n",
      "  ipykernel          pkgs/main/osx-arm64::ipykernel-6.30.1-py311hca03da5_0 \n",
      "  ipython            pkgs/main/osx-arm64::ipython-9.5.0-py311hca03da5_0 \n",
      "  ipython_pygments_~ pkgs/main/osx-arm64::ipython_pygments_lexers-1.1.1-py311hca03da5_0 \n",
      "  jedi               pkgs/main/osx-arm64::jedi-0.19.2-py311hca03da5_0 \n",
      "  jupyter_client     pkgs/main/osx-arm64::jupyter_client-8.6.3-py311hca03da5_0 \n",
      "  jupyter_core       pkgs/main/osx-arm64::jupyter_core-5.8.1-py311hca03da5_0 \n",
      "  libsodium          pkgs/main/osx-arm64::libsodium-1.0.20-h897f8a9_0 \n",
      "  matplotlib-inline  pkgs/main/osx-arm64::matplotlib-inline-0.1.7-py311hca03da5_0 \n",
      "  nest-asyncio       pkgs/main/osx-arm64::nest-asyncio-1.6.0-py311hca03da5_0 \n",
      "  packaging          pkgs/main/osx-arm64::packaging-25.0-py311hca03da5_0 \n",
      "  parso              pkgs/main/osx-arm64::parso-0.8.4-py311hca03da5_0 \n",
      "  pexpect            pkgs/main/osx-arm64::pexpect-4.9.0-py311hca03da5_0 \n",
      "  platformdirs       pkgs/main/osx-arm64::platformdirs-4.3.7-py311hca03da5_0 \n",
      "  prompt-toolkit     pkgs/main/osx-arm64::prompt-toolkit-3.0.43-py311hca03da5_0 \n",
      "  prompt_toolkit     pkgs/main/noarch::prompt_toolkit-3.0.43-hd3eb1b0_0 \n",
      "  psutil             pkgs/main/osx-arm64::psutil-7.0.0-py311h254cc4a_0 \n",
      "  ptyprocess         pkgs/main/noarch::ptyprocess-0.7.0-pyhd3eb1b0_2 \n",
      "  pure_eval          pkgs/main/osx-arm64::pure_eval-0.2.3-py311hca03da5_0 \n",
      "  pygments           pkgs/main/osx-arm64::pygments-2.19.1-py311hca03da5_0 \n",
      "  python-dateutil    pkgs/main/osx-arm64::python-dateutil-2.9.0post0-py311hca03da5_2 \n",
      "  pyzmq              pkgs/main/osx-arm64::pyzmq-27.1.0-py311h854a7ef_0 \n",
      "  six                pkgs/main/osx-arm64::six-1.17.0-py311hca03da5_0 \n",
      "  stack_data         pkgs/main/osx-arm64::stack_data-0.6.3-py311hca03da5_0 \n",
      "  tornado            pkgs/main/osx-arm64::tornado-6.5.1-py311h80987f9_0 \n",
      "  traitlets          pkgs/main/osx-arm64::traitlets-5.14.3-py311hca03da5_0 \n",
      "  typing_extensions  pkgs/main/osx-arm64::typing_extensions-4.15.0-py311hca03da5_0 \n",
      "  wcwidth            pkgs/main/osx-arm64::wcwidth-0.2.13-py311hca03da5_0 \n",
      "  zeromq             pkgs/main/osx-arm64::zeromq-4.3.5-h2c7f8f0_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "usage: ipython-kernel-install [-h] [--user] [--name NAME]\n",
      "                              [--display-name DISPLAY_NAME]\n",
      "                              [--profile PROFILE] [--prefix PREFIX]\n",
      "                              [--sys-prefix] [--env ENV VALUE]\n",
      "                              [--frozen_modules]\n",
      "ipython-kernel-install: error: unrecognized arguments: --python=/opt/anaconda3/envs/ai_env/bin/python\n",
      "Collecting transformers==4.51.3\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp311-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting unstructured\n",
      "  Using cached unstructured-0.18.15-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting streamlit\n",
      "  Using cached streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting filelock (from transformers==4.51.3)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.51.3)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.51.3)\n",
      "  Using cached numpy-2.3.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/ai_env/lib/python3.11/site-packages (from transformers==4.51.3) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.51.3)\n",
      "  Using cached pyyaml-6.0.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.51.3)\n",
      "  Using cached regex-2025.9.18-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers==4.51.3)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.51.3)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers==4.51.3)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.51.3)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/ai_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting charset-normalizer (from unstructured)\n",
      "  Using cached charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Using cached lxml-6.0.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dataclasses-json (from unstructured)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Using cached rapidfuzz-3.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Using cached unstructured_client-0.42.3-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Using cached wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/ai_env/lib/python3.11/site-packages (from unstructured) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Using cached python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Using cached cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Using cached pillow-11.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit)\n",
      "  Using cached protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Using cached pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /opt/anaconda3/envs/ai_env/lib/python3.11/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/ai_env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Using cached narwhals-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.51.3)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.51.3)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.51.3)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached markupsafe-3.0.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Using cached rpds_py-0.27.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ai_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Using cached cryptography-46.0.2-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting httpcore>=1.0.9 (from unstructured-client->unstructured)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting httpx>=0.27.0 (from unstructured-client->unstructured)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic>=2.11.2 (from unstructured-client->unstructured)\n",
      "  Using cached pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Using cached pypdf-6.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting h11>=0.16 (from httpcore>=1.0.9->unstructured-client->unstructured)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->unstructured-client->unstructured)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.11.2->unstructured-client->unstructured)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.11.2->unstructured-client->unstructured)\n",
      "  Using cached pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.11.2->unstructured-client->unstructured)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27.0->unstructured-client->unstructured)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached torch-2.8.0-cp311-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "Using cached sentencepiece-0.2.1-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Using cached unstructured-0.18.15-py3-none-any.whl (1.8 MB)\n",
      "Using cached streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached pandas-2.3.3-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached numpy-2.3.3-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Using cached pillow-11.3.0-cp311-cp311-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl (204 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached markupsafe-3.0.3-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached narwhals-2.7.0-py3-none-any.whl (412 kB)\n",
      "Using cached pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl (31.2 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached pyyaml-6.0.3-cp311-cp311-macosx_11_0_arm64.whl (175 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached regex-2025.9.18-cp311-cp311-macosx_11_0_arm64.whl (286 kB)\n",
      "Using cached rpds_py-0.27.1-cp311-cp311-macosx_11_0_arm64.whl (353 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached lxml-6.0.2-cp311-cp311-macosx_10_9_universal2.whl (8.6 MB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Using cached rapidfuzz-3.14.1-cp311-cp311-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Using cached unstructured_client-0.42.3-py3-none-any.whl (207 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached cryptography-46.0.2-cp311-abi3-macosx_10_9_universal2.whl (7.3 MB)\n",
      "Using cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl (180 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached pypdf-6.1.1-py3-none-any.whl (323 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: webencodings, pytz, mpmath, filetype, wrapt, urllib3, tzdata, typing-inspection, tqdm, toml, tenacity, sympy, soupsieve, sniffio, smmap, sentencepiece, safetensors, rpds-py, regex, rapidfuzz, pyyaml, python-magic, python-iso639, pypdf, pydantic-core, pycparser, pyarrow, protobuf, pillow, olefile, numpy, networkx, narwhals, mypy-extensions, marshmallow, MarkupSafe, lxml, langdetect, joblib, idna, html5lib, hf-xet, h11, fsspec, filelock, emoji, click, charset-normalizer, certifi, cachetools, blinker, backoff, attrs, annotated-types, aiofiles, typing-inspect, requests, referencing, python-oxmsg, pydantic, pandas, nltk, jinja2, httpcore, gitdb, cffi, beautifulsoup4, anyio, torch, requests-toolbelt, pydeck, jsonschema-specifications, huggingface-hub, httpx, gitpython, dataclasses-json, cryptography, unstructured-client, tokenizers, jsonschema, unstructured, transformers, altair, streamlit\n",
      "\u001b[?25l\n",
      "\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/84\u001b[0m [mpmath]\n",
      "\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/84\u001b[0m [urllib3]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/84\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/84\u001b[0m [regex]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/84\u001b[0m [pypdf]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/84\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/84\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/84\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/84\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/84\u001b[0m [pillow]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/84\u001b[0m [olefile]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/84\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/84\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/84\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/84\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/84\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/84\u001b[0m [networkx]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/84\u001b[0m [networkx]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/84\u001b[0m [networkx]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/84\u001b[0m [networkx]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32/84\u001b[0m [narwhals]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35/84\u001b[0m [MarkupSafe]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/84\u001b[0m [joblib]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/84\u001b[0m [joblib]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/84\u001b[0m [joblib]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/84\u001b[0m [fsspec]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/84\u001b[0m [attrs]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m59/84\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m60/84\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m61/84\u001b[0m [nltk]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m61/84\u001b[0m [nltk]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m61/84\u001b[0m [nltk]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m64/84\u001b[0m [gitdb]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m68/84\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m72/84\u001b[0m [huggingface-hub]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m73/84\u001b[0m [httpx]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m76/84\u001b[0m [cryptography]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m78/84\u001b[0m [tokenizers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m80/84\u001b[0m [unstructured]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81/84\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m82/84\u001b[0m [altair]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m83/84\u001b[0m [streamlit]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m83/84\u001b[0m [streamlit]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84/84\u001b[0m [streamlit]\n",
      "\u001b[?25h\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 aiofiles-24.1.0 altair-5.5.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 backoff-2.2.1 beautifulsoup4-4.14.2 blinker-1.9.0 cachetools-6.2.0 certifi-2025.10.5 cffi-2.0.0 charset-normalizer-3.4.3 click-8.3.0 cryptography-46.0.2 dataclasses-json-0.6.7 emoji-2.15.0 filelock-3.19.1 filetype-1.2.0 fsspec-2025.9.0 gitdb-4.0.12 gitpython-3.1.45 h11-0.16.0 hf-xet-1.1.10 html5lib-1.1 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.35.3 idna-3.10 jinja2-3.1.6 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 langdetect-1.0.9 lxml-6.0.2 marshmallow-3.26.1 mpmath-1.3.0 mypy-extensions-1.1.0 narwhals-2.7.0 networkx-3.5 nltk-3.9.2 numpy-2.3.3 olefile-0.47 pandas-2.3.3 pillow-11.3.0 protobuf-6.32.1 pyarrow-21.0.0 pycparser-2.23 pydantic-2.11.10 pydantic-core-2.33.2 pydeck-0.9.1 pypdf-6.1.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pytz-2025.2 pyyaml-6.0.3 rapidfuzz-3.14.1 referencing-0.36.2 regex-2025.9.18 requests-2.32.5 requests-toolbelt-1.0.0 rpds-py-0.27.1 safetensors-0.6.2 sentencepiece-0.2.1 smmap-5.0.2 sniffio-1.3.1 soupsieve-2.8 streamlit-1.50.0 sympy-1.14.0 tenacity-9.1.2 tokenizers-0.21.4 toml-0.10.2 torch-2.8.0 tqdm-4.67.1 transformers-4.51.3 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.2 unstructured-0.18.15 unstructured-client-0.42.3 urllib3-2.5.0 webencodings-0.5.1 wrapt-1.17.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ Créer l'environnement Conda (Python 3.11)\n",
    "!conda create -n ai_env python=3.11 -y\n",
    "\n",
    "# 2️⃣ Installer ipykernel dans l'environnement\n",
    "!conda install -n ai_env ipykernel -y\n",
    "\n",
    "# 3️⃣ Ajouter l'environnement comme kernel Jupyter\n",
    "!ai_env_python=$(conda run -n ai_env which python) && \\\n",
    "python -m ipykernel install --user --name=ai_env --display-name \"Python 3.11 (ai_env)\" --python=$ai_env_python\n",
    "\n",
    "# Installer les packages dans l'environnement ai_env\n",
    "!conda run -n ai_env pip install transformers==4.51.3 torch sentencepiece unstructured streamlit pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c93254-1bbd-4b7c-abc4-bce1ad679393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.51.3\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: protobuf==4.25.3 in /opt/anaconda3/lib/python3.12/site-packages (4.25.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.51.3)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.51.3) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.1.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.51.3) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.51.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.51.3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.51.3) (2025.1.31)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.19.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.19.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.19.1\n",
      "\u001b[2K  Attempting uninstall: transformers\n",
      "\u001b[2K    Found existing installation: transformers 4.41.2\n",
      "\u001b[2K    Uninstalling transformers-4.41.2:\n",
      "\u001b[2K      Successfully uninstalled transformers-4.41.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.21.4 transformers-4.51.3\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.51.3 protobuf==4.25.3\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afbc8be5-4d82-4432-a23b-a7cb809745c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1967, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/__init__.py\", line 26, in <module>\n",
      "    from ..image_processing_utils import BaseImageProcessor\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/image_processing_utils.py\", line 22, in <module>\n",
      "    from .image_transforms import center_crop, normalize, rescale\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/image_transforms.py\", line 47, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/__init__.py\", line 49, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\", line 33, in <module>\n",
      "    from tensorflow.core.framework import attr_value_pb2\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 9, in <module>\n",
      "    from google.protobuf import runtime_version as _runtime_version\n",
      "ImportError: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.12/site-packages/google/protobuf/__init__.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 1412, in _handle_fromlist\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1955, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1969, in _get_module\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\n",
      "cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.12/site-packages/google/protobuf/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from transformers import pipeline; import torch; print('✅ Tout fonctionne !')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8416d223-d98b-4364-87f9-d790198e770f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/__init__.py\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.12/site-packages/google/protobuf/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1967\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1966\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:995\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/__init__.py:26\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_processing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/transformers/image_processing_utils.py:22\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_processing_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchFeature, ImageProcessingMixin\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, get_image_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/transformers/image_transforms.py:47\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/__init__.py:49\u001b[39m\n\u001b[32m     47\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:33\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.12/site-packages/google/protobuf/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(transformers.\u001b[34m__file__\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstreamlit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mst\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1955\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1953\u001b[39m     value = Placeholder\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1956\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1957\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1969\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1969\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1970\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1971\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1972\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.12/site-packages/google/protobuf/__init__.py)"
     ]
    }
   ],
   "source": [
    "#!pip install transformers==4.51.3 torch sentencepiece unstructured streamlit pandas\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "print(transformers.__file__)\n",
    "\n",
    "from transformers import pipeline\n",
    "from unstructured.partition.auto import partition\n",
    "import streamlit as st\n",
    "\n",
    "# ======================\n",
    "# 🔧 CONFIGURATION\n",
    "# ======================\n",
    "SOURCE_DIR = \"../documents\"\n",
    "DEST_DIR = \"../sorted\"\n",
    "RESULTS_FILE = \"../results.json\"\n",
    "\n",
    "# Thèmes cibles\n",
    "CATEGORIES = [\n",
    "    \"Physique\", \"Mathématiques\", \"Informatique\", \"Intelligence Artificielle\",\n",
    "    \"Philosophie\", \"Littérature\", \"Biologie\", \"Chimie\", \"Économie\", \"Sociologie\"\n",
    "]\n",
    "\n",
    "# ======================\n",
    "# 🧠 CHARGEMENT DU MODÈLE\n",
    "# ======================\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    return pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "classifier = load_model()\n",
    "\n",
    "# ======================\n",
    "# 📖 EXTRACTION TEXTE\n",
    "# ======================\n",
    "def extract_text(filepath):\n",
    "    try:\n",
    "        elements = partition(filename=filepath)\n",
    "        text = \"\\n\".join([el.text for el in elements if hasattr(el, \"text\")])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        st.warning(f\"Erreur lecture {filepath} : {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# ======================\n",
    "# 🔍 CLASSIFICATION\n",
    "# ======================\n",
    "def classify_document(filename, text):\n",
    "    if not text or len(text) < 50:\n",
    "        return {\"label\": \"Inconnu\", \"score\": 0.0}\n",
    "\n",
    "    result = classifier(text[:1000], CATEGORIES)\n",
    "    return {\"label\": result[\"labels\"][0], \"score\": float(result[\"scores\"][0])}\n",
    "\n",
    "# ======================\n",
    "# 📦 SAUVEGARDE JSON\n",
    "# ======================\n",
    "def save_results(results):\n",
    "    with open(RESULTS_FILE, \"w\") as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def load_results():\n",
    "    if os.path.exists(RESULTS_FILE):\n",
    "        with open(RESULTS_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "# ======================\n",
    "# 📂 RANGEMENT FICHIER\n",
    "# ======================\n",
    "def move_file(filepath, category):\n",
    "    basename = os.path.basename(filepath)\n",
    "    dest_folder = os.path.join(DEST_DIR, category)\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    shutil.move(filepath, os.path.join(dest_folder, basename))\n",
    "\n",
    "# ======================\n",
    "# 🖥️ INTERFACE STREAMLIT\n",
    "# ======================\n",
    "def app():\n",
    "    st.set_page_config(page_title=\"Organiseur de Documents IA\", layout=\"wide\")\n",
    "    st.title(\"📚 Organiseur de Documents IA\")\n",
    "    st.markdown(\"Analyse et classe automatiquement vos fichiers selon leur thème.\")\n",
    "\n",
    "    results = load_results()\n",
    "\n",
    "    # --- Section analyse automatique ---\n",
    "    st.header(\"🔍 Analyse automatique des documents\")\n",
    "    if st.button(\"Lancer l'analyse\"):\n",
    "        for filename in os.listdir(SOURCE_DIR):\n",
    "            filepath = os.path.join(SOURCE_DIR, filename)\n",
    "            if not os.path.isfile(filepath):\n",
    "                continue\n",
    "\n",
    "            with st.spinner(f\"Analyse de {filename}...\"):\n",
    "                text = extract_text(filepath)\n",
    "                prediction = classify_document(filename, text)\n",
    "                results[filename] = {\n",
    "                    \"category\": prediction[\"label\"],\n",
    "                    \"confidence\": prediction[\"score\"],\n",
    "                    \"path\": filepath,\n",
    "                }\n",
    "\n",
    "        save_results(results)\n",
    "        st.success(\"Analyse terminée ✅\")\n",
    "\n",
    "    # --- Section visualisation ---\n",
    "    if results:\n",
    "        df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "        st.header(\"🧩 Résultats du classement\")\n",
    "        st.dataframe(df)\n",
    "\n",
    "        # Correction manuelle\n",
    "        filename = st.selectbox(\"Choisir un fichier à corriger :\", list(results.keys()))\n",
    "        if filename:\n",
    "            current = results[filename]\n",
    "            new_category = st.selectbox(\n",
    "                f\"Modifier la catégorie de {filename} :\",\n",
    "                CATEGORIES + [\"Inconnu\"],\n",
    "                index=CATEGORIES.index(current[\"category\"]) if current[\"category\"] in CATEGORIES else len(CATEGORIES),\n",
    "            )\n",
    "            if st.button(\"Valider la correction\"):\n",
    "                results[filename][\"category\"] = new_category\n",
    "                save_results(results)\n",
    "                st.success(f\"{filename} → {new_category}\")\n",
    "\n",
    "        # Rangement automatique\n",
    "        if st.button(\"📂 Ranger les fichiers\"):\n",
    "            for filename, info in results.items():\n",
    "                if os.path.exists(info[\"path\"]):\n",
    "                    move_file(info[\"path\"], info[\"category\"])\n",
    "            st.success(\"Tous les fichiers ont été rangés dans leurs dossiers respectifs ✅\")\n",
    "\n",
    "# ======================\n",
    "# 🚀 LANCEMENT\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    app()\n",
    "\n",
    "#streamlit run organize_documents_AI.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1abb59-8296-45c0-bc00-3af834edbeca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
